{
    "sourceFile": "include/stereo_visual_odometry/visualOdometry.h",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1644294512005,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1644294512005,
            "name": "Commit-0",
            "content": "#ifndef VISUAL_ODOM_H\n#define VISUAL_ODOM_H\n\n#include \"opencv2/video/tracking.hpp\"\n#include \"opencv2/imgproc/imgproc.hpp\"\n#include \"opencv2/highgui/highgui.hpp\"\n#include \"opencv2/features2d/features2d.hpp\"\n#include \"opencv2/calib3d/calib3d.hpp\"\n\n#include <iostream>\n#include <ctype.h>\n#include <algorithm>\n#include <iterator>\n#include <vector>\n#include <ctime>\n#include <sstream>\n#include <fstream>\n#include <string>\n\n#include \"feature.h\"\n#include \"bucket.h\"\n#include \"utils.h\"\n\n#include \"ceres/ceres.h\"\n#include \"ceres/rotation.h\"\n/*\n* Input: 4 images and the set of currently tracked features, as\n* well as references to 4 vectors of points (by reference).\n* Return: vectors of features shared between the 4 images\n*/\nvoid matchingFeatures(cv::Mat& imageLeft_t0, cv::Mat& imageRight_t0,\n                      cv::Mat& imageLeft_t1, cv::Mat& imageRight_t1, \n                      FeatureSet& currentVOFeatures,\n                      std::vector<cv::Point2f>&  pointsLeft_t0, \n                      std::vector<cv::Point2f>&  pointsRight_t0, \n                      std::vector<cv::Point2f>&  pointsLeft_t1, \n                      std::vector<cv::Point2f>&  pointsRight_t1);\n\n\n// void trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n//                          std::vector<cv::Point2f>&  pointsLeft_t0,\n//                          std::vector<cv::Point2f>&  pointsLeft_t1, \n//                          cv::Mat& points3D_t0,\n//                          cv::Mat& rotation,\n//                          cv::Mat& translation,\n//                          bool mono_rotation=true);\n\nvoid trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n                         std::vector<cv::Point2f>&  pointsLeft_t1, \n                         cv::Mat& points3D_t0,\n                         cv::Mat& rotation,\n                         cv::Mat& translation,\n                         bool mono_rotation=true);\n\n\nvoid displayTracking(cv::Mat& imageLeft_t1, \n                     std::vector<cv::Point2f>&  pointsLeft_t0,\n                     std::vector<cv::Point2f>&  pointsLeft_t1);\n\nvoid displayPoints(cv::Mat& image, std::vector<cv::Point2f>&  points);\n\nvoid optimize_transformation(cv::Mat& rotation, cv::Mat& translation, cv::Mat& points3D, \n  cv::Mat& pointsLeft, cv::Mat& inliers, cv::Mat & projection_matrix);\n\n#endif\n"
        }
    ]
}