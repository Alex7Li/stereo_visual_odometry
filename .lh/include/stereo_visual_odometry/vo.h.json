{
    "sourceFile": "include/stereo_visual_odometry/vo.h",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 124,
            "patches": [
                {
                    "date": 1645281187446,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1645281250433,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,10 +160,15 @@\n     VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n \n     ~VisualOdometry();\n \n-    // Takes the two images seen by both cameras and runs the pipeline.\n-    // TODO: Results are obtained somehow\n+    /**\n+     * @brief \n+     * \n+     * @param image_left The left image from stereo camera\n+     * @param image_right The right image from stereo camera\n+     */\n+  \n     void stereo_callback(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n };\n }   // namespace visual_odometry\n"
                },
                {
                    "date": 1645281277117,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -161,9 +161,10 @@\n \n     ~VisualOdometry();\n \n     /**\n-     * @brief \n+     * @brief Process one time step of camera imagery and\n+     * update the API.\n      * \n      * @param image_left The left image from stereo camera\n      * @param image_right The right image from stereo camera\n      */\n"
                },
                {
                    "date": 1645281298711,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -162,9 +162,9 @@\n     ~VisualOdometry();\n \n     /**\n      * @brief Process one time step of camera imagery and\n-     * update the API.\n+     * publish the result.\n      * \n      * @param image_left The left image from stereo camera\n      * @param image_right The right image from stereo camera\n      */\n"
                },
                {
                    "date": 1645281322732,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,11 +95,8 @@\n \n     // set of features currently tracked\n     FeatureSet currentVOFeatures;\n \n-    // runs the pipeline\n-    void run();\n-\n     /**\n      *  Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      */\n"
                },
                {
                    "date": 1645282286754,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,8 +27,9 @@\n #include <opencv2/highgui/highgui.hpp>\n #include <opencv2/imgproc/imgproc.hpp>\n #include <opencv2/opencv.hpp>\n #include <opencv2/video/tracking.hpp>\n+#include <bucket.h>\n #include <sstream>\n #include <string>\n #include <vector>\n \n"
                },
                {
                    "date": 1645282297851,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,24 +55,8 @@\n         ages.clear();\n     }\n };\n \n-class Bucket {\n-   public:\n-    int id;\n-    int max_size;\n-\n-    FeatureSet features;\n-\n-    Bucket(int);\n-    ~Bucket();\n-\n-    void add_feature(cv::Point2f, int);\n-    void get_features(FeatureSet&);\n-\n-    int size();\n-};\n-\n class StereoVO {\n    public:\n };\n \n"
                },
                {
                    "date": 1645282310265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,8 +28,9 @@\n #include <opencv2/imgproc/imgproc.hpp>\n #include <opencv2/opencv.hpp>\n #include <opencv2/video/tracking.hpp>\n #include <bucket.h>\n+#include <feature.h>\n #include <sstream>\n #include <string>\n #include <vector>\n \n"
                },
                {
                    "date": 1645282338599,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,10 +27,8 @@\n #include <opencv2/highgui/highgui.hpp>\n #include <opencv2/imgproc/imgproc.hpp>\n #include <opencv2/opencv.hpp>\n #include <opencv2/video/tracking.hpp>\n-#include <bucket.h>\n-#include <feature.h>\n #include <sstream>\n #include <string>\n #include <vector>\n \n@@ -56,8 +54,24 @@\n         ages.clear();\n     }\n };\n \n+class Bucket {\n+   public:\n+    int id;\n+    int max_size;\n+\n+    FeatureSet features;\n+\n+    Bucket(int);\n+    ~Bucket();\n+\n+    void add_feature(cv::Point2f, int);\n+    void get_features(FeatureSet&);\n+\n+    int size();\n+};\n+\n class StereoVO {\n    public:\n };\n \n@@ -81,8 +95,11 @@\n \n     // set of features currently tracked\n     FeatureSet currentVOFeatures;\n \n+\n+    void run();\n+\n     /**\n      *  Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      */\n"
                },
                {
                    "date": 1645282541148,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -170,6 +170,16 @@\n      */\n   \n     void stereo_callback(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n+    /**\n+     * @brief Process one time step of camera imagery and\n+     * publish the result.\n+     * \n+     * @param image_left The left image from stereo camera\n+     * @param image_right The right image from stereo camera\n+     */\n+  \n+    void stereo_callback(const cv::Mat& image_left,\n+                         const cv::Mat& image_right);\n };\n }   // namespace visual_odometry\n"
                },
                {
                    "date": 1645282566859,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -168,9 +168,9 @@\n      * @param image_left The left image from stereo camera\n      * @param image_right The right image from stereo camera\n      */\n   \n-    void stereo_callback(const cv::Mat& image_left,\n+    void stereo_callback_(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n     /**\n      * @brief Process one time step of camera imagery and\n      * publish the result.\n"
                },
                {
                    "date": 1645282701276,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,8 +132,16 @@\n                            int bucket_size, int features_per_bucket);\n     /**\n      * \n      */\n+/*\n+* Input: 4 images and the set of currently tracked features, as\n+* well as references to 4 vectors of points (by reference).\n+* Return: vectors of features shared between the 4 images\n+*/\n+    /**\n+     *\n+     */\n     void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                           cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                           FeatureSet& currentVOFeatures,\n                           std::vector<cv::Point2f>& pointsLeftT0,\n@@ -168,18 +176,8 @@\n      * @param image_left The left image from stereo camera\n      * @param image_right The right image from stereo camera\n      */\n   \n-    void stereo_callback_(const cv::Mat& image_left,\n-                         const cv::Mat& image_right);\n-    /**\n-     * @brief Process one time step of camera imagery and\n-     * publish the result.\n-     * \n-     * @param image_left The left image from stereo camera\n-     * @param image_right The right image from stereo camera\n-     */\n-  \n     void stereo_callback(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n };\n }   // namespace visual_odometry\n"
                },
                {
                    "date": 1645282715503,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,9 @@\n * well as references to 4 vectors of points (by reference).\n * Return: vectors of features shared between the 4 images\n */\n     /**\n-     *\n+     * \n      */\n     void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                           cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                           FeatureSet& currentVOFeatures,\n"
                },
                {
                    "date": 1645282732137,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,14 +133,14 @@\n     /**\n      * \n      */\n /*\n-* Input: 4 images and the set of currently tracked features, as\n-* well as references to 4 vectors of points (by reference).\n-* Return: vectors of features shared between the 4 images\n */\n     /**\n      * \n+    * Input: 4 images and the set of currently tracked features, as\n+    * well as references to 4 vectors of points (by reference).\n+    * @return: vectors of features shared between the 4 images\n      */\n     void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                           cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                           FeatureSet& currentVOFeatures,\n"
                },
                {
                    "date": 1645282745157,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -135,12 +135,11 @@\n      */\n /*\n */\n     /**\n-     * \n-    * Input: 4 images and the set of currently tracked features, as\n-    * well as references to 4 vectors of points (by reference).\n-    * @return: vectors of features shared between the 4 images\n+     * Input: 4 images and the set of currently tracked features, as\n+     * well as references to 4 vectors of points (by reference).\n+     * @return: vectors of features shared between the 4 images\n      */\n     void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                           cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                           FeatureSet& currentVOFeatures,\n"
                },
                {
                    "date": 1645282766331,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -130,13 +130,8 @@\n      */\n     void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n                            int bucket_size, int features_per_bucket);\n     /**\n-     * \n-     */\n-/*\n-*/\n-    /**\n      * Input: 4 images and the set of currently tracked features, as\n      * well as references to 4 vectors of points (by reference).\n      * @return: vectors of features shared between the 4 images\n      */\n"
                },
                {
                    "date": 1645282781072,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,9 +132,9 @@\n                            int bucket_size, int features_per_bucket);\n     /**\n      * Input: 4 images and the set of currently tracked features, as\n      * well as references to 4 vectors of points (by reference).\n-     * @return: vectors of features shared between the 4 images\n+     * @return: vectors of features shared between the 4 images.\n      */\n     void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                           cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                           FeatureSet& currentVOFeatures,\n"
                },
                {
                    "date": 1645282811910,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -123,11 +123,12 @@\n                           FeatureSet& current_features);\n     /**\n      * Updates current_features to only include a subset of the\n      * original features which give a good spread throughout the image.\n-     * image: only use for getting dimension of the image\n-     * bucket_size: bucket size in pixel is bucket_size*bucket_size\n-     * features_per_bucket: number of selected features per bucket\n+     * @param image: only use for getting dimension of the image\n+     * @param current_features: All features currently in the bucket.\n+     * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n+     * @param features_per_bucket: number of selected features per bucket\n      */\n     void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n                            int bucket_size, int features_per_bucket);\n     /**\n"
                },
                {
                    "date": 1645282931565,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,8 +159,14 @@\n                              cv::Mat& points3D_T0, cv::Mat& rotation,\n                              cv::Mat& translation, bool mono_rotation);\n \n    public:\n+   /**\n+    * @brief Construct a new Visual Odometry object\n+    * \n+    * @param ProjMatrl \n+    * @param projMatrr \n+    */\n     VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n \n     ~VisualOdometry();\n \n"
                },
                {
                    "date": 1645282965538,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -162,10 +162,10 @@\n    public:\n    /**\n     * @brief Construct a new Visual Odometry object\n     * \n-    * @param ProjMatrl \n-    * @param projMatrr \n+    * @param ProjMatrl Left camera parameter matrix\n+    * @param projMatrr Right camera parameter matrix\n     */\n     VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n \n     ~VisualOdometry();\n"
                },
                {
                    "date": 1645282977177,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -176,9 +176,8 @@\n      * \n      * @param image_left The left image from stereo camera\n      * @param image_right The right image from stereo camera\n      */\n-  \n     void stereo_callback(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n };\n }   // namespace visual_odometry\n"
                },
                {
                    "date": 1645283005150,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,12 +70,8 @@\n \n     int size();\n };\n \n-class StereoVO {\n-   public:\n-};\n-\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n     int frame_id = 0;\n"
                },
                {
                    "date": 1645283240374,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,8 +55,10 @@\n     }\n };\n \n class Bucket {\n+  private:\n+    int AGE_THRESHOLD = 10;\n    public:\n     int id;\n     int max_size;\n \n"
                },
                {
                    "date": 1645283807345,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,9 @@\n }\n \n namespace visual_odometry {\n \n-struct FeatureSet {\n+class FeatureSet {\n     std::vector<cv::Point2f> points;\n     std::vector<int> ages;\n     int size() {\n         return points.size();\n@@ -57,9 +57,9 @@\n \n class Bucket {\n   private:\n     int AGE_THRESHOLD = 10;\n-   public:\n+  public:\n     int id;\n     int max_size;\n \n     FeatureSet features;\n"
                },
                {
                    "date": 1645283827746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -43,8 +43,10 @@\n \n namespace visual_odometry {\n \n class FeatureSet {\n+  private:\n+    int AGE_THRESHOLD = 10;\n     std::vector<cv::Point2f> points;\n     std::vector<int> ages;\n     int size() {\n         return points.size();\n"
                },
                {
                    "date": 1645283965432,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,8 +45,9 @@\n \n class FeatureSet {\n   private:\n     int AGE_THRESHOLD = 10;\n+  public:\n     std::vector<cv::Point2f> points;\n     std::vector<int> ages;\n     int size() {\n         return points.size();\n@@ -54,8 +55,18 @@\n     void clear() {\n         points.clear();\n         ages.clear();\n     }\n+    /**\n+     * Updates current_features to only include a subset of the\n+     * original features which give a good spread throughout the image.\n+     * @param image: only use for getting dimension of the image\n+     * @param current_features: All features currently in the bucket.\n+     * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n+     * @param features_per_bucket: number of selected features per bucket\n+     */\n+    void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n+                           int bucket_size, int features_per_bucket);\n };\n \n class Bucket {\n   private:\n@@ -121,18 +132,8 @@\n                           std::vector<cv::Point2f>& points_r_1,\n                           std::vector<cv::Point2f>& points_l_0_return,\n                           FeatureSet& current_features);\n     /**\n-     * Updates current_features to only include a subset of the\n-     * original features which give a good spread throughout the image.\n-     * @param image: only use for getting dimension of the image\n-     * @param current_features: All features currently in the bucket.\n-     * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n-     * @param features_per_bucket: number of selected features per bucket\n-     */\n-    void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n-                           int bucket_size, int features_per_bucket);\n-    /**\n      * Input: 4 images and the set of currently tracked features, as\n      * well as references to 4 vectors of points (by reference).\n      * @return: vectors of features shared between the 4 images.\n      */\n"
                },
                {
                    "date": 1645283977153,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,13 +59,13 @@\n     /**\n      * Updates current_features to only include a subset of the\n      * original features which give a good spread throughout the image.\n      * @param image: only use for getting dimension of the image\n-     * @param current_features: All features currently in the bucket.\n+     * @param c\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n-    void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n+    void bucketFeatures(cv::Mat& image, FeatureSet& current_features,\n                            int bucket_size, int features_per_bucket);\n };\n \n class Bucket {\n"
                },
                {
                    "date": 1645283983406,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,13 +59,12 @@\n     /**\n      * Updates current_features to only include a subset of the\n      * original features which give a good spread throughout the image.\n      * @param image: only use for getting dimension of the image\n-     * @param c\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n-    void bucketFeatures(cv::Mat& image, FeatureSet& current_features,\n+    void bucketFeatures(cv::Mat& image,\n                            int bucket_size, int features_per_bucket);\n };\n \n class Bucket {\n"
                },
                {
                    "date": 1645283991656,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,16 +56,15 @@\n         points.clear();\n         ages.clear();\n     }\n     /**\n-     * Updates current_features to only include a subset of the\n+     * Updates the feature set to only include a subset of the\n      * original features which give a good spread throughout the image.\n      * @param image: only use for getting dimension of the image\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n-    void bucketFeatures(cv::Mat& image,\n-                           int bucket_size, int features_per_bucket);\n+    void bucketFeatures(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n \n class Bucket {\n   private:\n"
                },
                {
                    "date": 1645284089541,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,10 +66,8 @@\n     void bucketFeatures(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n \n class Bucket {\n-  private:\n-    int AGE_THRESHOLD = 10;\n   public:\n     int id;\n     int max_size;\n \n"
                },
                {
                    "date": 1645284149639,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,12 +51,8 @@\n     std::vector<int> ages;\n     int size() {\n         return points.size();\n     }\n-    void clear() {\n-        points.clear();\n-        ages.clear();\n-    }\n     /**\n      * Updates the feature set to only include a subset of the\n      * original features which give a good spread throughout the image.\n      * @param image: only use for getting dimension of the image\n"
                },
                {
                    "date": 1645288138864,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,8 @@\n     Bucket(int);\n     ~Bucket();\n \n     void add_feature(cv::Point2f, int);\n-    void get_features(FeatureSet&);\n \n     int size();\n };\n \n"
                },
                {
                    "date": 1645288636823,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,8 +42,24 @@\n }\n \n namespace visual_odometry {\n \n+\n+class Bucket {\n+  public:\n+    int id;\n+    int max_size;\n+\n+    FeatureSet features;\n+\n+    Bucket(int);\n+    ~Bucket();\n+\n+    void add_feature(cv::Point2f, int);\n+\n+    int size();\n+};\n+\n class FeatureSet {\n   private:\n     int AGE_THRESHOLD = 10;\n   public:\n@@ -58,26 +74,11 @@\n      * @param image: only use for getting dimension of the image\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n+ \n     void bucketFeatures(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n-\n-class Bucket {\n-  public:\n-    int id;\n-    int max_size;\n-\n-    FeatureSet features;\n-\n-    Bucket(int);\n-    ~Bucket();\n-\n-    void add_feature(cv::Point2f, int);\n-\n-    int size();\n-};\n-\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n     int frame_id = 0;\n"
                },
                {
                    "date": 1645288703623,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n  \n-    void bucketFeatures(cv::Mat& image, int bucket_size, int features_per_bucket);\n+    void filterByBucket(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n"
                },
                {
                    "date": 1645288907503,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,10 +75,15 @@\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n  \n-    void filterByBucket(cv::Mat& image, int bucket_size, int features_per_bucket);\n+    void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n+/**\n+ * @brief If we have more than this many features, then we won't\n+ * use the matching to look for more.\n+ */\n+  int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n     int frame_id = 0;\n"
                },
                {
                    "date": 1645288984538,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,8 +41,18 @@\n #include \"pe_events.h\"\n }\n \n namespace visual_odometry {\n+/**\n+ * @brief Ignore all features that have been around for 10 frames\n+ * \n+ */\n+int AGE_THRESHOLD = 10;\n+/**\n+ * @brief If we have more than this many features, then we won't\n+ * use the matching to look for more.\n+ */\n+int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n \n \n class Bucket {\n   public:\n@@ -60,9 +70,8 @@\n };\n \n class FeatureSet {\n   private:\n-    int AGE_THRESHOLD = 10;\n   public:\n     std::vector<cv::Point2f> points;\n     std::vector<int> ages;\n     int size() {\n@@ -77,13 +86,8 @@\n      */\n  \n     void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n };\n-/**\n- * @brief If we have more than this many features, then we won't\n- * use the matching to look for more.\n- */\n-  int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n     int frame_id = 0;\n@@ -106,9 +110,33 @@\n \n \n     void run();\n \n+\n+   public:\n+   /**\n+    * @brief Construct a new Visual Odometry object\n+    * \n+    * @param ProjMatrl Left camera parameter matrix\n+    * @param projMatrr Right camera parameter matrix\n+    */\n+    VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n+\n+    ~VisualOdometry();\n+\n     /**\n+     * @brief Process one time step of camera imagery and\n+     * publish the result.\n+     * \n+     * @param image_left The left image from stereo camera\n+     * @param image_right The right image from stereo camera\n+     */\n+    void stereo_callback(const cv::Mat& image_left,\n+                         const cv::Mat& image_right);\n+};\n+}   // namespace visual_odometry\n+\n+    /**\n      *  Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      */\n     void featureDetectionFast(cv::Mat image, std::vector<cv::Point2f>& points);\n@@ -154,28 +182,5 @@\n                              const std::vector<bool>& status);\n     void trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n                              std::vector<cv::Point2f>& pointsLeft_T1,\n                              cv::Mat& points3D_T0, cv::Mat& rotation,\n-                             cv::Mat& translation, bool mono_rotation);\n-\n-   public:\n-   /**\n-    * @brief Construct a new Visual Odometry object\n-    * \n-    * @param ProjMatrl Left camera parameter matrix\n-    * @param projMatrr Right camera parameter matrix\n-    */\n-    VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n-\n-    ~VisualOdometry();\n-\n-    /**\n-     * @brief Process one time step of camera imagery and\n-     * publish the result.\n-     * \n-     * @param image_left The left image from stereo camera\n-     * @param image_right The right image from stereo camera\n-     */\n-    void stereo_callback(const cv::Mat& image_left,\n-                         const cv::Mat& image_right);\n-};\n-}   // namespace visual_odometry\n+                             cv::Mat& translation, bool mono_rotation);\n\\ No newline at end of file\n"
                },
                {
                    "date": 1645288996619,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,10 +42,10 @@\n }\n \n namespace visual_odometry {\n /**\n- * @brief Ignore all features that have been around for 10 frames\n- * \n+ * @brief Ignore all features that have been around but not detected\n+ * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n /**\n  * @brief If we have more than this many features, then we won't\n"
                },
                {
                    "date": 1645289020604,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,8 @@\n     int size();\n };\n \n class FeatureSet {\n-  private:\n   public:\n     std::vector<cv::Point2f> points;\n     std::vector<int> ages;\n     int size() {\n"
                },
                {
                    "date": 1645289077237,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,8 +42,12 @@\n }\n \n namespace visual_odometry {\n /**\n+ * @brief Maximum number of features per bucket\n+ */\n+int FEATURES_PER_BUCKET = 1;\n+/**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n"
                },
                {
                    "date": 1645289200095,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,8 +42,14 @@\n }\n \n namespace visual_odometry {\n /**\n+ * @brief Number of buckets along each axis of the image.\n+ * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n+ * buckets.\n+ */\n+int BUCKETS_PER_AXIS = 10\n+/**\n  * @brief Maximum number of features per bucket\n  */\n int FEATURES_PER_BUCKET = 1;\n /**\n"
                },
                {
                    "date": 1645289251032,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,8 +59,9 @@\n int AGE_THRESHOLD = 10;\n /**\n  * @brief If we have more than this many features, then we won't\n  * use the matching to look for more.\n+ * Doesn't do much if more than BUCKETS_PER_AXIS^2 * FEATURES_PER_BUCKET + AGE_THRESHOLD\n  */\n int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n \n \n"
                },
                {
                    "date": 1645289283591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,14 +56,8 @@\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n-/**\n- * @brief If we have more than this many features, then we won't\n- * use the matching to look for more.\n- * Doesn't do much if more than BUCKETS_PER_AXIS^2 * FEATURES_PER_BUCKET + AGE_THRESHOLD\n- */\n-int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n \n \n class Bucket {\n   public:\n"
                },
                {
                    "date": 1645289344601,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,8 +56,14 @@\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n+/**\n+ * @brief If we have more than this many features, then we won't\n+ * use the matching to look for more.\n+ * Doesn't do much if more than BUCKETS_PER_AXIS^2 * FEATURES_PER_BUCKET + AGE_THRESHOLD\n+ */\n+int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n \n \n class Bucket {\n   public:\n"
                },
                {
                    "date": 1645289544922,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,14 +56,8 @@\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n-/**\n- * @brief If we have more than this many features, then we won't\n- * use the matching to look for more.\n- * Doesn't do much if more than BUCKETS_PER_AXIS^2 * FEATURES_PER_BUCKET + AGE_THRESHOLD\n- */\n-int MAX_FEATURES_TO_RUN_MATCHING = 2000;\n \n \n class Bucket {\n   public:\n"
                },
                {
                    "date": 1645289621803,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,8 +89,15 @@\n      * @param features_per_bucket: number of selected features per bucket\n      */\n  \n     void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n+    /**\n+     * @brief \n+     * \n+     * @param image \n+     * @param current_features \n+     */\n+    void appendFeaturesFromImage(cv::Mat& image);\n };\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n@@ -172,9 +179,8 @@\n                           std::vector<cv::Point2f>& pointsLeftT0,\n                           std::vector<cv::Point2f>& pointsRightT0,\n                           std::vector<cv::Point2f>& pointsLeftT1,\n                           std::vector<cv::Point2f>& pointsRightT1);\n-    void appendNewFeatures(cv::Mat& image, FeatureSet& current_features);\n     void integrateOdometryStereo(int frame_i, cv::Mat& frame_pose,\n                                  const cv::Mat& rotation,\n                                  const cv::Mat& translation_stereo);\n     bool isRotationMatrix(cv::Mat& R);\n"
                },
                {
                    "date": 1645289659394,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -90,12 +90,12 @@\n      */\n  \n     void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n     /**\n-     * @brief \n+     * @brief Apply a feature detection algorithm over the image to generate new\n+     * features, and all all such features into this feature set.\n      * \n      * @param image \n-     * @param current_features \n      */\n     void appendFeaturesFromImage(cv::Mat& image);\n };\n class VisualOdometry {\n"
                },
                {
                    "date": 1645289776062,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,8 +89,9 @@\n      * @param features_per_bucket: number of selected features per bucket\n      */\n  \n     void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n+\n     /**\n      * @brief Apply a feature detection algorithm over the image to generate new\n      * features, and all all such features into this feature set.\n      * \n"
                },
                {
                    "date": 1645289913779,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -183,9 +183,8 @@\n                           std::vector<cv::Point2f>& pointsRightT1);\n     void integrateOdometryStereo(int frame_i, cv::Mat& frame_pose,\n                                  const cv::Mat& rotation,\n                                  const cv::Mat& translation_stereo);\n-    bool isRotationMatrix(cv::Mat& R);\n     cv::Vec3f rotationMatrixToEulerAngles(cv::Mat& R);\n     void checkValidMatch(std::vector<cv::Point2f>& points,\n                          std::vector<cv::Point2f>& points_return,\n                          std::vector<bool>& status, int threshold);\n"
                },
                {
                    "date": 1645290088322,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -96,9 +96,9 @@\n      * features, and all all such features into this feature set.\n      * \n      * @param image \n      */\n-    void appendFeaturesFromImage(cv::Mat& image);\n+    void appendFeaturesFromImage(const cv::Mat& image);\n };\n class VisualOdometry {\n    private:\n     /* number of frames seen so far. */\n"
                },
                {
                    "date": 1645290098277,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,9 +88,9 @@\n      * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n      * @param features_per_bucket: number of selected features per bucket\n      */\n  \n-    void filterByBucketLocation(cv::Mat& image, int bucket_size, int features_per_bucket);\n+    void filterByBucketLocation(const cv::Mat& image, const int bucket_size, const int features_per_bucket);\n \n     /**\n      * @brief Apply a feature detection algorithm over the image to generate new\n      * features, and all all such features into this feature set.\n"
                },
                {
                    "date": 1645290119538,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n \n     Bucket(int);\n     ~Bucket();\n \n-    void add_feature(cv::Point2f, int);\n+    void add_feature(const cv::Point2f point, const int age);\n \n     int size();\n };\n \n"
                },
                {
                    "date": 1645290130103,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -130,9 +130,9 @@\n     * \n     * @param ProjMatrl Left camera parameter matrix\n     * @param projMatrr Right camera parameter matrix\n     */\n-    VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n+    VisualOdometry(const cv::Mat ProjMatrl, const cv::Mat projMatrr);\n \n     ~VisualOdometry();\n \n     /**\n"
                },
                {
                    "date": 1645290135371,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,9 +150,9 @@\n     /**\n      *  Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      */\n-    void featureDetectionFast(cv::Mat image, std::vector<cv::Point2f>& points);\n+    void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f>& points);\n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n         std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n         std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n"
                },
                {
                    "date": 1645290443820,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,9 +116,9 @@\n     cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n     cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n \n-    // set of features currently tracked\n+    // Set of features currently tracked.\n     FeatureSet currentVOFeatures;\n \n \n     void run();\n"
                },
                {
                    "date": 1645290450589,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,9 +116,9 @@\n     cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n     cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n \n-    // Set of features currently tracked.\n+    /* Set of features currently tracked. */\n     FeatureSet currentVOFeatures;\n \n \n     void run();\n"
                },
                {
                    "date": 1645290457430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n };\n }   // namespace visual_odometry\n \n     /**\n-     *  Use the FAST feature detector to accumulate the features in image into\n+     *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      */\n     void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f>& points);\n     void deleteUnmatchFeaturesCircle(\n"
                },
                {
                    "date": 1645290492308,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,8 +149,10 @@\n \n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n+     * @param image Image we're detecting features and their location from\n+     * @param points vector to output the location of detected features into.\n      */\n     void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f>& points);\n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n"
                },
                {
                    "date": 1645290645257,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -152,9 +152,9 @@\n      *  points.\n      * @param image Image we're detecting features and their location from\n      * @param points vector to output the location of detected features into.\n      */\n-    void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f>& points);\n+    std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n         std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n         std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n"
                },
                {
                    "date": 1645290727491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,9 +150,8 @@\n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      * @param image Image we're detecting features and their location from\n-     * @param points vector to output the location of detected features into.\n      */\n     std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n"
                },
                {
                    "date": 1645290771541,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -152,8 +152,9 @@\n      *  points.\n      * @param image Image we're detecting features and their location from\n      */\n     std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n+\n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n         std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n         std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n"
                },
                {
                    "date": 1645290786317,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,9 +149,10 @@\n \n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n-     * @param image Image we're detecting features and their location from\n+     * @param image Image we're detecting.\n+     * @return A vector with the locations of all newly detected features.\n      */\n     std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n     void deleteUnmatchFeaturesCircle(\n"
                },
                {
                    "date": 1645290791769,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,9 +149,9 @@\n \n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n-     * @param image Image we're detecting.\n+     * @param image The image we're detecting.\n      * @return A vector with the locations of all newly detected features.\n      */\n     std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n"
                },
                {
                    "date": 1645291793911,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,11 +150,11 @@\n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n      * @param image The image we're detecting.\n-     * @return A vector with the locations of all newly detected features.\n+     * @param points A vector with the locations of all newly detected features.\n      */\n-    std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n+    void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f> points) {\n \n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n         std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n"
                },
                {
                    "date": 1645291808672,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,9 +144,8 @@\n      */\n     void stereo_callback(const cv::Mat& image_left,\n                          const cv::Mat& image_right);\n };\n-}   // namespace visual_odometry\n \n     /**\n      *  @brief Use the FAST feature detector to accumulate the features in image into\n      *  points.\n@@ -195,5 +194,7 @@\n                              const std::vector<bool>& status);\n     void trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n                              std::vector<cv::Point2f>& pointsLeft_T1,\n                              cv::Mat& points3D_T0, cv::Mat& rotation,\n-                             cv::Mat& translation, bool mono_rotation);\n\\ No newline at end of file\n+                             cv::Mat& translation, bool mono_rotation);\n+\n+}   // namespace visual_odometry\n\\ No newline at end of file\n"
                },
                {
                    "date": 1645291826089,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,9 +160,9 @@\n         std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n         std::vector<uchar>& status1, std::vector<uchar>& status2,\n         std::vector<uchar>& status3, std::vector<int>& ages);\n     /**\n-     * Detect points not found in both cameras for both the previous and current\n+     * @brief Detect points not found in both cameras for both the previous and current\n      * frame and remove them.\n      */\n     void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n                           cv::Mat img_r_1, std::vector<cv::Point2f>& points_l_0,\n"
                },
                {
                    "date": 1645291856367,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -146,10 +146,10 @@\n                          const cv::Mat& image_right);\n };\n \n     /**\n-     *  @brief Use the FAST feature detector to accumulate the features in image into\n-     *  points.\n+     * @brief Use the FAST feature detector to accumulate the features in image into\n+     * points.\n      * @param image The image we're detecting.\n      * @param points A vector with the locations of all newly detected features.\n      */\n     void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f> points) {\n@@ -185,8 +185,14 @@\n                           std::vector<cv::Point2f>& pointsRightT1);\n     void integrateOdometryStereo(int frame_i, cv::Mat& frame_pose,\n                                  const cv::Mat& rotation,\n                                  const cv::Mat& translation_stereo);\n+    /**\n+     * @brief Compute the three euler angles for a given rotation matrix\n+     * \n+     * @param R \n+     * @return cv::Vec3f Euler angles for \n+     */\n     cv::Vec3f rotationMatrixToEulerAngles(cv::Mat& R);\n     void checkValidMatch(std::vector<cv::Point2f>& points,\n                          std::vector<cv::Point2f>& points_return,\n                          std::vector<bool>& status, int threshold);\n"
                },
                {
                    "date": 1645291893668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -188,10 +188,10 @@\n                                  const cv::Mat& translation_stereo);\n     /**\n      * @brief Compute the three euler angles for a given rotation matrix\n      * \n-     * @param R \n-     * @return cv::Vec3f Euler angles for \n+     * @param R A rotation matrix\n+     * @return cv::Vec3f (x, y, z) euler angles for R\n      */\n     cv::Vec3f rotationMatrixToEulerAngles(cv::Mat& R);\n     void checkValidMatch(std::vector<cv::Point2f>& points,\n                          std::vector<cv::Point2f>& points_return,\n"
                },
                {
                    "date": 1645292283962,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,11 +149,11 @@\n     /**\n      * @brief Use the FAST feature detector to accumulate the features in image into\n      * points.\n      * @param image The image we're detecting.\n-     * @param points A vector with the locations of all newly detected features.\n+     * @return A vector with the locations of all newly detected features.\n      */\n-    void featureDetectionFast(const cv::Mat image, std::vector<cv::Point2f> points) {\n+    void featureDetectionFast(const cv::Mat image) {\n \n     void deleteUnmatchFeaturesCircle(\n         std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n         std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n@@ -191,9 +191,9 @@\n      * \n      * @param R A rotation matrix\n      * @return cv::Vec3f (x, y, z) euler angles for R\n      */\n-    cv::Vec3f rotationMatrixToEulerAngles(cv::Mat& R);\n+    cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat& R);\n     void checkValidMatch(std::vector<cv::Point2f>& points,\n                          std::vector<cv::Point2f>& points_return,\n                          std::vector<bool>& status, int threshold);\n     void removeInvalidPoints(std::vector<cv::Point2f>& points,\n"
                },
                {
                    "date": 1645292387129,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -152,15 +152,28 @@\n      * @param image The image we're detecting.\n      * @return A vector with the locations of all newly detected features.\n      */\n     void featureDetectionFast(const cv::Mat image) {\n-\n-    void deleteUnmatchFeaturesCircle(\n-        std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n-        std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n-        std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n-        std::vector<uchar>& status1, std::vector<uchar>& status2,\n-        std::vector<uchar>& status3, std::vector<int>& ages);\n+      /**\n+       * @brief \n+       * \n+       * @param points0 \n+       * @param points1 \n+       * @param points2 \n+       * @param points3 \n+       * @param points0_return \n+       * @param status0 \n+       * @param status1 \n+       * @param status2 \n+       * @param status3 \n+       * @param ages \n+       */\n+  void deleteUnmatchFeaturesCircle(\n+      std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n+      std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n+      std::vector<cv::Point2f> & points0_return, const std::vector<uchar> & status0,\n+      const std::vector<uchar> & status1, const std::vector<uchar> & status2,\n+      const std::vector<uchar> & status3, std::vector<int> & ages) {\n     /**\n      * @brief Detect points not found in both cameras for both the previous and current\n      * frame and remove them.\n      */\n"
                },
                {
                    "date": 1645292439978,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,10 @@\n      * @return A vector with the locations of all newly detected features.\n      */\n     void featureDetectionFast(const cv::Mat image) {\n       /**\n-       * @brief \n+       * @brief Remove all points from the 4 points vectors that are out of frame\n+       * or have a bad status\n        * \n        * @param points0 \n        * @param points1 \n        * @param points2 \n"
                },
                {
                    "date": 1645292454978,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,9 +154,9 @@\n      */\n     void featureDetectionFast(const cv::Mat image) {\n       /**\n        * @brief Remove all points from the 4 points vectors that are out of frame\n-       * or have a bad status\n+       * or have a status of 0\n        * \n        * @param points0 \n        * @param points1 \n        * @param points2 \n"
                },
                {
                    "date": 1645292551443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -161,12 +161,9 @@\n        * @param points1 \n        * @param points2 \n        * @param points3 \n        * @param points0_return \n-       * @param status0 \n-       * @param status1 \n-       * @param status2 \n-       * @param status3 \n+       * @param status[0..3] Status of the each vector\n        * @param ages \n        */\n   void deleteUnmatchFeaturesCircle(\n       std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n"
                },
                {
                    "date": 1645292564116,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -156,12 +156,9 @@\n       /**\n        * @brief Remove all points from the 4 points vectors that are out of frame\n        * or have a status of 0\n        * \n-       * @param points0 \n-       * @param points1 \n-       * @param points2 \n-       * @param points3 \n+       * @param points[0..3] locations of detected features \n        * @param points0_return \n        * @param status[0..3] Status of the each vector\n        * @param ages \n        */\n"
                },
                {
                    "date": 1645293414073,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,168 +47,165 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n int BUCKETS_PER_AXIS = 10\n+    /**\n+     * @brief Maximum number of features per bucket\n+     */\n+    int FEATURES_PER_BUCKET = 1;\n /**\n- * @brief Maximum number of features per bucket\n- */\n-int FEATURES_PER_BUCKET = 1;\n-/**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n \n-\n class Bucket {\n-  public:\n-    int id;\n-    int max_size;\n+public:\n+  int id;\n+  int max_size;\n \n-    FeatureSet features;\n+  FeatureSet features;\n \n-    Bucket(int);\n-    ~Bucket();\n+  Bucket(int);\n+  ~Bucket();\n \n-    void add_feature(const cv::Point2f point, const int age);\n+  void add_feature(const cv::Point2f point, const int age);\n \n-    int size();\n+  int size();\n };\n \n class FeatureSet {\n-  public:\n-    std::vector<cv::Point2f> points;\n-    std::vector<int> ages;\n-    int size() {\n-        return points.size();\n-    }\n-    /**\n-     * Updates the feature set to only include a subset of the\n-     * original features which give a good spread throughout the image.\n-     * @param image: only use for getting dimension of the image\n-     * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n-     * @param features_per_bucket: number of selected features per bucket\n-     */\n- \n-    void filterByBucketLocation(const cv::Mat& image, const int bucket_size, const int features_per_bucket);\n+public:\n+  std::vector<cv::Point2f> points;\n+  std::vector<int> ages;\n+  int size() { return points.size(); }\n+  /**\n+   * Updates the feature set to only include a subset of the\n+   * original features which give a good spread throughout the image.\n+   * @param image: only use for getting dimension of the image\n+   * @param bucket_size: bucket size in pixel is bucket_size*bucket_size\n+   * @param features_per_bucket: number of selected features per bucket\n+   */\n \n-    /**\n-     * @brief Apply a feature detection algorithm over the image to generate new\n-     * features, and all all such features into this feature set.\n-     * \n-     * @param image \n-     */\n-    void appendFeaturesFromImage(const cv::Mat& image);\n+  void filterByBucketLocation(const cv::Mat &image, const int bucket_size,\n+                              const int features_per_bucket);\n+\n+  /**\n+   * @brief Apply a feature detection algorithm over the image to generate new\n+   * features, and all all such features into this feature set.\n+   *\n+   * @param image\n+   */\n+  void appendFeaturesFromImage(const cv::Mat &image);\n };\n class VisualOdometry {\n-   private:\n-    /* number of frames seen so far. */\n-    int frame_id = 0;\n-    /* Projection matrices for the left and right cameras */\n-    cv::Mat leftCameraProjection_, rightCameraProjection_;\n+private:\n+  /* number of frames seen so far. */\n+  int frame_id = 0;\n+  /* Projection matrices for the left and right cameras */\n+  cv::Mat leftCameraProjection_, rightCameraProjection_;\n \n-    /* Images at current and next time step */\n-    cv::Mat imageRightT0_, imageLeftT0_;\n-    cv::Mat imageRightT1_, imageLeftT1_;\n+  /* Images at current and next time step */\n+  cv::Mat imageRightT0_, imageLeftT0_;\n+  cv::Mat imageRightT1_, imageLeftT1_;\n \n-    /* Initial pose variables */\n-    cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n-    cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n-    cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n+  /* Initial pose variables */\n+  cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n+  cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n+  cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n-    cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n+  cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n \n-    /* Set of features currently tracked. */\n-    FeatureSet currentVOFeatures;\n+  /* Set of features currently tracked. */\n+  FeatureSet currentVOFeatures;\n \n+  void run();\n \n-    void run();\n+public:\n+  /**\n+   * @brief Construct a new Visual Odometry object\n+   *\n+   * @param ProjMatrl Left camera parameter matrix\n+   * @param projMatrr Right camera parameter matrix\n+   */\n+  VisualOdometry(const cv::Mat ProjMatrl, const cv::Mat projMatrr);\n \n+  ~VisualOdometry();\n \n-   public:\n-   /**\n-    * @brief Construct a new Visual Odometry object\n-    * \n-    * @param ProjMatrl Left camera parameter matrix\n-    * @param projMatrr Right camera parameter matrix\n-    */\n-    VisualOdometry(const cv::Mat ProjMatrl, const cv::Mat projMatrr);\n-\n-    ~VisualOdometry();\n-\n-    /**\n-     * @brief Process one time step of camera imagery and\n-     * publish the result.\n-     * \n-     * @param image_left The left image from stereo camera\n-     * @param image_right The right image from stereo camera\n-     */\n-    void stereo_callback(const cv::Mat& image_left,\n-                         const cv::Mat& image_right);\n+  /**\n+   * @brief Process one time step of camera imagery and\n+   * publish the result.\n+   *\n+   * @param image_left The left image from stereo camera\n+   * @param image_right The right image from stereo camera\n+   */\n+  void stereo_callback(const cv::Mat &image_left, const cv::Mat &image_right);\n };\n \n\\ No newline at end of file\n-    /**\n-     * @brief Use the FAST feature detector to accumulate the features in image into\n-     * points.\n-     * @param image The image we're detecting.\n-     * @return A vector with the locations of all newly detected features.\n-     */\n-    void featureDetectionFast(const cv::Mat image) {\n-      /**\n-       * @brief Remove all points from the 4 points vectors that are out of frame\n-       * or have a status of 0\n-       * \n-       * @param points[0..3] locations of detected features \n-       * @param points0_return \n-       * @param status[0..3] Status of the each vector\n-       * @param ages \n-       */\n+/**\n+ * @brief Use the FAST feature detector to accumulate the features in image into\n+ * points.\n+ * @param image The image we're detecting.\n+ * @return A vector with the locations of all newly detected features.\n+ */\n+void featureDetectionFast(const cv::Mat image) {\n+  /**\n+   * @brief Remove all points from the 4 point vectors that are out of frame\n+   * or have a status of 0\n+   *\n+   * @param points[0..3] locations of detected features\n+   * @param points0_return\n+   * @param status[0..3] Status of the each vector\n+   * @param ages Current ages of each of the points\n+   */\n   void deleteUnmatchFeaturesCircle(\n       std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n       std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n-      std::vector<cv::Point2f> & points0_return, const std::vector<uchar> & status0,\n-      const std::vector<uchar> & status1, const std::vector<uchar> & status2,\n-      const std::vector<uchar> & status3, std::vector<int> & ages) {\n+      std::vector<cv::Point2f> & points0_return,\n+      const std::vector<uchar> &status0, const std::vector<uchar> &status1,\n+      const std::vector<uchar> &status2, const std::vector<uchar> &status3,\n+      std::vector<int> &ages) {\n     /**\n-     * @brief Detect points not found in both cameras for both the previous and current\n-     * frame and remove them.\n+     * @brief Detect points not found in both cameras for both the previous and\n+     * current frame and remove them.\n      */\n     void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n-                          cv::Mat img_r_1, std::vector<cv::Point2f>& points_l_0,\n-                          std::vector<cv::Point2f>& points_r_0,\n-                          std::vector<cv::Point2f>& points_l_1,\n-                          std::vector<cv::Point2f>& points_r_1,\n-                          std::vector<cv::Point2f>& points_l_0_return,\n-                          FeatureSet& current_features);\n+                          cv::Mat img_r_1,\n+                          std::vector<cv::Point2f> & points_l_0,\n+                          std::vector<cv::Point2f> & points_r_0,\n+                          std::vector<cv::Point2f> & points_l_1,\n+                          std::vector<cv::Point2f> & points_r_1,\n+                          std::vector<cv::Point2f> & points_l_0_return,\n+                          FeatureSet & current_features);\n     /**\n      * Input: 4 images and the set of currently tracked features, as\n      * well as references to 4 vectors of points (by reference).\n      * @return: vectors of features shared between the 4 images.\n      */\n-    void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n-                          cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n-                          FeatureSet& currentVOFeatures,\n-                          std::vector<cv::Point2f>& pointsLeftT0,\n-                          std::vector<cv::Point2f>& pointsRightT0,\n-                          std::vector<cv::Point2f>& pointsLeftT1,\n-                          std::vector<cv::Point2f>& pointsRightT1);\n-    void integrateOdometryStereo(int frame_i, cv::Mat& frame_pose,\n-                                 const cv::Mat& rotation,\n-                                 const cv::Mat& translation_stereo);\n+    void matchingFeatures(cv::Mat & imageLeftT0, cv::Mat & imageRightT0,\n+                          cv::Mat & imageLeftT1, cv::Mat & imageRightT1,\n+                          FeatureSet & currentVOFeatures,\n+                          std::vector<cv::Point2f> & pointsLeftT0,\n+                          std::vector<cv::Point2f> & pointsRightT0,\n+                          std::vector<cv::Point2f> & pointsLeftT1,\n+                          std::vector<cv::Point2f> & pointsRightT1);\n+    void integrateOdometryStereo(int frame_i, cv::Mat &frame_pose,\n+                                 const cv::Mat &rotation,\n+                                 const cv::Mat &translation_stereo);\n     /**\n      * @brief Compute the three euler angles for a given rotation matrix\n-     * \n+     *\n      * @param R A rotation matrix\n      * @return cv::Vec3f (x, y, z) euler angles for R\n      */\n-    cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat& R);\n-    void checkValidMatch(std::vector<cv::Point2f>& points,\n-                         std::vector<cv::Point2f>& points_return,\n-                         std::vector<bool>& status, int threshold);\n-    void removeInvalidPoints(std::vector<cv::Point2f>& points,\n-                             const std::vector<bool>& status);\n-    void trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n-                             std::vector<cv::Point2f>& pointsLeft_T1,\n-                             cv::Mat& points3D_T0, cv::Mat& rotation,\n-                             cv::Mat& translation, bool mono_rotation);\n+    cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n+    void checkValidMatch(std::vector<cv::Point2f> & points,\n+                         std::vector<cv::Point2f> & points_return,\n+                         std::vector<bool> & status, int threshold);\n+    void removeInvalidPoints(std::vector<cv::Point2f> & points,\n+                             const std::vector<bool> &status);\n+    void trackingFrame2Frame(cv::Mat & projMatrl, cv::Mat & projMatrr,\n+                             std::vector<cv::Point2f> & pointsLeft_T1,\n+                             cv::Mat & points3D_T0, cv::Mat & rotation,\n+                             cv::Mat & translation, bool mono_rotation);\n \n-}   // namespace visual_odometry\n+  } // namespace visual_odometry\n\\ No newline at end of file\n"
                },
                {
                    "date": 1645293421794,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -146,9 +146,9 @@\n  * points.\n  * @param image The image we're detecting.\n  * @return A vector with the locations of all newly detected features.\n  */\n-void featureDetectionFast(const cv::Mat image) {\n+void featureDetectionFast(const cv::Mat image);\n   /**\n    * @brief Remove all points from the 4 point vectors that are out of frame\n    * or have a status of 0\n    *\n@@ -162,9 +162,9 @@\n       std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n       std::vector<cv::Point2f> & points0_return,\n       const std::vector<uchar> &status0, const std::vector<uchar> &status1,\n       const std::vector<uchar> &status2, const std::vector<uchar> &status3,\n-      std::vector<int> &ages) {\n+      std::vector<int> &ages);\n     /**\n      * @brief Detect points not found in both cameras for both the previous and\n      * current frame and remove them.\n      */\n"
                },
                {
                    "date": 1645293434753,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,65 +147,62 @@\n  * @param image The image we're detecting.\n  * @return A vector with the locations of all newly detected features.\n  */\n void featureDetectionFast(const cv::Mat image);\n-  /**\n-   * @brief Remove all points from the 4 point vectors that are out of frame\n-   * or have a status of 0\n-   *\n-   * @param points[0..3] locations of detected features\n-   * @param points0_return\n-   * @param status[0..3] Status of the each vector\n-   * @param ages Current ages of each of the points\n-   */\n-  void deleteUnmatchFeaturesCircle(\n-      std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n-      std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n-      std::vector<cv::Point2f> & points0_return,\n-      const std::vector<uchar> &status0, const std::vector<uchar> &status1,\n-      const std::vector<uchar> &status2, const std::vector<uchar> &status3,\n-      std::vector<int> &ages);\n-    /**\n-     * @brief Detect points not found in both cameras for both the previous and\n-     * current frame and remove them.\n-     */\n-    void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n-                          cv::Mat img_r_1,\n-                          std::vector<cv::Point2f> & points_l_0,\n-                          std::vector<cv::Point2f> & points_r_0,\n-                          std::vector<cv::Point2f> & points_l_1,\n-                          std::vector<cv::Point2f> & points_r_1,\n-                          std::vector<cv::Point2f> & points_l_0_return,\n-                          FeatureSet & current_features);\n-    /**\n-     * Input: 4 images and the set of currently tracked features, as\n-     * well as references to 4 vectors of points (by reference).\n-     * @return: vectors of features shared between the 4 images.\n-     */\n-    void matchingFeatures(cv::Mat & imageLeftT0, cv::Mat & imageRightT0,\n-                          cv::Mat & imageLeftT1, cv::Mat & imageRightT1,\n-                          FeatureSet & currentVOFeatures,\n-                          std::vector<cv::Point2f> & pointsLeftT0,\n-                          std::vector<cv::Point2f> & pointsRightT0,\n-                          std::vector<cv::Point2f> & pointsLeftT1,\n-                          std::vector<cv::Point2f> & pointsRightT1);\n-    void integrateOdometryStereo(int frame_i, cv::Mat &frame_pose,\n-                                 const cv::Mat &rotation,\n-                                 const cv::Mat &translation_stereo);\n-    /**\n-     * @brief Compute the three euler angles for a given rotation matrix\n-     *\n-     * @param R A rotation matrix\n-     * @return cv::Vec3f (x, y, z) euler angles for R\n-     */\n-    cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n-    void checkValidMatch(std::vector<cv::Point2f> & points,\n-                         std::vector<cv::Point2f> & points_return,\n-                         std::vector<bool> & status, int threshold);\n-    void removeInvalidPoints(std::vector<cv::Point2f> & points,\n-                             const std::vector<bool> &status);\n-    void trackingFrame2Frame(cv::Mat & projMatrl, cv::Mat & projMatrr,\n-                             std::vector<cv::Point2f> & pointsLeft_T1,\n-                             cv::Mat & points3D_T0, cv::Mat & rotation,\n-                             cv::Mat & translation, bool mono_rotation);\n+/**\n+ * @brief Remove all points from the 4 point vectors that are out of frame\n\\ No newline at end of file\n+ * or have a status of 0\n+ *\n+ * @param points[0..3] locations of detected features\n+ * @param points0_return\n+ * @param status[0..3] Status of the each vector\n+ * @param ages Current ages of each of the points\n+ */\n+void deleteUnmatchFeaturesCircle(\n+    std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n+    std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n+    std::vector<cv::Point2f> &points0_return, const std::vector<uchar> &status_all,\n+    std::vector<int> &ages);\n+/**\n+ * @brief Detect points not found in both cameras for both the previous and\n+ * current frame and remove them.\n+ */\n+void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n+                      cv::Mat img_r_1, std::vector<cv::Point2f> &points_l_0,\n+                      std::vector<cv::Point2f> &points_r_0,\n+                      std::vector<cv::Point2f> &points_l_1,\n+                      std::vector<cv::Point2f> &points_r_1,\n+                      std::vector<cv::Point2f> &points_l_0_return,\n+                      FeatureSet &current_features);\n+/**\n+ * Input: 4 images and the set of currently tracked features, as\n+ * well as references to 4 vectors of points (by reference).\n+ * @return: vectors of features shared between the 4 images.\n+ */\n+void matchingFeatures(cv::Mat &imageLeftT0, cv::Mat &imageRightT0,\n+                      cv::Mat &imageLeftT1, cv::Mat &imageRightT1,\n+                      FeatureSet &currentVOFeatures,\n+                      std::vector<cv::Point2f> &pointsLeftT0,\n+                      std::vector<cv::Point2f> &pointsRightT0,\n+                      std::vector<cv::Point2f> &pointsLeftT1,\n+                      std::vector<cv::Point2f> &pointsRightT1);\n+void integrateOdometryStereo(int frame_i, cv::Mat &frame_pose,\n+                             const cv::Mat &rotation,\n+                             const cv::Mat &translation_stereo);\n+/**\n+ * @brief Compute the three euler angles for a given rotation matrix\n+ *\n+ * @param R A rotation matrix\n+ * @return cv::Vec3f (x, y, z) euler angles for R\n+ */\n+cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n+void checkValidMatch(std::vector<cv::Point2f> &points,\n+                     std::vector<cv::Point2f> &points_return,\n+                     std::vector<bool> &status, int threshold);\n+void removeInvalidPoints(std::vector<cv::Point2f> &points,\n+                         const std::vector<bool> &status);\n+void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n+                         std::vector<cv::Point2f> &pointsLeft_T1,\n+                         cv::Mat &points3D_T0, cv::Mat &rotation,\n+                         cv::Mat &translation, bool mono_rotation);\n \n-  } // namespace visual_odometry\n+} // namespace visual_odometry\n\\ No newline at end of file\n"
                },
                {
                    "date": 1645293523068,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n  * or have a status of 0\n  *\n  * @param points[0..3] locations of detected features\n  * @param points0_return\n- * @param status[0..3] Status of the each vector\n+ * @param status_all 1 if the point is ok, and 0 if it is not.\n  * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n"
                },
                {
                    "date": 1645293623556,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n  * or have a status of 0\n  *\n  * @param points[0..3] locations of detected features\n  * @param points0_return\n- * @param status_all 1 if the point is ok, and 0 if it is not.\n+ * @param status_all 1 If the point is ok, and 0 if it is not.\n  * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n"
                },
                {
                    "date": 1645293631120,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n  * or have a status of 0\n  *\n  * @param points[0..3] locations of detected features\n  * @param points0_return\n- * @param status_all 1 If the point is ok, and 0 if it is not.\n+ * @param status_all a vector with 1 If the point is ok, and 0 if it is not.\n  * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n"
                },
                {
                    "date": 1645293638055,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n  * or have a status of 0\n  *\n  * @param points[0..3] locations of detected features\n  * @param points0_return\n- * @param status_all a vector with 1 If the point is ok, and 0 if it is not.\n+ * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n"
                },
                {
                    "date": 1645293718793,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,17 +151,16 @@\n /**\n  * @brief Remove all points from the 4 point vectors that are out of frame\n  * or have a status of 0\n  *\n- * @param points[0..3] locations of detected features\n- * @param points0_return\n+ * @param points[0..4] parallel vectors of points to update based on status.\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n-    std::vector<cv::Point2f> &points0_return, const std::vector<uchar> &status_all,\n+    std::vector<cv::Point2f> &points4, const std::vector<uchar> &status_all,\n     std::vector<int> &ages);\n /**\n  * @brief Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n"
                },
                {
                    "date": 1645293774964,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -152,10 +152,10 @@\n  * @brief Remove all points from the 4 point vectors that are out of frame\n  * or have a status of 0\n  *\n  * @param points[0..4] parallel vectors of points to update based on status.\n+ * @param ages Current ages of each of the points\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n- * @param ages Current ages of each of the points\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n"
                },
                {
                    "date": 1645293791087,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,8 +147,9 @@\n  * @param image The image we're detecting.\n  * @return A vector with the locations of all newly detected features.\n  */\n void featureDetectionFast(const cv::Mat image);\n+\n /**\n  * @brief Remove all points from the 4 point vectors that are out of frame\n  * or have a status of 0\n  *\n@@ -158,10 +159,11 @@\n  */\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n-    std::vector<cv::Point2f> &points4, const std::vector<uchar> &status_all,\n-    std::vector<int> &ages);\n+    std::vector<cv::Point2f> &points4, std::vector<int> &ages\n+    const std::vector<uchar> &status_all,);\n+\n /**\n  * @brief Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n  */\n"
                },
                {
                    "date": 1645293955028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,13 +47,13 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n int BUCKETS_PER_AXIS = 10\n-    /**\n-     * @brief Maximum number of features per bucket\n-     */\n-    int FEATURES_PER_BUCKET = 1;\n /**\n+ * @brief Maximum number of features per bucket\n+ */\n+int FEATURES_PER_BUCKET = 1;\n+/**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n int AGE_THRESHOLD = 10;\n@@ -160,9 +160,9 @@\n void deleteUnmatchFeaturesCircle(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, std::vector<int> &ages\n-    const std::vector<uchar> &status_all,);\n+    const std::vector<uchar> &status_all);\n \n /**\n  * @brief Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n"
                },
                {
                    "date": 1645390077141,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,15 +178,23 @@\n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * @return: vectors of features shared between the 4 images.\n  */\n-void matchingFeatures(cv::Mat &imageLeftT0, cv::Mat &imageRightT0,\n-                      cv::Mat &imageLeftT1, cv::Mat &imageRightT1,\n+void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n+                      const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n                       FeatureSet &currentVOFeatures,\n                       std::vector<cv::Point2f> &pointsLeftT0,\n                       std::vector<cv::Point2f> &pointsRightT0,\n                       std::vector<cv::Point2f> &pointsLeftT1,\n                       std::vector<cv::Point2f> &pointsRightT1);\n+/**\n+ * @brief \n+ * \n+ * @param frame_i \n+ * @param frame_pose \n+ * @param rotation \n+ * @param translation_stereo \n+ */\n void integrateOdometryStereo(int frame_i, cv::Mat &frame_pose,\n                              const cv::Mat &rotation,\n                              const cv::Mat &translation_stereo);\n /**\n"
                },
                {
                    "date": 1645390087310,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,5 +213,5 @@\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n \n-} // namespace visual_odometry\n\\ No newline at end of file\n+} // namespace visual_odometry\n"
                },
                {
                    "date": 1645390298815,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,11 +186,11 @@\n                       std::vector<cv::Point2f> &pointsRightT0,\n                       std::vector<cv::Point2f> &pointsLeftT1,\n                       std::vector<cv::Point2f> &pointsRightT1);\n /**\n- * @brief \n+ * @brief Compute the next pose from the current one\n+ * given the rotation and translation in the frame.\n  * \n- * @param frame_i \n  * @param frame_pose \n  * @param rotation \n  * @param translation_stereo \n  */\n"
                },
                {
                    "date": 1645390749245,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -189,13 +189,13 @@\n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * \n- * @param frame_pose \n- * @param rotation \n- * @param translation_stereo \n+ * @param frame_pose The original position of the robot, will be modified\n+ * @param rotation The rotation to go through\n+ * @param translation_stereo The translation to go through\n  */\n-void integrateOdometryStereo(int frame_i, cv::Mat &frame_pose,\n+void integrateOdometryStereo(cv::Mat &frame_pose,\n                              const cv::Mat &rotation,\n                              const cv::Mat &translation_stereo);\n /**\n  * @brief Compute the three euler angles for a given rotation matrix\n"
                },
                {
                    "date": 1645390756691,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -189,11 +189,11 @@\n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * \n- * @param frame_pose The original position of the robot, will be modified\n- * @param rotation The rotation to go through\n- * @param translation_stereo The translation to go through\n+ * @param frame_pose The original position of the robot, will be modified.\n+ * @param rotation The rotation to go through.\n+ * @param translation_stereo The translation to go through.\n  */\n void integrateOdometryStereo(cv::Mat &frame_pose,\n                              const cv::Mat &rotation,\n                              const cv::Mat &translation_stereo);\n"
                },
                {
                    "date": 1645390839283,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -200,14 +200,22 @@\n /**\n  * @brief Compute the three euler angles for a given rotation matrix\n  *\n  * @param R A rotation matrix\n- * @return cv::Vec3f (x, y, z) euler angles for R\n+ * @return cv::Vec3f (x, y, z) euler angles for R.\n  */\n cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n-void checkValidMatch(std::vector<cv::Point2f> &points,\n-                     std::vector<cv::Point2f> &points_return,\n-                     std::vector<bool> &status, int threshold);\n+/**\n+ * @brief \n+ * \n+ * @param points \n+ * @param points_return \n+ * @param status \n+ * @param threshold \n+ */\n+void checkValidMatch(const std::vector<cv::Point2f> &points,\n+                     const std::vector<cv::Point2f> &points_return,\n+                     const std::vector<bool> &status, int threshold);\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n"
                },
                {
                    "date": 1645390867110,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,9 +213,9 @@\n  * @param threshold \n  */\n void checkValidMatch(const std::vector<cv::Point2f> &points,\n                      const std::vector<cv::Point2f> &points_return,\n-                     const std::vector<bool> &status, int threshold);\n+                     const int threshold);\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n"
                },
                {
                    "date": 1645391062650,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -204,17 +204,17 @@\n  * @return cv::Vec3f (x, y, z) euler angles for R.\n  */\n cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n /**\n- * @brief \n+ * @brief For two vectors of points, find the locations where they\n+ * differ.\n  * \n- * @param points \n- * @param points_return \n- * @param status \n+ * @param original_points\n+ * @param adjusted_points \n  * @param threshold \n  */\n-void checkValidMatch(const std::vector<cv::Point2f> &points,\n-                     const std::vector<cv::Point2f> &points_return,\n+void checkValidMatch(const std::vector<cv::Point2f> &original_points,\n+                     const std::vector<cv::Point2f> &adjusted_points,\n                      const int threshold);\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n"
                },
                {
                    "date": 1645391282606,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -204,17 +204,17 @@\n  * @return cv::Vec3f (x, y, z) euler angles for R.\n  */\n cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n /**\n- * @brief For two vectors of points, find the locations where they\n+ * @brief Given two vectors of points, find the locations where they\n  * differ.\n  * \n- * @param original_points\n- * @param adjusted_points \n- * @param threshold \n+ * @param points_[1..2] The vectors of points to compar\n+ * @param threshold The distance at which to consider the points moved\n+ * @return a vector of length points_1, where \n  */\n-void checkValidMatch(const std::vector<cv::Point2f> &original_points,\n-                     const std::vector<cv::Point2f> &adjusted_points,\n+std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n+                     const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n"
                },
                {
                    "date": 1645391310525,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,9 +209,9 @@\n  * differ.\n  * \n  * @param points_[1..2] The vectors of points to compar\n  * @param threshold The distance at which to consider the points moved\n- * @return a vector of length points_1, where \n+ * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| < threshold\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n"
                },
                {
                    "date": 1645391322651,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,9 +209,9 @@\n  * differ.\n  * \n  * @param points_[1..2] The vectors of points to compar\n  * @param threshold The distance at which to consider the points moved\n- * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| < threshold\n+ * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| <= threshold\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n"
                },
                {
                    "date": 1645391331848,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -207,10 +207,10 @@\n /**\n  * @brief Given two vectors of points, find the locations where they\n  * differ.\n  * \n- * @param points_[1..2] The vectors of points to compar\n- * @param threshold The distance at which to consider the points moved\n+ * @param points_[1..2] The vectors of points to compare.\n+ * @param threshold The distance at which to consider the points moved.\n  * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| <= threshold\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n"
                },
                {
                    "date": 1645391347566,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -197,9 +197,9 @@\n void integrateOdometryStereo(cv::Mat &frame_pose,\n                              const cv::Mat &rotation,\n                              const cv::Mat &translation_stereo);\n /**\n- * @brief Compute the three euler angles for a given rotation matrix\n+ * @brief Compute the three euler angles for a given rotation matrix.\n  *\n  * @param R A rotation matrix\n  * @return cv::Vec3f (x, y, z) euler angles for R.\n  */\n@@ -214,10 +214,12 @@\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n+\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n+\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n"
                },
                {
                    "date": 1645391385810,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -214,9 +214,14 @@\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n-\n+/**\n+ * @brief \n+ * \n+ * @param points \n+ * @param status \n+ */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n \n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n"
                },
                {
                    "date": 1645391428309,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -215,9 +215,10 @@\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n /**\n- * @brief \n+ * @brief Update a vector of points, removing all of the points[i] in which status[i]\n+ * is false.\n  * \n  * @param points \n  * @param status \n  */\n"
                },
                {
                    "date": 1645391437420,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -215,10 +215,10 @@\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n /**\n- * @brief Update a vector of points, removing all of the points[i] in which status[i]\n- * is false.\n+ * @brief Update a vector of points, removing all of the points[i]\n+ * in which status[i] is false.\n  * \n  * @param points \n  * @param status \n  */\n"
                },
                {
                    "date": 1645391449267,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -218,10 +218,10 @@\n /**\n  * @brief Update a vector of points, removing all of the points[i]\n  * in which status[i] is false.\n  * \n- * @param points \n- * @param status \n+ * @param points The vector of points to update\n+ * @param status The status\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n \n"
                },
                {
                    "date": 1645391487124,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -219,9 +219,9 @@\n  * @brief Update a vector of points, removing all of the points[i]\n  * in which status[i] is false.\n  * \n  * @param points The vector of points to update\n- * @param status The status\n+ * @param status Vector indicating which points to remove.\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n \n"
                },
                {
                    "date": 1645391557881,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -219,13 +219,23 @@\n  * @brief Update a vector of points, removing all of the points[i]\n  * in which status[i] is false.\n  * \n  * @param points The vector of points to update\n- * @param status Vector indicating which points to remove.\n+ * @param status A vector indicating which points to remove.\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n-\n+/**\n+ * @brief \n+ * \n+ * @param projMatrl \n+ * @param projMatrr \n+ * @param pointsLeft_T1 \n+ * @param points3D_T0 \n+ * @param rotation \n+ * @param translation \n+ * @param mono_rotation \n+ */\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n"
                },
                {
                    "date": 1645391774106,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -174,20 +174,8 @@\n                       std::vector<cv::Point2f> &points_r_1,\n                       std::vector<cv::Point2f> &points_l_0_return,\n                       FeatureSet &current_features);\n /**\n- * Input: 4 images and the set of currently tracked features, as\n- * well as references to 4 vectors of points (by reference).\n- * @return: vectors of features shared between the 4 images.\n- */\n-void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n-                      const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n-                      FeatureSet &currentVOFeatures,\n-                      std::vector<cv::Point2f> &pointsLeftT0,\n-                      std::vector<cv::Point2f> &pointsRightT0,\n-                      std::vector<cv::Point2f> &pointsLeftT1,\n-                      std::vector<cv::Point2f> &pointsRightT1);\n-/**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * \n  * @param frame_pose The original position of the robot, will be modified.\n@@ -238,6 +226,17 @@\n void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n-\n+/**\n+ * Input: 4 images and the set of currently tracked features, as\n+ * well as references to 4 vectors of points (by reference).\n+ * @return: vectors of features shared between the 4 images.\n+ */\n+void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n+                      const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n+                      FeatureSet &currentVOFeatures,\n+                      std::vector<cv::Point2f> &pointsLeftT0,\n+                      std::vector<cv::Point2f> &pointsRightT0,\n+                      std::vector<cv::Point2f> &pointsLeftT1,\n+                      std::vector<cv::Point2f> &pointsRightT1);\n } // namespace visual_odometry\n"
                },
                {
                    "date": 1645391976875,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -222,9 +222,9 @@\n  * @param rotation \n  * @param translation \n  * @param mono_rotation \n  */\n-void trackingFrame2Frame(cv::Mat &projMatrl, cv::Mat &projMatrr,\n+void trackingFrame2Frame(cv::Mat &projMatrl,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n /**\n"
                },
                {
                    "date": 1645391993599,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -222,9 +222,9 @@\n  * @param rotation \n  * @param translation \n  * @param mono_rotation \n  */\n-void trackingFrame2Frame(cv::Mat &projMatrl,\n+void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n                          cv::Mat &translation, bool mono_rotation);\n /**\n"
                },
                {
                    "date": 1645391999891,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -225,9 +225,9 @@\n  */\n void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n-                         cv::Mat &translation, bool mono_rotation);\n+                         cv::Mat &translation, const bool mono_rotation);\n /**\n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * @return: vectors of features shared between the 4 images.\n"
                },
                {
                    "date": 1645392016301,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -225,9 +225,9 @@\n  */\n void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n-                         cv::Mat &translation, const bool mono_rotation);\n+                         cv::Mat &translation);\n /**\n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * @return: vectors of features shared between the 4 images.\n"
                },
                {
                    "date": 1645392027893,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -214,15 +214,13 @@\n                          const std::vector<bool> &status);\n /**\n  * @brief \n  * \n- * @param projMatrl \n- * @param projMatrr \n+ * @param leftCameraProjection_ \n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n  * @param rotation \n  * @param translation \n- * @param mono_rotation \n  */\n void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &points3D_T0, cv::Mat &rotation,\n"
                },
                {
                    "date": 1645392401239,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -214,9 +214,9 @@\n                          const std::vector<bool> &status);\n /**\n  * @brief \n  * \n- * @param leftCameraProjection_ \n+ * @param leftCameraProjection_ Left camera intrinsic matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n  * @param rotation \n  * @param translation \n"
                },
                {
                    "date": 1645394048468,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,11 +212,11 @@\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n- * @brief \n+ * @brief  \n  * \n- * @param leftCameraProjection_ Left camera intrinsic matrix\n+ * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n  * @param rotation \n  * @param translation \n"
                },
                {
                    "date": 1645394150134,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,9 +212,9 @@\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n- * @brief  \n+ * @brief \n  * \n  * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n"
                },
                {
                    "date": 1645394569967,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,9 +212,9 @@\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n- * @brief \n+ * @brief T\n  * \n  * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n@@ -222,9 +222,9 @@\n  * @param translation \n  */\n void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n-                         cv::Mat &points3D_T0, cv::Mat &rotation,\n+                         cv::Mat &world_points, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n"
                },
                {
                    "date": 1645394819268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,9 +212,10 @@\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n- * @brief T\n+ * @brief Compute the translation and rotation that needs to occur\n+ * for the \n  * \n  * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n"
                },
                {
                    "date": 1645394895924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,9 +213,9 @@\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n  * @brief Compute the translation and rotation that needs to occur\n- * for the \n+ * to obtain the given world points from the input points.\n  * \n  * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n"
                },
                {
                    "date": 1645394928167,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,9 +213,9 @@\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n  * @brief Compute the translation and rotation that needs to occur\n- * to obtain the given world points from the input points.\n+ * to obtain the given world points from the input points from the camera.\n  * \n  * @param leftCameraProjection_ Left camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n"
                },
                {
                    "date": 1645394953004,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -213,17 +213,17 @@\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n /**\n  * @brief Compute the translation and rotation that needs to occur\n- * to obtain the given world points from the input points from the camera.\n+ * to obtain the given world points from the camera input points\n  * \n- * @param leftCameraProjection_ Left camera projection matrix\n+ * @param cameraProjection_ camera projection matrix\n  * @param pointsLeft_T1 \n  * @param points3D_T0 \n  * @param rotation \n  * @param translation \n  */\n-void trackingFrame2Frame(cv::Mat &leftCameraProjection_,\n+void trackingFrame2Frame(cv::Mat &cameraProjection_,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &world_points, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n"
                },
                {
                    "date": 1645394980107,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -215,15 +215,15 @@\n /**\n  * @brief Compute the translation and rotation that needs to occur\n  * to obtain the given world points from the camera input points\n  * \n- * @param cameraProjection_ camera projection matrix\n- * @param pointsLeft_T1 \n- * @param points3D_T0 \n+ * @param cameraProjection Camera projection matrix\n+ * @param pointsLeft_T1 Points from the perspective of the camera\n+ * @param world_points \n  * @param rotation \n  * @param translation \n  */\n-void trackingFrame2Frame(cv::Mat &cameraProjection_,\n+void trackingFrame2Frame(cv::Mat &cameraProjection,\n                          std::vector<cv::Point2f> &pointsLeft_T1,\n                          cv::Mat &world_points, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n"
                },
                {
                    "date": 1645394985799,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -215,10 +215,10 @@\n /**\n  * @brief Compute the translation and rotation that needs to occur\n  * to obtain the given world points from the camera input points\n  * \n- * @param cameraProjection Camera projection matrix\n- * @param pointsLeft_T1 Points from the perspective of the camera\n+ * @param camera_projection Camera projection matrix\n+ * @param camera_points Points from the perspective of the camera\n  * @param world_points \n  * @param rotation \n  * @param translation \n  */\n"
                },
                {
                    "date": 1645394991637,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -215,11 +215,11 @@\n /**\n  * @brief Compute the translation and rotation that needs to occur\n  * to obtain the given world points from the camera input points\n  * \n- * @param camera_projection Camera projection matrix\n- * @param camera_points Points from the perspective of the camera\n- * @param world_points \n+ * @param cameraProjection Camera projection matrix\n+ * @param cameraPoints Points from the perspective of the camera\n+ * @param worldPoints \n  * @param rotation \n  * @param translation \n  */\n void trackingFrame2Frame(cv::Mat &cameraProjection,\n"
                },
                {
                    "date": 1645395001139,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -222,10 +222,10 @@\n  * @param rotation \n  * @param translation \n  */\n void trackingFrame2Frame(cv::Mat &cameraProjection,\n-                         std::vector<cv::Point2f> &pointsLeft_T1,\n-                         cv::Mat &world_points, cv::Mat &rotation,\n+                         std::vector<cv::Point2f> &cameraPoints,\n+                         cv::Mat &worldPoints, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n"
                },
                {
                    "date": 1645395035722,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -217,11 +217,11 @@\n  * to obtain the given world points from the camera input points\n  * \n  * @param cameraProjection Camera projection matrix\n  * @param cameraPoints Points from the perspective of the camera\n- * @param worldPoints \n- * @param rotation \n- * @param translation \n+ * @param worldPoints Same points in the real world\n+ * @param rotation Matrix to store the estimated rotation output in.\n+ * @param translation Matrix to store the estimated translation in.\n  */\n void trackingFrame2Frame(cv::Mat &cameraProjection,\n                          std::vector<cv::Point2f> &cameraPoints,\n                          cv::Mat &worldPoints, cv::Mat &rotation,\n"
                },
                {
                    "date": 1645395047415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -221,9 +221,9 @@\n  * @param worldPoints Same points in the real world\n  * @param rotation Matrix to store the estimated rotation output in.\n  * @param translation Matrix to store the estimated translation in.\n  */\n-void trackingFrame2Frame(cv::Mat &cameraProjection,\n+void worldToCamera(cv::Mat &cameraProjection,\n                          std::vector<cv::Point2f> &cameraPoints,\n                          cv::Mat &worldPoints, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n"
                },
                {
                    "date": 1645395226109,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -221,9 +221,9 @@\n  * @param worldPoints Same points in the real world\n  * @param rotation Matrix to store the estimated rotation output in.\n  * @param translation Matrix to store the estimated translation in.\n  */\n-void worldToCamera(cv::Mat &cameraProjection,\n+void cameraToWorld(cv::Mat &cameraProjection,\n                          std::vector<cv::Point2f> &cameraPoints,\n                          cv::Mat &worldPoints, cv::Mat &rotation,\n                          cv::Mat &translation);\n /**\n"
                },
                {
                    "date": 1645649381626,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -96,8 +96,10 @@\n    * @param image\n    */\n   void appendFeaturesFromImage(const cv::Mat &image);\n };\n+\n+cv::Mat rosImage2CvMat(sensor_msgs::ImageConstPtr img);\n class VisualOdometry {\n private:\n   /* number of frames seen so far. */\n   int frame_id = 0;\n"
                }
            ],
            "date": 1645281187446,
            "name": "Commit-0",
            "content": "/****************************************************************\n *\n * @file \t\tvo.h\n *\n * @brief \t\tThe Visual Odometry class being used for\n translation. The math can be found in Haidar Jamal's Thesis:\n *https://www.ri.cmu.edu/publications/localization-for-lunar-micro-rovers/\n *\n * @version \t1.0\n * @date \t\t02/09/2022\n *\n * @authors \tBen Kolligs, Alex Li\n * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n *\n ****************************************************************/\n#include <ctype.h>\n#include <math.h>\n\n#include <algorithm>\n#include <chrono>\n#include <ctime>\n#include <fstream>\n#include <iostream>\n#include <iterator>\n#include <opencv2/calib3d/calib3d.hpp>\n#include <opencv2/features2d/features2d.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/opencv.hpp>\n#include <opencv2/video/tracking.hpp>\n#include <sstream>\n#include <string>\n#include <vector>\n\n#include \"Core\"\n#include \"Dense\"\n\nextern \"C\" {\n#include \"cfe_error.h\"\n#include \"common_types.h\"\n#include \"pe_events.h\"\n}\n\nnamespace visual_odometry {\n\nstruct FeatureSet {\n    std::vector<cv::Point2f> points;\n    std::vector<int> ages;\n    int size() {\n        return points.size();\n    }\n    void clear() {\n        points.clear();\n        ages.clear();\n    }\n};\n\nclass Bucket {\n   public:\n    int id;\n    int max_size;\n\n    FeatureSet features;\n\n    Bucket(int);\n    ~Bucket();\n\n    void add_feature(cv::Point2f, int);\n    void get_features(FeatureSet&);\n\n    int size();\n};\n\nclass StereoVO {\n   public:\n};\n\nclass VisualOdometry {\n   private:\n    /* number of frames seen so far. */\n    int frame_id = 0;\n    /* Projection matrices for the left and right cameras */\n    cv::Mat leftCameraProjection_, rightCameraProjection_;\n\n    /* Images at current and next time step */\n    cv::Mat imageRightT0_, imageLeftT0_;\n    cv::Mat imageRightT1_, imageLeftT1_;\n\n    /* Initial pose variables */\n    cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n    cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n    cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n\n    cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n\n    // set of features currently tracked\n    FeatureSet currentVOFeatures;\n\n    // runs the pipeline\n    void run();\n\n    /**\n     *  Use the FAST feature detector to accumulate the features in image into\n     *  points.\n     */\n    void featureDetectionFast(cv::Mat image, std::vector<cv::Point2f>& points);\n    void deleteUnmatchFeaturesCircle(\n        std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n        std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n        std::vector<cv::Point2f>& points0_return, std::vector<uchar>& status0,\n        std::vector<uchar>& status1, std::vector<uchar>& status2,\n        std::vector<uchar>& status3, std::vector<int>& ages);\n    /**\n     * Detect points not found in both cameras for both the previous and current\n     * frame and remove them.\n     */\n    void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n                          cv::Mat img_r_1, std::vector<cv::Point2f>& points_l_0,\n                          std::vector<cv::Point2f>& points_r_0,\n                          std::vector<cv::Point2f>& points_l_1,\n                          std::vector<cv::Point2f>& points_r_1,\n                          std::vector<cv::Point2f>& points_l_0_return,\n                          FeatureSet& current_features);\n    /**\n     * Updates current_features to only include a subset of the\n     * original features which give a good spread throughout the image.\n     * image: only use for getting dimension of the image\n     * bucket_size: bucket size in pixel is bucket_size*bucket_size\n     * features_per_bucket: number of selected features per bucket\n     */\n    void bucketingFeatures(cv::Mat& image, FeatureSet& current_features,\n                           int bucket_size, int features_per_bucket);\n    /**\n     * \n     */\n    void matchingFeatures(cv::Mat& imageLeftT0, cv::Mat& imageRightT0,\n                          cv::Mat& imageLeftT1, cv::Mat& imageRightT1,\n                          FeatureSet& currentVOFeatures,\n                          std::vector<cv::Point2f>& pointsLeftT0,\n                          std::vector<cv::Point2f>& pointsRightT0,\n                          std::vector<cv::Point2f>& pointsLeftT1,\n                          std::vector<cv::Point2f>& pointsRightT1);\n    void appendNewFeatures(cv::Mat& image, FeatureSet& current_features);\n    void integrateOdometryStereo(int frame_i, cv::Mat& frame_pose,\n                                 const cv::Mat& rotation,\n                                 const cv::Mat& translation_stereo);\n    bool isRotationMatrix(cv::Mat& R);\n    cv::Vec3f rotationMatrixToEulerAngles(cv::Mat& R);\n    void checkValidMatch(std::vector<cv::Point2f>& points,\n                         std::vector<cv::Point2f>& points_return,\n                         std::vector<bool>& status, int threshold);\n    void removeInvalidPoints(std::vector<cv::Point2f>& points,\n                             const std::vector<bool>& status);\n    void trackingFrame2Frame(cv::Mat& projMatrl, cv::Mat& projMatrr,\n                             std::vector<cv::Point2f>& pointsLeft_T1,\n                             cv::Mat& points3D_T0, cv::Mat& rotation,\n                             cv::Mat& translation, bool mono_rotation);\n\n   public:\n    VisualOdometry(cv::Mat ProjMatrl, cv::Mat projMatrr);\n\n    ~VisualOdometry();\n\n    // Takes the two images seen by both cameras and runs the pipeline.\n    // TODO: Results are obtained somehow\n    void stereo_callback(const cv::Mat& image_left,\n                         const cv::Mat& image_right);\n};\n}   // namespace visual_odometry\n"
        }
    ]
}