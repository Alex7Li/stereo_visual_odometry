{
    "sourceFile": "include/stereo_visual_odometry/vo.h",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 76,
            "patches": [
                {
                    "date": 1646257211002,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1646257243337,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,17 +60,19 @@\n int AGE_THRESHOLD = 10;\n \n \n // TODO @Alex7Li comment what the Bucket class does\n+/*\n+ * @brief Removes a \n+ */\n class Bucket {\n public:\n   int id;\n   int max_size;\n \n   // TODO @Alex7Li comment what this is meant to store\n   FeatureSet features;\n \n-  // TODO @Alex7Li name this\n   Bucket(int max_size);\n   ~Bucket();\n \n   /** //TODO @Alex7Li comment this\n"
                },
                {
                    "date": 1646257264348,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,16 +61,20 @@\n \n \n // TODO @Alex7Li comment what the Bucket class does\n /*\n- * @brief Removes a \n+ * @brief A class to store a set of features \n  */\n class Bucket {\n public:\n   int id;\n   int max_size;\n \n   // TODO @Alex7Li comment what this is meant to store\n+  /**\n+   * @brief \n+   * \n+   */\n   FeatureSet features;\n \n   Bucket(int max_size);\n   ~Bucket();\n"
                },
                {
                    "date": 1646257561994,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,9 +61,10 @@\n \n \n // TODO @Alex7Li comment what the Bucket class does\n /*\n- * @brief A class to store a set of features \n+ * @brief A class to store a set of image features.\n+ *\n  */\n class Bucket {\n public:\n   int id;\n"
                },
                {
                    "date": 1646257653997,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,14 +61,13 @@\n \n \n // TODO @Alex7Li comment what the Bucket class does\n /*\n- * @brief A class to store a set of image features.\n- *\n+ * @brief A class to store a set of at most max_size\n+ * image features and \n  */\n class Bucket {\n public:\n-  int id;\n   int max_size;\n \n   // TODO @Alex7Li comment what this is meant to store\n   /**\n"
                },
                {
                    "date": 1646257771412,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,10 +61,11 @@\n \n \n // TODO @Alex7Li comment what the Bucket class does\n /*\n- * @brief A class to store a set of at most max_size\n- * image features and \n+ * @brief A class to allow storing a set of at most max_size\n+ * image features, and remove outdated features to satisfy this\n+ * constraint.\n  */\n class Bucket {\n public:\n   int max_size;\n"
                },
                {
                    "date": 1646257790627,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -60,21 +60,19 @@\n int AGE_THRESHOLD = 10;\n \n \n // TODO @Alex7Li comment what the Bucket class does\n-/*\n+/**\n  * @brief A class to allow storing a set of at most max_size\n  * image features, and remove outdated features to satisfy this\n  * constraint.\n- */\n+ **/\n class Bucket {\n public:\n   int max_size;\n \n-  // TODO @Alex7Li comment what this is meant to store\n   /**\n-   * @brief \n-   * \n+   * @brief The set of features stored in this bucket.\n    */\n   FeatureSet features;\n \n   Bucket(int max_size);\n"
                },
                {
                    "date": 1646257799813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,10 +77,10 @@\n \n   Bucket(int max_size);\n   ~Bucket();\n \n-  /** //TODO @Alex7Li comment this\n-   * @brief DESCRIPTION \n+  /**\n+   * @brief Add a feature to the bucket\n    *\n    * @param point DESCRIPTION\n    * @param age DESCRIPTION\n    */\n"
                },
                {
                    "date": 1646257821726,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,10 +80,10 @@\n \n   /**\n    * @brief Add a feature to the bucket\n    *\n-   * @param point DESCRIPTION\n-   * @param age DESCRIPTION\n+   * @param point The location of the feature to add\n+   * @param age The number of iterations since this feature was detected.\n    */\n   void add_feature(const cv::Point2f point, const int age);\n \n   int size();\n"
                },
                {
                    "date": 1646257864453,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,9 +84,12 @@\n    * @param point The location of the feature to add\n    * @param age The number of iterations since this feature was detected.\n    */\n   void add_feature(const cv::Point2f point, const int age);\n-\n+  \n+  /**\n+   * @return int The size of the feature set\n+   */\n   int size();\n };\n \n // TODO @Alex7Li comment what the FeatureSet class does\n"
                },
                {
                    "date": 1646257873851,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,16 +66,16 @@\n  * image features, and remove outdated features to satisfy this\n  * constraint.\n  **/\n class Bucket {\n-public:\n   int max_size;\n \n   /**\n    * @brief The set of features stored in this bucket.\n    */\n   FeatureSet features;\n \n+public:\n   Bucket(int max_size);\n   ~Bucket();\n \n   /**\n"
                },
                {
                    "date": 1646257910640,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,9 +59,8 @@\n  */\n int AGE_THRESHOLD = 10;\n \n \n-// TODO @Alex7Li comment what the Bucket class does\n /**\n  * @brief A class to allow storing a set of at most max_size\n  * image features, and remove outdated features to satisfy this\n  * constraint.\n@@ -92,8 +91,12 @@\n   int size();\n };\n \n // TODO @Alex7Li comment what the FeatureSet class does\n+/**\n+ * @brief A set of point features and their ages.\n+ * \n+ */\n class FeatureSet {\n public:\n   \n   // TODO @Alex7Li comment what this is meant to store\n"
                },
                {
                    "date": 1646257923107,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,8 +99,11 @@\n class FeatureSet {\n public:\n   \n   // TODO @Alex7Li comment what this is meant to store\n+  /**\n+   * @brief The points stored in this set of features\n+   */\n   std::vector<cv::Point2f> points;\n   // TODO @Alex7Li comment what this is meant to store\n   std::vector<int> ages;\n   int size() { return points.size(); }\n"
                },
                {
                    "date": 1646257929189,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,10 +92,9 @@\n };\n \n // TODO @Alex7Li comment what the FeatureSet class does\n /**\n- * @brief A set of point features and their ages.\n- * \n+ * @brief A set of locations for image features and their ages.\n  */\n class FeatureSet {\n public:\n   \n"
                },
                {
                    "date": 1646257965612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,12 @@\n   /**\n    * @brief The points stored in this set of features\n    */\n   std::vector<cv::Point2f> points;\n-  // TODO @Alex7Li comment what this is meant to store\n+  /**\n+   * @brief A parallel set to points; ages[i] contains\n+   * the number of iterations that points[i] has been alive.\n+   */\n   std::vector<int> ages;\n   int size() { return points.size(); }\n   /**\n    * @brief Updates the feature set to only include a subset of the\n"
                },
                {
                    "date": 1646257979762,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n    */\n   std::vector<cv::Point2f> points;\n   /**\n    * @brief A parallel set to points; ages[i] contains\n-   * the number of iterations that points[i] has been alive.\n+   * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n   int size() { return points.size(); }\n   /**\n"
                },
                {
                    "date": 1646257984970,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -96,10 +96,8 @@\n  * @brief A set of locations for image features and their ages.\n  */\n class FeatureSet {\n public:\n-  \n-  // TODO @Alex7Li comment what this is meant to store\n   /**\n    * @brief The points stored in this set of features\n    */\n   std::vector<cv::Point2f> points;\n"
                },
                {
                    "date": 1646257995877,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -124,9 +124,9 @@\n   /**\n    * @brief Apply a feature detection algorithm over the image to generate new\n    * features, and all all such features into this feature set.\n    *\n-   * @param image //  TODO @Alex7Li Description\n+   * @param image The image to obtain all points from.\n    */\n   void appendFeaturesFromImage(const cv::Mat &image);\n };\n \n"
                },
                {
                    "date": 1646258008241,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,10 +150,9 @@\n   cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n \n   /* Set of features currently tracked. */\n   FeatureSet currentVOFeatures;\n-\n-  //  TODO @Alex7Li Comment this\n+  \n   void run();\n \n public:\n   /**\n"
                },
                {
                    "date": 1646258023580,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -150,10 +150,8 @@\n   cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n \n   /* Set of features currently tracked. */\n   FeatureSet currentVOFeatures;\n-  \n-  void run();\n \n public:\n   /**\n    * @brief Construct a new Visual Odometry object\n"
                },
                {
                    "date": 1646258052702,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,11 +145,8 @@\n   cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n   cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n   cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n-  // TODO @Alex7Li What is this\n-  cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n-\n   /* Set of features currently tracked. */\n   FeatureSet currentVOFeatures;\n \n public:\n"
                },
                {
                    "date": 1646258060158,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,8 +145,11 @@\n   cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n   cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n   cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n+  // TODO @Alex7Li What is this\n+  cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n+\n   /* Set of features currently tracked. */\n   FeatureSet currentVOFeatures;\n \n public:\n"
                },
                {
                    "date": 1646258081471,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,11 +145,8 @@\n   cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n   cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n   cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n-  // TODO @Alex7Li What is this\n-  cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n-\n   /* Set of features currently tracked. */\n   FeatureSet currentVOFeatures;\n \n public:\n"
                },
                {
                    "date": 1646258103783,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,9 +131,9 @@\n };\n \n class VisualOdometry {\n private:\n-  /* number of frames seen so far. */\n+  /* Number of frames seen so far. */\n   int frame_id = 0;\n   /* Projection matrices for the left and right cameras */\n   cv::Mat leftCameraProjection_, rightCameraProjection_;\n \n"
                },
                {
                    "date": 1646258138880,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -180,9 +180,9 @@\n  *\n  * @return A vector with the locations of all newly detected features.\n  * //TODO @Alex7Li this does not return anything??\n  */\n-void featureDetectionFast(const cv::Mat image);\n+std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n /**\n  * @brief Remove all points from the 4 point vectors that are out of frame\n  * or have a status of 0 //TODO @Alex7Li also old??\n"
                },
                {
                    "date": 1646259862658,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,15 +178,14 @@\n  *\n  * @param image The image we're detecting.\n  *\n  * @return A vector with the locations of all newly detected features.\n- * //TODO @Alex7Li this does not return anything??\n  */\n std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n /**\n- * @brief Remove all points from the 4 point vectors that are out of frame\n- * or have a status of 0 //TODO @Alex7Li also old??\n+ * @brief Remove all points from the input point vectors and the parallel\n+ * ages vector where the parallel status vector is invalid.\n  *\n  * @param points[0..4] vectors of points to update based on status.\n  * SHOULD ALL BE THE SAME SIZE AND REPRESENT //TODO @Alex7Li what do they represent\n  *\n@@ -194,9 +193,9 @@\n  *\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  */\n // TODO @Alex7Li rename this\n-void deleteUnmatchFeaturesCircle(\n+void deleteFeaturesWithFailureStatus(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, std::vector<int> &ages\n     const std::vector<uchar> &status_all);\n"
                },
                {
                    "date": 1646259919906,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -182,9 +182,9 @@\n  */\n std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n /**\n- * @brief Remove all points from the input point vectors and the parallel\n+ * @brief Given parallel vectors of points, ages, and statusRemove all points from the input point vectors and the parallel\n  * ages vector where the parallel status vector is invalid.\n  *\n  * @param points[0..4] vectors of points to update based on status.\n  * SHOULD ALL BE THE SAME SIZE AND REPRESENT //TODO @Alex7Li what do they represent\n"
                },
                {
                    "date": 1646260047761,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -182,10 +182,10 @@\n  */\n std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n \n /**\n- * @brief Given parallel vectors of points, ages, and statusRemove all points from the input point vectors and the parallel\n- * ages vector where the parallel status vector is invalid.\n+ * @brief Given parallel vectors of points, ages, and the status of those points,\n+ * update the vectors by removing elements with a invalid status.\n  *\n  * @param points[0..4] vectors of points to update based on status.\n  * SHOULD ALL BE THE SAME SIZE AND REPRESENT //TODO @Alex7Li what do they represent\n  *\n"
                },
                {
                    "date": 1646260053713,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,10 +186,8 @@\n  * @brief Given parallel vectors of points, ages, and the status of those points,\n  * update the vectors by removing elements with a invalid status.\n  *\n  * @param points[0..4] vectors of points to update based on status.\n- * SHOULD ALL BE THE SAME SIZE AND REPRESENT //TODO @Alex7Li what do they represent\n- *\n  * @param ages Current ages of each of the points\n  *\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  */\n"
                },
                {
                    "date": 1646260071595,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -185,10 +185,12 @@\n /**\n  * @brief Given parallel vectors of points, ages, and the status of those points,\n  * update the vectors by removing elements with a invalid status.\n  *\n- * @param points[0..4] vectors of points to update based on status.\n- * @param ages Current ages of each of the points\n+ * @param points[0..4] vectors of points to update based on status, each with\n+ * the same length as status_all.\n+ * \n+ * @param ages Current ages of each of the points.\n  *\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  */\n // TODO @Alex7Li rename this\n"
                },
                {
                    "date": 1646260145328,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -187,14 +187,13 @@\n  * update the vectors by removing elements with a invalid status.\n  *\n  * @param points[0..4] vectors of points to update based on status, each with\n  * the same length as status_all.\n- * \n+ *\n  * @param ages Current ages of each of the points.\n  *\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  */\n-// TODO @Alex7Li rename this\n void deleteFeaturesWithFailureStatus(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, std::vector<int> &ages\n"
                },
                {
                    "date": 1646260157042,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,9 +199,9 @@\n     std::vector<cv::Point2f> &points4, std::vector<int> &ages\n     const std::vector<uchar> &status_all);\n \n /**\n- * @brief Perform circular matching on  TODO @Alex7Li on what\n+ * @brief Perform circular matching on 4 images.\n  * Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n"
                },
                {
                    "date": 1646260189550,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,8 +202,12 @@\n /**\n  * @brief Perform circular matching on 4 images.\n  * Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n+ * @param points_l_0\n+ * @param points_r_0\n+ * @param points_l_1\n+ * @param points_r_1\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n                       cv::Mat img_r_1, std::vector<cv::Point2f> &points_l_0,\n"
                },
                {
                    "date": 1646260216344,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,12 +202,10 @@\n /**\n  * @brief Perform circular matching on 4 images.\n  * Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n- * @param points_l_0\n- * @param points_r_0\n- * @param points_l_1\n- * @param points_r_1\n+ * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n+ * at a given timestamp\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n                       cv::Mat img_r_1, std::vector<cv::Point2f> &points_l_0,\n"
                },
                {
                    "date": 1646260223893,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,8 +202,9 @@\n /**\n  * @brief Perform circular matching on 4 images.\n  * Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n+ * @param img_[l,r]_[0,1] points corresponding to the right/left camera\n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n"
                },
                {
                    "date": 1646260274706,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,9 +202,9 @@\n /**\n  * @brief Perform circular matching on 4 images.\n  * Detect points not found in both cameras for both the previous and\n  * current frame and remove them.\n- * @param img_[l,r]_[0,1] points corresponding to the right/left camera\n+ * @param img_[l,r]_[0,1] Images taken by the right/left camera at the \n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n"
                },
                {
                    "date": 1646260370542,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -207,15 +207,15 @@\n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n-void circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n-                      cv::Mat img_r_1, std::vector<cv::Point2f> &points_l_0,\n-                      std::vector<cv::Point2f> &points_r_0,\n-                      std::vector<cv::Point2f> &points_l_1,\n-                      std::vector<cv::Point2f> &points_r_1,\n-                      std::vector<cv::Point2f> &points_l_0_return,\n-                      FeatureSet &current_features);\n+void circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n+                        cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n+                        std::vector<cv::Point2f> & points_1,\n+                        std::vector<cv::Point2f> & points_2,\n+                        std::vector<cv::Point2f> & points_3,\n+                        std::vector<cv::Point2f> & points_0_return,\n+                        FeatureSet & current_features) {\n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * Essentially a multiplicationof homogeneous transforms.\n"
                },
                {
                    "date": 1646260598878,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,17 +199,18 @@\n     std::vector<cv::Point2f> &points4, std::vector<int> &ages\n     const std::vector<uchar> &status_all);\n \n /**\n- * @brief Perform circular matching on 4 images.\n- * Detect points not found in both cameras for both the previous and\n- * current frame and remove them.\n+ * @brief Perform circular matching on 4 images and\n+ * detect points not found in both cameras for both the previous and\n+ * current frame.\n  * @param img_[l,r]_[0,1] Images taken by the right/left camera at the \n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n+ * @ \n  */\n // TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n-void circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n+std::vector<uchar>  circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n"
                },
                {
                    "date": 1646260633502,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,12 +205,11 @@\n  * current frame.\n  * @param img_[l,r]_[0,1] Images taken by the right/left camera at the \n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n- * @ \n+ * @return \n  */\n-// TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\n-std::vector<uchar>  circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n+std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n"
                },
                {
                    "date": 1646260673205,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,8 +205,11 @@\n  * current frame.\n  * @param img_[l,r]_[0,1] Images taken by the right/left camera at the \n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n+ * @param points_0_return The \n+ * @param current_features The current feature set to consider while performing\n+ * the circular matching.\n  * @return \n  */\n std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n"
                },
                {
                    "date": 1646260730959,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -208,9 +208,10 @@\n  * at a given timestamp\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n- * @return \n+ * @return good_status An array parallel to the points arrays which is true\n+ *      exactly where \n  */\n std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n"
                },
                {
                    "date": 1646260741458,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,9 +209,9 @@\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n  * @return good_status An array parallel to the points arrays which is true\n- *      exactly where \n+ *      exactly where they are.\n  */\n std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n"
                },
                {
                    "date": 1646260824877,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -208,9 +208,9 @@\n  * at a given timestamp\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n- * @return good_status An array parallel to the points arrays which is true\n+ * @return matchingStatus An array parallel to the points arrays which is true\n  *      exactly where they are.\n  */\n std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n"
                },
                {
                    "date": 1646260833663,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,9 +209,9 @@\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n  * @return matchingStatus An array parallel to the points arrays which is true\n- *      exactly where they are.\n+ *      at points that were matched correctly.\n  */\n std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n                         cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n"
                },
                {
                    "date": 1646260949482,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -211,10 +211,11 @@\n  * the circular matching.\n  * @return matchingStatus An array parallel to the points arrays which is true\n  *      at points that were matched correctly.\n  */\n-std::vector<uchar> circularMatching(cv::Mat img_0, cv::Mat img_1, cv::Mat img_2,\n-                        cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n+std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n+                        const cv::Mat img_2,\n+                        const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n                         std::vector<cv::Point2f> & points_0_return,\n"
                },
                {
                    "date": 1646261005343,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,9 +202,9 @@\n /**\n  * @brief Perform circular matching on 4 images and\n  * detect points not found in both cameras for both the previous and\n  * current frame.\n- * @param img_[l,r]_[0,1] Images taken by the right/left camera at the \n+ * @param img_[0,3] Images of the same object taken by different cameras.\n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n"
                },
                {
                    "date": 1646261017822,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -202,9 +202,9 @@\n /**\n  * @brief Perform circular matching on 4 images and\n  * detect points not found in both cameras for both the previous and\n  * current frame.\n- * @param img_[0,3] Images of the same object taken by different cameras.\n+ * @param img_[0,3] Images of the same scene taken by different cameras at different times.\n  * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n  * at a given timestamp\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n"
                },
                {
                    "date": 1646261034135,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -203,10 +203,9 @@\n  * @brief Perform circular matching on 4 images and\n  * detect points not found in both cameras for both the previous and\n  * current frame.\n  * @param img_[0,3] Images of the same scene taken by different cameras at different times.\n- * @param points_[l,r]_[0,1] points corresponding to the right/left camera\n- * at a given timestamp\n+ * @param points_[0,3] Feature points corresponding to each camera\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n  * @return matchingStatus An array parallel to the points arrays which is true\n"
                },
                {
                    "date": 1646261049243,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -203,9 +203,9 @@\n  * @brief Perform circular matching on 4 images and\n  * detect points not found in both cameras for both the previous and\n  * current frame.\n  * @param img_[0,3] Images of the same scene taken by different cameras at different times.\n- * @param points_[0,3] Feature points corresponding to each camera\n+ * @param points_[0,3] Features of the scene detected by the cameras.\n  * @param points_0_return The \n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n  * @return matchingStatus An array parallel to the points arrays which is true\n"
                },
                {
                    "date": 1646261141547,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -204,9 +204,10 @@\n  * detect points not found in both cameras for both the previous and\n  * current frame.\n  * @param img_[0,3] Images of the same scene taken by different cameras at different times.\n  * @param points_[0,3] Features of the scene detected by the cameras.\n- * @param points_0_return The \n+ * @param points_0_return The locations of points in points_0 after mapping them to\n+ * points_1, points_2, points_3, and then back to points_0.\n  * @param current_features The current feature set to consider while performing\n  * the circular matching.\n  * @return matchingStatus An array parallel to the points arrays which is true\n  *      at points that were matched correctly.\n"
                },
                {
                    "date": 1646261252529,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -217,10 +217,9 @@\n                         const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n-                        std::vector<cv::Point2f> & points_0_return,\n-                        FeatureSet & current_features) {\n+                        std::vector<cv::Point2f> & points_0_return) {\n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * Essentially a multiplicationof homogeneous transforms.\n"
                },
                {
                    "date": 1646261258167,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -217,9 +217,10 @@\n                         const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n-                        std::vector<cv::Point2f> & points_0_return) {\n+                        std::vector<cv::Point2f> & points_0_return);\n+\n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n  * Essentially a multiplicationof homogeneous transforms.\n"
                },
                {
                    "date": 1646261267663,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -222,9 +222,9 @@\n \n /**\n  * @brief Compute the next pose from the current one\n  * given the rotation and translation in the frame.\n- * Essentially a multiplicationof homogeneous transforms.\n+ * Essentially a multiplication of homogeneous transforms.\n  * \n  * @param frame_pose The original position of the robot, will be modified.\n  *\n  * @param rotation The rotation to go through.\n"
                },
                {
                    "date": 1646261340632,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -241,8 +241,9 @@\n  *\n  * @return cv::Vec3f (x, y, z) euler angles for R.\n  */\n cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n+\n /**\n  * @brief Given two vectors of points, find the locations where they\n  * differ.\n  * \n"
                },
                {
                    "date": 1646261348365,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -255,8 +255,9 @@\n  */\n std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                      const std::vector<cv::Point2f> &points_2,\n                      const int threshold);\n+\n /**\n  * @brief Update a vector of points, removing all of the points[i]\n  * in which status[i] is false.\n  * \n"
                },
                {
                    "date": 1646261355081,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -266,8 +266,9 @@\n  * @param status A vector indicating which points to remove.\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n                          const std::vector<bool> &status);\n+\n /**\n  * @brief Compute the translation and rotation that needs to occur\n  * to obtain the given world points from the camera input points\n  * \n"
                },
                {
                    "date": 1646261362527,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -260,9 +260,9 @@\n /**\n  * @brief Update a vector of points, removing all of the points[i]\n  * in which status[i] is false.\n  * \n- * @param points The vector of points to update\n+ * @param points The vector of points to update.\n  *\n  * @param status A vector indicating which points to remove.\n  */\n void removeInvalidPoints(std::vector<cv::Point2f> &points,\n"
                },
                {
                    "date": 1646261392805,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -281,12 +281,12 @@\n  * @param rotation Matrix to store the estimated rotation output in.\n  *\n  * @param translation Matrix to store the estimated translation in.\n  */\n-void cameraToWorld(cv::Mat &cameraProjection,\n-                         std::vector<cv::Point2f> &cameraPoints,\n-                         cv::Mat &worldPoints, cv::Mat &rotation,\n-                         cv::Mat &translation);\n+void cameraToWorld(const cv::Mat &cameraProjection,\n+                const std::vector<cv::Point2f> &cameraPoints,\n+                const cv::Mat &worldPoints, cv::Mat &rotation,\n+                cv::Mat &translation);\n /**\n  * // TODO @Alex7Li \n  * @brief <<DESCRIBE>>\n  * Calls many of the above functions in a pipeline.\n"
                },
                {
                    "date": 1646262074599,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -287,9 +287,11 @@\n                 const cv::Mat &worldPoints, cv::Mat &rotation,\n                 cv::Mat &translation);\n /**\n  * // TODO @Alex7Li \n- * @brief <<DESCRIBE>>\n+ * @brief Given four images and the set of features used in the last\n+ * iteration, this method finds new features in the images and appends\n+ * the locations of these features to a point vector for each image.\n  * Calls many of the above functions in a pipeline.\n  * a->b->c\n  * \n  * Input: 4 images and the set of currently tracked features, as\n"
                },
                {
                    "date": 1646262492856,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -289,9 +289,9 @@\n /**\n  * // TODO @Alex7Li \n  * @brief Given four images and the set of features used in the last\n  * iteration, this method finds new features in the images and appends\n- * the locations of these features to a point vector for each image.\n+ * each of the locations of these features to a vector.\n  * Calls many of the above functions in a pipeline.\n  * a->b->c\n  * \n  * Input: 4 images and the set of currently tracked features, as\n"
                },
                {
                    "date": 1646262519155,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -289,9 +289,9 @@\n /**\n  * // TODO @Alex7Li \n  * @brief Given four images and the set of features used in the last\n  * iteration, this method finds new features in the images and appends\n- * each of the locations of these features to a vector.\n+ * each of the locations of the features in each image to 4 parallel vectors.\n  * Calls many of the above functions in a pipeline.\n  * a->b->c\n  * \n  * Input: 4 images and the set of currently tracked features, as\n"
                },
                {
                    "date": 1646262601027,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -290,10 +290,12 @@\n  * // TODO @Alex7Li \n  * @brief Given four images and the set of features used in the last\n  * iteration, this method finds new features in the images and appends\n  * each of the locations of the features in each image to 4 parallel vectors.\n+ * \n  * Calls many of the above functions in a pipeline.\n- * a->b->c\n+ * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n+ * deleteFeaturesWithFailureStatus -> findUnmovedPoints\n  * \n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * \n"
                },
                {
                    "date": 1646262910696,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -293,9 +293,9 @@\n  * each of the locations of the features in each image to 4 parallel vectors.\n  * \n  * Calls many of the above functions in a pipeline.\n  * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n- * deleteFeaturesWithFailureStatus -> findUnmovedPoints\n+ * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n  * Input: 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * \n"
                },
                {
                    "date": 1646263013878,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -295,9 +295,10 @@\n  * Calls many of the above functions in a pipeline.\n  * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n- * Input: 4 images and the set of currently tracked features, as\n+ * Input: \n+ * image[(Left)|(Right)][01] 4 images and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * \n  * @return: vectors of features shared between the 4 images.\n  */\n"
                },
                {
                    "date": 1646263031233,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -296,9 +296,10 @@\n  * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n  * Input: \n- * image[(Left)|(Right)][01] 4 images and the set of currently tracked features, as\n+ * image[(Left)|(Right)][01] Images from the left/right cameras at the last/current timestep.\n+ * and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * \n  * @return: vectors of features shared between the 4 images.\n  */\n"
                },
                {
                    "date": 1646263078617,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -297,8 +297,9 @@\n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n  * Input: \n  * image[(Left)|(Right)][01] Images from the left/right cameras at the last/current timestep.\n+ * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image.\n  * and the set of currently tracked features, as\n  * well as references to 4 vectors of points (by reference).\n  * \n  * @return: vectors of features shared between the 4 images.\n"
                },
                {
                    "date": 1646263289077,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -296,12 +296,11 @@\n  * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n  * Input: \n- * image[(Left)|(Right)][01] Images from the left/right cameras at the last/current timestep.\n+ * image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n  * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image.\n- * and the set of currently tracked features, as\n- * well as references to 4 vectors of points (by reference).\n+ * points[(Left)|(Right)][01]: well as references to 4 empty vectors of points (by reference).\n  * \n  * @return: vectors of features shared between the 4 images.\n  */\n void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n"
                },
                {
                    "date": 1646263302693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -298,9 +298,9 @@\n  * \n  * Input: \n  * image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n  * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image.\n- * points[(Left)|(Right)][01]: well as references to 4 empty vectors of points (by reference).\n+ * points[(Left)|(Right)][01]: references to 4 empty vectors of points to fill up with feature positions.\n  * \n  * @return: vectors of features shared between the 4 images.\n  */\n void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n"
                },
                {
                    "date": 1646263312861,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -297,12 +297,11 @@\n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n  * Input: \n  * image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n- * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image.\n+ * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image, will\n+ * be updated over time.\n  * points[(Left)|(Right)][01]: references to 4 empty vectors of points to fill up with feature positions.\n- * \n- * @return: vectors of features shared between the 4 images.\n  */\n void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n                       const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n                       FeatureSet &currentVOFeatures,\n"
                },
                {
                    "date": 1646263363862,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -295,13 +295,12 @@\n  * Calls many of the above functions in a pipeline.\n  * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n  * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n  * \n- * Input: \n- * image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n- * currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image, will\n- * be updated over time.\n- * points[(Left)|(Right)][01]: references to 4 empty vectors of points to fill up with feature positions.\n+ * @param image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n+ * @param currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image, will\n+ * be updated with newly detected features.\n+ * @param points[(Left)|(Right)][01]: references to 4 empty vectors of points to fill up with feature positions.\n  */\n void matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n                       const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n                       FeatureSet &currentVOFeatures,\n"
                },
                {
                    "date": 1646263425766,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -286,9 +286,8 @@\n                 const std::vector<cv::Point2f> &cameraPoints,\n                 const cv::Mat &worldPoints, cv::Mat &rotation,\n                 cv::Mat &translation);\n /**\n- * // TODO @Alex7Li \n  * @brief Given four images and the set of features used in the last\n  * iteration, this method finds new features in the images and appends\n  * each of the locations of the features in each image to 4 parallel vectors.\n  * \n"
                },
                {
                    "date": 1646263475335,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,16 +133,16 @@\n class VisualOdometry {\n private:\n   /* Number of frames seen so far. */\n   int frame_id = 0;\n-  /* Projection matrices for the left and right cameras */\n+  /* Projection matrices for the left and right cameras. */\n   cv::Mat leftCameraProjection_, rightCameraProjection_;\n \n-  /* Images at current and next time step */\n+  /* Images at current and next time step. */\n   cv::Mat imageRightT0_, imageLeftT0_;\n   cv::Mat imageRightT1_, imageLeftT1_;\n \n-  /* Initial pose variables */\n+  /* Initial pose variables. */\n   cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n   cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n   cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n \n"
                },
                {
                    "date": 1646263484287,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -110,13 +110,13 @@\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n-   * @param image only use for getting dimension of the image\n+   * @param image only use for getting dimension of the image.\n    *\n-   * @param bucket_size bucket size in pixel is bucket_size*bucket_size\n+   * @param bucket_size bucket size in pixel is bucket_size*bucket_size.\n    *\n-   * @param features_per_bucket: number of selected features per bucket\n+   * @param features_per_bucket: number of selected features per bucket.\n    */\n \n   void filterByBucketLocation(const cv::Mat &image, const int bucket_size,\n                               const int features_per_bucket);\n"
                },
                {
                    "date": 1646263491147,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -90,16 +90,15 @@\n    */\n   int size();\n };\n \n-// TODO @Alex7Li comment what the FeatureSet class does\n /**\n  * @brief A set of locations for image features and their ages.\n  */\n class FeatureSet {\n public:\n   /**\n-   * @brief The points stored in this set of features\n+   * @brief The points stored in this set of features.\n    */\n   std::vector<cv::Point2f> points;\n   /**\n    * @brief A parallel set to points; ages[i] contains\n"
                },
                {
                    "date": 1646263508481,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,9 +47,10 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n // TODO @Future change to different bucket sizes per axis\n-int BUCKETS_PER_AXIS = 10\n+int BUCKETS_X = 10\n+int BUCKETS_Y = 10\n /**\n  * @brief Maximum number of features per bucket\n  */\n int FEATURES_PER_BUCKET = 1;\n"
                },
                {
                    "date": 1646263523815,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,10 +47,10 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n // TODO @Future change to different bucket sizes per axis\n-int BUCKETS_X = 10\n-int BUCKETS_Y = 10\n+int BUCKETS_PER_ROW = 10\n+int BUCKETS_PER_COL = 10\n /**\n  * @brief Maximum number of features per bucket\n  */\n int FEATURES_PER_BUCKET = 1;\n"
                },
                {
                    "date": 1646263625402,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,10 +47,9 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n // TODO @Future change to different bucket sizes per axis\n-int BUCKETS_PER_ROW = 10\n-int BUCKETS_PER_COL = 10\n+int BUCKETS_PER_AXIS = 10\n /**\n  * @brief Maximum number of features per bucket\n  */\n int FEATURES_PER_BUCKET = 1;\n"
                }
            ],
            "date": 1646257211001,
            "name": "Commit-0",
            "content": "/****************************************************************\n *\n * @file \t\tvo.h\n *\n * @brief \t\tThe Visual Odometry class being used for\n translation. The math can be found in Haidar Jamal's Thesis:\n *https://www.ri.cmu.edu/publications/localization-for-lunar-micro-rovers/\n *\n * @version \t1.0\n * @date \t\t02/09/2022\n *\n * @authors \tBen Kolligs, Alex Li\n * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n *\n ****************************************************************/\n#include <ctype.h>\n#include <math.h>\n\n#include <algorithm>\n#include <chrono>\n#include <ctime>\n#include <fstream>\n#include <iostream>\n#include <iterator>\n#include <opencv2/calib3d/calib3d.hpp>\n#include <opencv2/features2d/features2d.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/opencv.hpp>\n#include <opencv2/video/tracking.hpp>\n#include <sstream>\n#include <string>\n#include <vector>\n\n#include \"Core\"\n#include \"Dense\"\n\nextern \"C\" {\n#include \"cfe_error.h\"\n#include \"common_types.h\"\n#include \"pe_events.h\"\n}\n\nnamespace visual_odometry {\n/**\n * @brief Number of buckets along each axis of the image.\n * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n * buckets.\n */\n// TODO @Future change to different bucket sizes per axis\nint BUCKETS_PER_AXIS = 10\n/**\n * @brief Maximum number of features per bucket\n */\nint FEATURES_PER_BUCKET = 1;\n/**\n * @brief Ignore all features that have been around but not detected\n * for this many frames.\n */\nint AGE_THRESHOLD = 10;\n\n\n// TODO @Alex7Li comment what the Bucket class does\nclass Bucket {\npublic:\n  int id;\n  int max_size;\n\n  // TODO @Alex7Li comment what this is meant to store\n  FeatureSet features;\n\n  // TODO @Alex7Li name this\n  Bucket(int max_size);\n  ~Bucket();\n\n  /** //TODO @Alex7Li comment this\n   * @brief DESCRIPTION \n   *\n   * @param point DESCRIPTION\n   * @param age DESCRIPTION\n   */\n  void add_feature(const cv::Point2f point, const int age);\n\n  int size();\n};\n\n// TODO @Alex7Li comment what the FeatureSet class does\nclass FeatureSet {\npublic:\n  \n  // TODO @Alex7Li comment what this is meant to store\n  std::vector<cv::Point2f> points;\n  // TODO @Alex7Li comment what this is meant to store\n  std::vector<int> ages;\n  int size() { return points.size(); }\n  /**\n   * @brief Updates the feature set to only include a subset of the\n   * original features which give a good spread throughout the image.\n   *\n   * @param image only use for getting dimension of the image\n   *\n   * @param bucket_size bucket size in pixel is bucket_size*bucket_size\n   *\n   * @param features_per_bucket: number of selected features per bucket\n   */\n\n  void filterByBucketLocation(const cv::Mat &image, const int bucket_size,\n                              const int features_per_bucket);\n\n  /**\n   * @brief Apply a feature detection algorithm over the image to generate new\n   * features, and all all such features into this feature set.\n   *\n   * @param image //  TODO @Alex7Li Description\n   */\n  void appendFeaturesFromImage(const cv::Mat &image);\n};\n\nclass VisualOdometry {\nprivate:\n  /* number of frames seen so far. */\n  int frame_id = 0;\n  /* Projection matrices for the left and right cameras */\n  cv::Mat leftCameraProjection_, rightCameraProjection_;\n\n  /* Images at current and next time step */\n  cv::Mat imageRightT0_, imageLeftT0_;\n  cv::Mat imageRightT1_, imageLeftT1_;\n\n  /* Initial pose variables */\n  cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n  cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n  cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n\n  // TODO @Alex7Li What is this\n  cv::Mat trajectory = cv::Mat::zeros(600, 1200, CV_8UC3);\n\n  /* Set of features currently tracked. */\n  FeatureSet currentVOFeatures;\n\n  //  TODO @Alex7Li Comment this\n  void run();\n\npublic:\n  /**\n   * @brief Construct a new Visual Odometry object\n   *\n   * @param ProjMatrl Left camera projection matrix\n   *\n   * @param projMatrr Right camera projection matrix\n   */\n  VisualOdometry(const cv::Mat ProjMatrl, const cv::Mat projMatrr);\n\n  ~VisualOdometry();\n\n  /**\n   * @brief Process one time step of camera imagery and\n   * publish the result.\n   *\n   * @param image_left The left image from stereo camera\n   *\n   * @param image_right The right image from stereo camera\n   */\n  void stereo_callback(const cv::Mat &image_left, const cv::Mat &image_right);\n};\n\n/**\n * @brief Use the FAST feature detector to accumulate the features in image into\n * points.\n *\n * @param image The image we're detecting.\n *\n * @return A vector with the locations of all newly detected features.\n * //TODO @Alex7Li this does not return anything??\n */\nvoid featureDetectionFast(const cv::Mat image);\n\n/**\n * @brief Remove all points from the 4 point vectors that are out of frame\n * or have a status of 0 //TODO @Alex7Li also old??\n *\n * @param points[0..4] vectors of points to update based on status.\n * SHOULD ALL BE THE SAME SIZE AND REPRESENT //TODO @Alex7Li what do they represent\n *\n * @param ages Current ages of each of the points\n *\n * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n */\n// TODO @Alex7Li rename this\nvoid deleteUnmatchFeaturesCircle(\n    std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n    std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n    std::vector<cv::Point2f> &points4, std::vector<int> &ages\n    const std::vector<uchar> &status_all);\n\n/**\n * @brief Perform circular matching on  TODO @Alex7Li on what\n * Detect points not found in both cameras for both the previous and\n * current frame and remove them.\n */\n// TODO @Alex7Li separate out deleteUnmatchFeaturesCircle\nvoid circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1,\n                      cv::Mat img_r_1, std::vector<cv::Point2f> &points_l_0,\n                      std::vector<cv::Point2f> &points_r_0,\n                      std::vector<cv::Point2f> &points_l_1,\n                      std::vector<cv::Point2f> &points_r_1,\n                      std::vector<cv::Point2f> &points_l_0_return,\n                      FeatureSet &current_features);\n/**\n * @brief Compute the next pose from the current one\n * given the rotation and translation in the frame.\n * Essentially a multiplicationof homogeneous transforms.\n * \n * @param frame_pose The original position of the robot, will be modified.\n *\n * @param rotation The rotation to go through.\n *\n * @param translation_stereo The translation to go through.\n */\nvoid integrateOdometryStereo(cv::Mat &frame_pose,\n                             const cv::Mat &rotation,\n                             const cv::Mat &translation_stereo);\n/**\n * @brief Compute the three euler angles for a given rotation matrix.\n *\n * @param R A rotation matrix\n *\n * @return cv::Vec3f (x, y, z) euler angles for R.\n */\ncv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n/**\n * @brief Given two vectors of points, find the locations where they\n * differ.\n * \n * @param points_[1..2] The vectors of points to compare.\n *\n * @param threshold The distance at which to consider the points moved.\n *\n * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| <= threshold\n */\nstd::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                     const std::vector<cv::Point2f> &points_2,\n                     const int threshold);\n/**\n * @brief Update a vector of points, removing all of the points[i]\n * in which status[i] is false.\n * \n * @param points The vector of points to update\n *\n * @param status A vector indicating which points to remove.\n */\nvoid removeInvalidPoints(std::vector<cv::Point2f> &points,\n                         const std::vector<bool> &status);\n/**\n * @brief Compute the translation and rotation that needs to occur\n * to obtain the given world points from the camera input points\n * \n * @param cameraProjection Camera projection matrix\n *\n * @param cameraPoints Points from the perspective of the camera\n *\n * @param worldPoints Same points in the real world\n *\n * @param rotation Matrix to store the estimated rotation output in.\n *\n * @param translation Matrix to store the estimated translation in.\n */\nvoid cameraToWorld(cv::Mat &cameraProjection,\n                         std::vector<cv::Point2f> &cameraPoints,\n                         cv::Mat &worldPoints, cv::Mat &rotation,\n                         cv::Mat &translation);\n/**\n * // TODO @Alex7Li \n * @brief <<DESCRIBE>>\n * Calls many of the above functions in a pipeline.\n * a->b->c\n * \n * Input: 4 images and the set of currently tracked features, as\n * well as references to 4 vectors of points (by reference).\n * \n * @return: vectors of features shared between the 4 images.\n */\nvoid matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n                      const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n                      FeatureSet &currentVOFeatures,\n                      std::vector<cv::Point2f> &pointsLeftT0,\n                      std::vector<cv::Point2f> &pointsRightT0,\n                      std::vector<cv::Point2f> &pointsLeftT1,\n                      std::vector<cv::Point2f> &pointsRightT1);\n} // namespace visual_odometry\n"
        }
    ]
}