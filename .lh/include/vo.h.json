{
    "sourceFile": "include/vo.h",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 30,
            "patches": [
                {
                    "date": 1647377025058,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1647377044681,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,13 +79,14 @@\n /**\n  * @brief Maximum number of features per bucket\n  */\n int FEATURES_PER_BUCKET = 2;\n+\n /**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n-int AGE_THRESHOLD = 10;\n+int AGE_THRESHOLD = 15;\n \n /**\n  * @brief A set of locations for image features and their ages.\n  */\n"
                },
                {
                    "date": 1647378534869,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -101,8 +101,13 @@\n    * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n   int size() { return points.size(); }\n+  \n+  /*\n+   * Sort all of the features and their ages.\n+   */\n+  int sortFeatures() { return points.size(); }\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n"
                },
                {
                    "date": 1647378560240,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,12 +100,14 @@\n    * @brief A parallel set to points; ages[i] contains\n    * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n+\n   int size() { return points.size(); }\n   \n   /*\n-   * Sort all of the features and their ages.\n+   * Sort all of the features and their ages based on the\n+   * (x, y) tuple\n    */\n   int sortFeatures() { return points.size(); }\n   /**\n    * @brief Updates the feature set to only include a subset of the\n"
                },
                {
                    "date": 1647378580114,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,11 +103,12 @@\n   std::vector<int> ages;\n \n   int size() { return points.size(); }\n   \n-  /*\n-   * Sort all of the features and their ages based on the\n+  /**\n+   * @brief Sort all of the features and their ages based on the\n    * (x, y) tuple\n+   * \n    */\n   int sortFeatures() { return points.size(); }\n   /**\n    * @brief Updates the feature set to only include a subset of the\n"
                },
                {
                    "date": 1647378585641,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -108,9 +108,9 @@\n    * @brief Sort all of the features and their ages based on the\n    * (x, y) tuple\n    * \n    */\n-  int sortFeatures() { return points.size(); }\n+  int sortFeatures();\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n"
                },
                {
                    "date": 1647378617425,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -101,8 +101,14 @@\n    * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n \n+  /**\n+   * @brief Return the size of the feature set. Note that\n+   * points.size() == ages.size()\n+   * \n+   * @return int \n+   */\n   int size() { return points.size(); }\n   \n   /**\n    * @brief Sort all of the features and their ages based on the\n"
                },
                {
                    "date": 1647378631025,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n   /**\n    * @brief Return the size of the feature set. Note that\n    * points.size() == ages.size()\n    * \n-   * @return int \n+   * @return size: number of points in the set.\n    */\n   int size() { return points.size(); }\n   \n   /**\n"
                },
                {
                    "date": 1647378655834,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,23 +100,14 @@\n    * @brief A parallel set to points; ages[i] contains\n    * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n-\n-  /**\n-   * @brief Return the size of the feature set. Note that\n-   * points.size() == ages.size()\n-   * \n-   * @return size: number of points in the set.\n-   */\n   int size() { return points.size(); }\n   \n-  /**\n-   * @brief Sort all of the features and their ages based on the\n-   * (x, y) tuple\n-   * \n+  /*\n+   * Sort all of the features and their\n    */\n-  int sortFeatures();\n+  int sortFeatures() { return points.size(); }\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n"
                },
                {
                    "date": 1647378661318,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,14 +100,23 @@\n    * @brief A parallel set to points; ages[i] contains\n    * the number of iterations that points[i] has been around.\n    */\n   std::vector<int> ages;\n+\n+  /**\n+   * @brief Return the size of the feature set. Note that\n+   * points.size() == ages.size()\n+   * \n+   * @return size: number of points in the set.\n+   */\n   int size() { return points.size(); }\n   \n-  /*\n-   * Sort all of the features and their\n+  /**\n+   * @brief Sort all of the features and their ages based on the\n+   * (x, y) tuple\n+   * \n    */\n-  int sortFeatures() { return points.size(); }\n+  int sortFeatures();\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n"
                },
                {
                    "date": 1647378666546,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,9 @@\n    * @brief Sort all of the features and their ages based on the\n    * (x, y) tuple\n    * \n    */\n-  int sortFeatures();\n+  void sortFeatures();\n   /**\n    * @brief Updates the feature set to only include a subset of the\n    * original features which give a good spread throughout the image.\n    *\n"
                },
                {
                    "date": 1647378814246,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -169,8 +169,14 @@\n    */\n   int size();\n };\n \n+/**\n+ * @brief A comparator for points.\n+ * \n+ */\n+struct PointOrder{};\n+\n class VisualOdometry {\n private:\n   /* Number of frames seen so far. */\n   int frame_id = 0;\n"
                },
                {
                    "date": 1647378820924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,9 +171,8 @@\n };\n \n /**\n  * @brief A comparator for points.\n- * \n  */\n struct PointOrder{};\n \n class VisualOdometry {\n"
                },
                {
                    "date": 1647378864866,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -170,9 +170,10 @@\n   int size();\n };\n \n /**\n- * @brief A comparator for points.\n+ * @brief A comparator for cv::Point2f types.\n+ * It sorts first by the x coordinate, then the y.\n  */\n struct PointOrder{};\n \n class VisualOdometry {\n"
                },
                {
                    "date": 1647468451138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,22 +36,22 @@\n  \n /************\n  * ROS ONLY *\n  ************/\n-#include \"ros/ros.h\"\n-#include \"sensor_msgs/Image.h\"\n-#include \"std_msgs/Int32MultiArray.h\"\n-#include \"nav_msgs/Odometry.h\"\n-#include \"geometry_msgs/Quaternion.h\"\n-#include <tf/transform_broadcaster.h>\n-#include <message_filters/subscriber.h>\n-#include <message_filters/synchronizer.h>\n-#include <message_filters/sync_policies/approximate_time.h>\n-#include <cv_bridge/cv_bridge.h>\n+// #include \"ros/ros.h\"\n+// #include \"sensor_msgs/Image.h\"\n+// #include \"std_msgs/Int32MultiArray.h\"\n+// #include \"nav_msgs/Odometry.h\"\n+// #include \"geometry_msgs/Quaternion.h\"\n+// #include <tf/transform_broadcaster.h>\n+// #include <message_filters/subscriber.h>\n+// #include <message_filters/synchronizer.h>\n+// #include <message_filters/sync_policies/approximate_time.h>\n+// #include <cv_bridge/cv_bridge.h>\n \n-#include <eigen3/Eigen/Dense>\n-#include <eigen3/Eigen/Core>\n-#include <eigen3/Eigen/Geometry> \n+// #include <eigen3/Eigen/Dense>\n+// #include <eigen3/Eigen/Core>\n+// #include <eigen3/Eigen/Geometry> \n /* END ROS ONLY */\n \n /************\n  * CFS ONLY *\n"
                },
                {
                    "date": 1647543092630,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,8 +25,9 @@\n #include <iostream>\n #include <iterator>\n #include <opencv2/calib3d/calib3d.hpp>\n #include <opencv2/features2d/features2d.hpp>\n+#include <opencv2/xfeatures2d.hpp>\n #include <opencv2/highgui/highgui.hpp>\n #include <opencv2/imgproc/imgproc.hpp>\n #include <opencv2/opencv.hpp>\n #include <opencv2/video/tracking.hpp>\n"
                },
                {
                    "date": 1647543160296,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,8 +103,14 @@\n    */\n   std::vector<int> ages;\n \n   /**\n+   * @brief A parallel set to points; strengths[i] contains\n+   * the clarity of the features reported by the feature detector.\n+   */\n+  std::vector<int> strengths;\n+\n+  /**\n    * @brief Return the size of the feature set. Note that\n    * points.size() == ages.size()\n    * \n    * @return size: number of points in the set.\n"
                },
                {
                    "date": 1647543208682,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,15 +79,15 @@\n int BUCKETS_PER_AXIS = 10;\n /**\n  * @brief Maximum number of features per bucket\n  */\n-int FEATURES_PER_BUCKET = 2;\n+int FEATURES_PER_BUCKET = 4;\n \n /**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n-int AGE_THRESHOLD = 15;\n+int AGE_THRESHOLD = 10;\n \n /**\n  * @brief A set of locations for image features and their ages.\n  */\n"
                },
                {
                    "date": 1647543237430,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,19 +75,21 @@\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n // TODO @Future change to different bucket sizes per axis\n-int BUCKETS_PER_AXIS = 10;\n+const int BUCKETS_PER_AXIS = 10;\n /**\n  * @brief Maximum number of features per bucket\n  */\n-int FEATURES_PER_BUCKET = 4;\n+conts int FEATURES_PER_BUCKET = 4;\n \n /**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n-int AGE_THRESHOLD = 10;\n+const int AGE_THRESHOLD = 10;\n+const int FAST_THRESHOLD = 20;\n+const int \n \n /**\n  * @brief A set of locations for image features and their ages.\n  */\n"
                },
                {
                    "date": 1647543284104,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,14 @@\n */\n /* END CFS ONLY */\n \n namespace visual_odometry {\n+\n /**\n+ * @brief Number of buckets to divide the image into.\n+ */\n+const int BUCKET_START_ROW = 2;\n+/**\n  * @brief Number of buckets along each axis of the image.\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n  */\n@@ -79,9 +84,9 @@\n const int BUCKETS_PER_AXIS = 10;\n /**\n  * @brief Maximum number of features per bucket\n  */\n-conts int FEATURES_PER_BUCKET = 4;\n+const int FEATURES_PER_BUCKET = 4;\n \n /**\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n"
                },
                {
                    "date": 1647543464623,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,8 +74,9 @@\n /**\n  * @brief Number of buckets to divide the image into.\n  */\n const int BUCKET_START_ROW = 2;\n+\n /**\n  * @brief Number of buckets along each axis of the image.\n  * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n  * buckets.\n@@ -91,11 +92,15 @@\n  * @brief Ignore all features that have been around but not detected\n  * for this many frames.\n  */\n const int AGE_THRESHOLD = 10;\n+\n+/**\n+ * @brief Minimum confidence for the robot to report \n+ */\n const int FAST_THRESHOLD = 20;\n-const int \n \n+\n /**\n  * @brief A set of locations for image features and their ages.\n  */\n class FeatureSet {\n"
                },
                {
                    "date": 1647543494336,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -244,9 +244,9 @@\n  * @param image The image we're detecting.\n  *\n  * @return A vector with the locations of all newly detected features.\n  */\n-std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n+std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image, std::vector<float>& response_strengths);\n \n /**\n  * @brief Given parallel vectors of points, ages, and the status of those points,\n  * update the vectors by removing elements with a invalid status.\n"
                },
                {
                    "date": 1647543526232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -241,8 +241,9 @@\n  * @brief Use the FAST feature detector to accumulate the features in image into\n  * points.\n  *\n  * @param image The image we're detecting.\n+ * @param response_strengths: A vector to fill with the response strength of each newly detected feature.\n  *\n  * @return A vector with the locations of all newly detected features.\n  */\n std::vector<cv::Point2f> featureDetectionFast(const cv::Mat image, std::vector<float>& response_strengths);\n"
                },
                {
                    "date": 1647543627364,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -261,9 +261,9 @@\n  */\n void deleteFeaturesWithFailureStatus(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n-    std::vector<cv::Point2f> &points4, std::vector<int> &ages,\n+    std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n     const std::vector<bool> &status_all);\n \n /**\n  * @brief Perform circular matching on 4 images and\n"
                },
                {
                    "date": 1647543643961,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -254,9 +254,9 @@\n  *\n  * @param points[0..4] vectors of points to update based on status, each with\n  * the same length as status_all.\n  *\n- * @param ages Current ages of each of the points.\n+ * @param currentFeatures Current set of features we will need to update.\n  *\n  * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n  */\n void deleteFeaturesWithFailureStatus(\n"
                },
                {
                    "date": 1647544057211,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -175,8 +175,12 @@\n   Bucket(int max_size);\n   ~Bucket();\n \n   /**\n+   * @brief Compute the score of elements in this bucket.\n+   */\n+  int Bucket::compute_score(const int age, const int strength);\n+  /**\n    * @brief Add a feature to the bucket\n    *\n    * @param point The location of the feature to add\n    * @param age The number of iterations since this feature was detected.\n"
                },
                {
                    "date": 1647544178153,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -175,9 +175,12 @@\n   Bucket(int max_size);\n   ~Bucket();\n \n   /**\n-   * @brief Compute the score of elements in this bucket.\n+   * @brief Rank how good a feature is based on it's current\n+   * age and strength. Older points that have survived many\n+   * iterations are desirable, as are ones that were detected\n+   * strongly.\n    */\n   int Bucket::compute_score(const int age, const int strength);\n   /**\n    * @brief Add a feature to the bucket\n"
                },
                {
                    "date": 1647544219499,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,10 +186,11 @@\n    * @brief Add a feature to the bucket\n    *\n    * @param point The location of the feature to add\n    * @param age The number of iterations since this feature was detected.\n+   * @param strength The strength this feature was detected as.\n    */\n-  void add_feature(const cv::Point2f point, const int age);\n+  void add_feature(const cv::Point2f point, const int age, const int strength);\n   \n   /**\n    * @return int The size of the feature set\n    */\n"
                },
                {
                    "date": 1647544232332,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,9 +186,9 @@\n    * @brief Add a feature to the bucket\n    *\n    * @param point The location of the feature to add\n    * @param age The number of iterations since this feature was detected.\n-   * @param strength The strength this feature was detected as.\n+   * @param strength The strength of the detected feature.\n    */\n   void add_feature(const cv::Point2f point, const int age, const int strength);\n   \n   /**\n"
                },
                {
                    "date": 1647545784479,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -196,14 +196,8 @@\n    */\n   int size();\n };\n \n-/**\n- * @brief A comparator for cv::Point2f types.\n- * It sorts first by the x coordinate, then the y.\n- */\n-struct PointOrder{};\n-\n class VisualOdometry {\n private:\n   /* Number of frames seen so far. */\n   int frame_id = 0;\n"
                },
                {
                    "date": 1647547050592,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,14 +141,11 @@\n    *\n    * @param image only use for getting dimension of the image.\n    *\n    * @param bucket_size bucket size in pixel is bucket_size*bucket_size.\n-   *\n-   * @param features_per_bucket: number of selected features per bucket.\n    */\n \n-  void filterByBucketLocation(const cv::Mat &image, const int bucket_size,\n-                              const int features_per_bucket);\n+  void filterByBucketLocation(const cv::Mat &image, const int bucket_size);\n \n   /**\n    * @brief Apply a feature detection algorithm over the image to generate new\n    * features, and all all such features into this feature set.\n"
                }
            ],
            "date": 1647377025058,
            "name": "Commit-0",
            "content": "/****************************************************************\n *\n * @file \t\tvo.h\n *\n * @brief \t\tThe Visual Odometry class being used for\n translation. The math can be found in Haidar Jamal's Thesis:\n *https://www.ri.cmu.edu/publications/localization-for-lunar-micro-rovers/\n *\n * @version \t1.0\n * @date \t\t02/09/2022\n *\n * @authors \tBen Kolligs, Alex Li\n * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n *\n ****************************************************************/\n#ifndef VO_H__\n#define VO_H__\n#include <ctype.h>\n#include <math.h>\n\n#include <algorithm>\n#include <chrono>\n#include <ctime>\n#include <fstream>\n#include <iostream>\n#include <iterator>\n#include <opencv2/calib3d/calib3d.hpp>\n#include <opencv2/features2d/features2d.hpp>\n#include <opencv2/highgui/highgui.hpp>\n#include <opencv2/imgproc/imgproc.hpp>\n#include <opencv2/opencv.hpp>\n#include <opencv2/video/tracking.hpp>\n#include <sstream>\n#include <string>\n#include <vector>\n \n/************\n * ROS ONLY *\n ************/\n#include \"ros/ros.h\"\n#include \"sensor_msgs/Image.h\"\n#include \"std_msgs/Int32MultiArray.h\"\n#include \"nav_msgs/Odometry.h\"\n#include \"geometry_msgs/Quaternion.h\"\n#include <tf/transform_broadcaster.h>\n#include <message_filters/subscriber.h>\n#include <message_filters/synchronizer.h>\n#include <message_filters/sync_policies/approximate_time.h>\n#include <cv_bridge/cv_bridge.h>\n\n#include <eigen3/Eigen/Dense>\n#include <eigen3/Eigen/Core>\n#include <eigen3/Eigen/Geometry> \n/* END ROS ONLY */\n\n/************\n * CFS ONLY *\n ************/\n/*\n#include \"Core\"\n#include \"Dense\"\n\nextern \"C\" {\n#include \"cfe_error.h\"\n#include \"common_types.h\"\n#include \"pe_events.h\"\n}\n*/\n/* END CFS ONLY */\n\nnamespace visual_odometry {\n/**\n * @brief Number of buckets along each axis of the image.\n * In total, there will be BUCKETS_PER_AXIS * BUCKETS_PER_AXIS\n * buckets.\n */\n// TODO @Future change to different bucket sizes per axis\nint BUCKETS_PER_AXIS = 10;\n/**\n * @brief Maximum number of features per bucket\n */\nint FEATURES_PER_BUCKET = 2;\n/**\n * @brief Ignore all features that have been around but not detected\n * for this many frames.\n */\nint AGE_THRESHOLD = 10;\n\n/**\n * @brief A set of locations for image features and their ages.\n */\nclass FeatureSet {\npublic:\n  /**\n   * @brief The points stored in this set of features.\n   */\n  std::vector<cv::Point2f> points;\n  /**\n   * @brief A parallel set to points; ages[i] contains\n   * the number of iterations that points[i] has been around.\n   */\n  std::vector<int> ages;\n  int size() { return points.size(); }\n  /**\n   * @brief Updates the feature set to only include a subset of the\n   * original features which give a good spread throughout the image.\n   *\n   * @param image only use for getting dimension of the image.\n   *\n   * @param bucket_size bucket size in pixel is bucket_size*bucket_size.\n   *\n   * @param features_per_bucket: number of selected features per bucket.\n   */\n\n  void filterByBucketLocation(const cv::Mat &image, const int bucket_size,\n                              const int features_per_bucket);\n\n  /**\n   * @brief Apply a feature detection algorithm over the image to generate new\n   * features, and all all such features into this feature set.\n   *\n   * @param image The image to obtain all points from.\n   */\n  void appendFeaturesFromImage(const cv::Mat &image);\n};\n\n/**\n * @brief A class to allow storing a set of at most max_size\n * image features, and remove outdated features to satisfy this\n * constraint.\n **/\nclass Bucket {\npublic:\n  int max_size;\n\n  /**\n   * @brief The set of features stored in this bucket.\n   */\n  FeatureSet features;\n\n  Bucket(int max_size);\n  ~Bucket();\n\n  /**\n   * @brief Add a feature to the bucket\n   *\n   * @param point The location of the feature to add\n   * @param age The number of iterations since this feature was detected.\n   */\n  void add_feature(const cv::Point2f point, const int age);\n  \n  /**\n   * @return int The size of the feature set\n   */\n  int size();\n};\n\nclass VisualOdometry {\nprivate:\n  /* Number of frames seen so far. */\n  int frame_id = 0;\n  /* Projection matrices for the left and right cameras. */\n  cv::Mat leftCameraProjection_, rightCameraProjection_;\n\n  /* Images at current and next time step. */\n  cv::Mat imageRightT0_, imageLeftT0_;\n  cv::Mat imageRightT1_, imageLeftT1_;\n\n  /* Initial pose variables. */\n  cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n  cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n  cv::Mat frame_pose = cv::Mat::eye(4, 4, CV_64F);\n\n  /* Set of features currently tracked. */\n  FeatureSet currentVOFeatures;\n\npublic:\n  /**\n   * @brief Construct a new Visual Odometry object\n   *\n   * @param ProjMatrl Left camera projection matrix\n   *\n   * @param projMatrr Right camera projection matrix\n   */\n  VisualOdometry(const cv::Mat ProjMatrl, const cv::Mat projMatrr);\n\n  ~VisualOdometry();\n\n  /**\n   * @brief Process one time step of camera imagery and\n   * publish the result.\n   *\n   * @param image_left The left image from stereo camera\n   *\n   * @param image_right The right image from stereo camera\n   */\n  void stereo_callback(const cv::Mat &image_left, const cv::Mat &image_right);\n};\n\n/**\n * @brief Use the FAST feature detector to accumulate the features in image into\n * points.\n *\n * @param image The image we're detecting.\n *\n * @return A vector with the locations of all newly detected features.\n */\nstd::vector<cv::Point2f> featureDetectionFast(const cv::Mat image);\n\n/**\n * @brief Given parallel vectors of points, ages, and the status of those points,\n * update the vectors by removing elements with a invalid status.\n *\n * @param points[0..4] vectors of points to update based on status, each with\n * the same length as status_all.\n *\n * @param ages Current ages of each of the points.\n *\n * @param status_all a vector with 1 If the point is valid, and 0 if it should be discarded.\n */\nvoid deleteFeaturesWithFailureStatus(\n    std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n    std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n    std::vector<cv::Point2f> &points4, std::vector<int> &ages,\n    const std::vector<bool> &status_all);\n\n/**\n * @brief Perform circular matching on 4 images and\n * detect points not found in both cameras for both the previous and\n * current frame.\n * @param img_[0,3] Images of the same scene taken by different cameras at different times.\n * @param points_[0,3] Features of the scene detected by the cameras.\n * @param points_0_return The locations of points in points_0 after mapping them to\n * points_1, points_2, points_3, and then back to points_0.\n * @param current_features The current feature set to consider while performing\n * the circular matching.\n * @return matchingStatus An array parallel to the points arrays which is true\n *      at points that were matched correctly.\n */\nstd::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                        const cv::Mat img_2,\n                        const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                        std::vector<cv::Point2f> & points_1,\n                        std::vector<cv::Point2f> & points_2,\n                        std::vector<cv::Point2f> & points_3,\n                        std::vector<cv::Point2f> & points_0_return);\n\n/**\n * @brief Compute the next pose from the current one\n * given the rotation and translation in the frame.\n * Essentially a multiplication of homogeneous transforms.\n * \n * @param frame_pose The original position of the robot, will be modified.\n *\n * @param rotation The rotation to go through.\n *\n * @param translation_stereo The translation to go through.\n */\nvoid integrateOdometryStereo(cv::Mat &frame_pose,\n                             const cv::Mat &rotation,\n                             const cv::Mat &translation_stereo);\n/**\n * @brief Compute the three euler angles for a given rotation matrix.\n *\n * @param R A rotation matrix\n *\n * @return cv::Vec3f (x, y, z) euler angles for R.\n */\ncv::Vec3f rotationMatrixToEulerAngles(const cv::Mat &R);\n\n/**\n * @brief Given two vectors of points, find the locations where they\n * differ.\n * \n * @param points_[1..2] The vectors of points to compare.\n *\n * @param threshold The distance at which to consider the points moved.\n *\n * @return a vector v where v[i] is true iff |points_1[i] - points_2[i]| <= threshold\n */\nstd::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> &points_1,\n                     const std::vector<cv::Point2f> &points_2,\n                     const int threshold);\n\n/**\n * @brief Update a vector of points, removing all of the points[i]\n * in which status[i] is false.\n * \n * @param points The vector of points to update.\n *\n * @param status A vector indicating which points to remove.\n */\nvoid removeInvalidPoints(std::vector<cv::Point2f> &points,\n                         const std::vector<bool> &status);\n\n/**\n * @brief Compute the translation and rotation that needs to occur\n * to obtain the given world points from the camera input points\n * \n * @param cameraProjection Camera projection matrix\n *\n * @param cameraPoints Points from the perspective of the camera\n *\n * @param worldPoints Same points in the real world\n *\n * @param rotation Matrix to store the estimated rotation output in.\n *\n * @param translation Matrix to store the estimated translation in.\n */\nvoid cameraToWorld(const cv::Mat &cameraProjection,\n                const std::vector<cv::Point2f> &cameraPoints,\n                const cv::Mat &worldPoints, cv::Mat &rotation,\n                cv::Mat &translation);\n/**\n * @brief Given four images and the set of features used in the last\n * iteration, this method finds new features in the images and appends\n * each of the locations of the features in each image to 4 parallel vectors.\n * \n * Calls many of the above functions in a pipeline.\n * appendFeaturesFromImage -> filterByBucketLocation -> circularMatching -> \n * deleteFeaturesWithFailureStatus -> findUnmovedPoints -> removeInvalidPoints\n * \n * @param image[(Left)|(Right)][01]: Images from the left/right cameras at the last/current timestep.\n * @param currentVOFeatures: The set of currently tracked features, stored as a position in the LeftT0 image, will\n * be updated with newly detected features.\n * @param points[(Left)|(Right)][01]: references to 4 empty vectors of points to fill up with feature positions.\n */\nvoid matchingFeatures(const cv::Mat &imageLeftT0, const cv::Mat &imageRightT0,\n                      const cv::Mat &imageLeftT1, const cv::Mat &imageRightT1,\n                      FeatureSet &currentVOFeatures,\n                      std::vector<cv::Point2f> &pointsLeftT0,\n                      std::vector<cv::Point2f> &pointsRightT0,\n                      std::vector<cv::Point2f> &pointsLeftT1,\n                      std::vector<cv::Point2f> &pointsRightT1);\n} // namespace visual_odometry\n#endif\n"
        }
    ]
}