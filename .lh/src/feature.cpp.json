{
    "sourceFile": "src/feature.cpp",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 7,
            "patches": [
                {
                    "date": 1644010023652,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1644010154703,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,8 +205,10 @@\n                         status0, status1, status2, status3, current_features.ages);\n }\n #endif\n \n+// Update the current features by including at most features_per_bucket features per bucket of the original image,\n+// to ensure a good distribution of features throughout the image.\n void bucketingFeatures(cv::Mat& image, FeatureSet& current_features, int bucket_size, int features_per_bucket)\n {\n     // This function buckets features\n     // image: only use for getting dimension of the image\n@@ -250,9 +252,11 @@\n         }\n     }\n \n }\n-\n+/*\n+Update the current features with features detected in the given image.\n+*/\n void appendNewFeatures(cv::Mat& image, FeatureSet& current_features)\n {\n     std::vector<cv::Point2f>  points_new;\n     featureDetectionFast(image, points_new);\n"
                },
                {
                    "date": 1644296111526,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,8 +95,9 @@\n         cv::Point2f pt2 = points2.at(i- indexCorrection);\n         cv::Point2f pt3 = points3.at(i- indexCorrection);\n         cv::Point2f pt0_r = points0_return.at(i- indexCorrection);\n \n+        // Why are we only checking the 0 boundaries? What about pt3.x > the x size of the image?\n         if ((status3.at(i) == 0)||(pt3.x<0)||(pt3.y<0)||\n             (status2.at(i) == 0)||(pt2.x<0)||(pt2.y<0)||\n             (status1.at(i) == 0)||(pt1.x<0)||(pt1.y<0)||\n             (status0.at(i) == 0)||(pt0.x<0)||(pt0.y<0))   \n"
                },
                {
                    "date": 1644296153386,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,8 +104,10 @@\n         {\n             if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n             {\n                 status3.at(i) = 0;\n+                // Huh?? Why are we changing the status and then deleting the element at i? A bug??\n+\n             }\n             points0.erase (points0.begin() + (i - indexCorrection));\n             points1.erase (points1.begin() + (i - indexCorrection));\n             points2.erase (points2.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1644296260617,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,8 @@\n             if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n             {\n                 status3.at(i) = 0;\n                 // Huh?? Why are we changing the status and then deleting the element at i? A bug??\n-\n             }\n             points0.erase (points0.begin() + (i - indexCorrection));\n             points1.erase (points1.begin() + (i - indexCorrection));\n             points2.erase (points2.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1644296285496,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,8 +105,10 @@\n             if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n             {\n                 status3.at(i) = 0;\n                 // Huh?? Why are we changing the status and then deleting the element at i? A bug??\n+                // We don't even use status outside of this function so it seems to just\n+                // mess up the next iteration of the loop\n             }\n             points0.erase (points0.begin() + (i - indexCorrection));\n             points1.erase (points1.begin() + (i - indexCorrection));\n             points2.erase (points2.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1644296298694,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,10 +105,9 @@\n             if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n             {\n                 status3.at(i) = 0;\n                 // Huh?? Why are we changing the status and then deleting the element at i? A bug??\n-                // We don't even use status outside of this function so it seems to just\n-                // mess up the next iteration of the loop\n+                // We don't even use status outside of this function so it seems to do nothing\n             }\n             points0.erase (points0.begin() + (i - indexCorrection));\n             points1.erase (points1.begin() + (i - indexCorrection));\n             points2.erase (points2.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1644296311597,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,9 +95,9 @@\n         cv::Point2f pt2 = points2.at(i- indexCorrection);\n         cv::Point2f pt3 = points3.at(i- indexCorrection);\n         cv::Point2f pt0_r = points0_return.at(i- indexCorrection);\n \n-        // Why are we only checking the 0 boundaries? What about pt3.x > the x size of the image?\n+        // Why are we only checking the 0 boundaries? What about pt3.x > the x size of the image? ~Alex\n         if ((status3.at(i) == 0)||(pt3.x<0)||(pt3.y<0)||\n             (status2.at(i) == 0)||(pt2.x<0)||(pt2.y<0)||\n             (status1.at(i) == 0)||(pt1.x<0)||(pt1.y<0)||\n             (status0.at(i) == 0)||(pt0.x<0)||(pt0.y<0))   \n@@ -105,9 +105,9 @@\n             if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n             {\n                 status3.at(i) = 0;\n                 // Huh?? Why are we changing the status and then deleting the element at i? A bug??\n-                // We don't even use status outside of this function so it seems to do nothing\n+                // We don't even use status outside of this function so it seems to do nothing... ~Alex\n             }\n             points0.erase (points0.begin() + (i - indexCorrection));\n             points1.erase (points1.begin() + (i - indexCorrection));\n             points2.erase (points2.begin() + (i - indexCorrection));\n"
                }
            ],
            "date": 1644010023652,
            "name": "Commit-0",
            "content": "#include \"stereo_visual_odometry/feature.h\"\n#include \"stereo_visual_odometry/bucket.h\"\n\n#if USE_CUDA\nstatic void download(const cv::cuda::GpuMat& d_mat, std::vector<cv::Point2f>& vec)\n{\n    vec.resize(d_mat.cols);\n    cv::Mat mat(1, d_mat.cols, CV_32FC2, (void*)&vec[0]);\n    d_mat.download(mat);\n}\n\nstatic void download(const cv::cuda::GpuMat& d_mat, std::vector<uchar>& vec)\n{\n    vec.resize(d_mat.cols);\n    cv::Mat mat(1, d_mat.cols, CV_8UC1, (void*)&vec[0]);\n    d_mat.download(mat);\n}\n#endif\n\nvoid deleteUnmatchFeatures(std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1, std::vector<uchar>& status)\n{\n    //getting rid of points for which the KLT tracking failed or those who have gone outside the frame\n    int indexCorrection = 0;\n    for( int i=0; i<status.size(); i++)\n    {  \n        cv::Point2f pt = points1.at(i- indexCorrection);\n        if ((status.at(i) == 0)||(pt.x<0)||(pt.y<0))   \n        {\n            if((pt.x<0)||(pt.y<0))    \n            {\n                status.at(i) = 0;\n            }\n            points0.erase (points0.begin() + (i - indexCorrection));\n            points1.erase (points1.begin() + (i - indexCorrection));\n            indexCorrection++;\n        }\n    }\n}\n\nvoid featureDetectionFast(cv::Mat image, std::vector<cv::Point2f>& points)  \n{   \n    //uses FAST as for feature dection, modify parameters as necessary\n    std::vector<cv::KeyPoint> keypoints;\n    int fast_threshold = 20;\n    bool nonmaxSuppression = true;\n    cv::FAST(image, keypoints, fast_threshold, nonmaxSuppression);\n    cv::KeyPoint::convert(keypoints, points, std::vector<int>());\n}\n\nvoid featureDetectionGoodFeaturesToTrack(cv::Mat image, std::vector<cv::Point2f>& points)  \n{   \n    //uses GoodFeaturesToTrack for feature dection, modify parameters as necessary\n\n    int maxCorners = 5000;\n    double qualityLevel = 0.01;\n    double minDistance = 5.;\n    int blockSize = 3;\n    bool useHarrisDetector = false;\n    double k = 0.04;\n    cv::Mat mask;\n\n    cv::goodFeaturesToTrack( image, points, maxCorners, qualityLevel, minDistance, mask, blockSize, useHarrisDetector, k );\n}\n\n// void featureTracking(cv::Mat img_1, cv::Mat img_2, std::vector<cv::Point2f>& points1, std::vector<cv::Point2f>& points2, std::vector<uchar>& status)  \n// { \n//     //this function automatically gets rid of points for which tracking fails\n\n//     std::vector<float> err;                    \n//     cv::Size winSize=cv::Size(21,21); // TODO PARAM                                                                                      \n//     cv::TermCriteria termcrit=cv::TermCriteria(cv::TermCriteria::COUNT+cv::TermCriteria::EPS, 30, 0.01); // TODO PARAM\n\n//     calcOpticalFlowPyrLK(img_1, img_2, points1, points2, status, err, winSize, 3, termcrit, 0, 0.001); // TODO PARAM\n//     deleteUnmatchFeatures(points1, points2, status);\n// }\n\nvoid deleteUnmatchFeaturesCircle(std::vector<cv::Point2f>& points0, std::vector<cv::Point2f>& points1,\n                          std::vector<cv::Point2f>& points2, std::vector<cv::Point2f>& points3,\n                          std::vector<cv::Point2f>& points0_return,\n                          std::vector<uchar>& status0, std::vector<uchar>& status1,\n                          std::vector<uchar>& status2, std::vector<uchar>& status3,\n                          std::vector<int>& ages){\n\n    //getting rid of points for which the KLT tracking failed or those who have gone outside the frame\n    for (int i = 0; i < ages.size(); ++i)\n    {\n        ages[i] += 1;\n    }\n\n    int indexCorrection = 0;\n    for( int i=0; i<status3.size(); i++)\n    {  \n        cv::Point2f pt0 = points0.at(i- indexCorrection);\n        cv::Point2f pt1 = points1.at(i- indexCorrection);\n        cv::Point2f pt2 = points2.at(i- indexCorrection);\n        cv::Point2f pt3 = points3.at(i- indexCorrection);\n        cv::Point2f pt0_r = points0_return.at(i- indexCorrection);\n\n        if ((status3.at(i) == 0)||(pt3.x<0)||(pt3.y<0)||\n            (status2.at(i) == 0)||(pt2.x<0)||(pt2.y<0)||\n            (status1.at(i) == 0)||(pt1.x<0)||(pt1.y<0)||\n            (status0.at(i) == 0)||(pt0.x<0)||(pt0.y<0))   \n        {\n            if((pt0.x<0)||(pt0.y<0)||(pt1.x<0)||(pt1.y<0)||(pt2.x<0)||(pt2.y<0)||(pt3.x<0)||(pt3.y<0))    \n            {\n                status3.at(i) = 0;\n            }\n            points0.erase (points0.begin() + (i - indexCorrection));\n            points1.erase (points1.begin() + (i - indexCorrection));\n            points2.erase (points2.begin() + (i - indexCorrection));\n            points3.erase (points3.begin() + (i - indexCorrection));\n            points0_return.erase (points0_return.begin() + (i - indexCorrection));\n\n            ages.erase (ages.begin() + (i - indexCorrection));\n            indexCorrection++;\n        }\n\n    }  \n}\n\n\n//this function automatically gets rid of points for which tracking fails   \nvoid circularMatching(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1, cv::Mat img_r_1,\n                      std::vector<cv::Point2f>& points_l_0, std::vector<cv::Point2f>& points_r_0,\n                      std::vector<cv::Point2f>& points_l_1, std::vector<cv::Point2f>& points_r_1,\n                      std::vector<cv::Point2f>& points_l_0_return,\n                      FeatureSet& current_features) { \n      std::vector<float> err;         \n\n    cv::Size winSize=cv::Size(20,20); // Lucas-Kanade optical flow window size                                                                                          \n    cv::TermCriteria termcrit=cv::TermCriteria(cv::TermCriteria::COUNT+cv::TermCriteria::EPS, 30, 0.01);\n\n    std::vector<uchar> status0;\n    std::vector<uchar> status1;\n    std::vector<uchar> status2;\n    std::vector<uchar> status3;\n\n    clock_t tic = clock();\n    // sparse iterative version of the Lucas-Kanade optical flow in pyramids\n    calcOpticalFlowPyrLK(img_l_0, img_r_0, points_l_0, points_r_0, status0, err, winSize, 3, termcrit, 0, 0.001);\n    calcOpticalFlowPyrLK(img_r_0, img_r_1, points_r_0, points_r_1, status1, err, winSize, 3, termcrit, 0, 0.001);\n    calcOpticalFlowPyrLK(img_r_1, img_l_1, points_r_1, points_l_1, status2, err, winSize, 3, termcrit, 0, 0.001);\n    calcOpticalFlowPyrLK(img_l_1, img_l_0, points_l_1, points_l_0_return, status3, err, winSize, 3, termcrit, 0, 0.001);\n    clock_t toc = clock();\n    std::cerr << \"calcOpticalFlowPyrLK time: \" << float(toc - tic)/CLOCKS_PER_SEC*1000 << \"ms\" << std::endl;\n\n    deleteUnmatchFeaturesCircle(points_l_0, points_r_0, points_r_1, points_l_1, points_l_0_return,\n                        status0, status1, status2, status3, current_features.ages);\n\n    // std::cout << \"points : \" << points_l_0.size() << \" \"<< points_r_0.size() << \" \"<< points_r_1.size() << \" \"<< points_l_1.size() << \" \"<<std::endl;\n}\n\n#if USE_CUDA\nvoid circularMatching_gpu(cv::Mat img_l_0, cv::Mat img_r_0, cv::Mat img_l_1, cv::Mat img_r_1,\n                      std::vector<cv::Point2f>& points_l_0, std::vector<cv::Point2f>& points_r_0,\n                      std::vector<cv::Point2f>& points_l_1, std::vector<cv::Point2f>& points_r_1,\n                      std::vector<cv::Point2f>& points_l_0_return,\n                      FeatureSet& current_features) { \n  \n    //this function automatically gets rid of points for which tracking fails\n                    \n    cv::Size winSize=cv::Size(21,21);                                                                                             \n\n    std::vector<uchar> status0;\n    std::vector<uchar> status1;\n    std::vector<uchar> status2;\n    std::vector<uchar> status3;\n\n    clock_t tic_gpu = clock();\n    cv::Ptr<cv::cuda::SparsePyrLKOpticalFlow> d_pyrLK_sparse = cv::cuda::SparsePyrLKOpticalFlow::create(\n            winSize, 3, 30);\n    cv::cuda::GpuMat img_l_0_gpu(img_l_0);\n    cv::cuda::GpuMat img_r_0_gpu(img_r_0);\n    cv::cuda::GpuMat img_l_1_gpu(img_l_1);\n    cv::cuda::GpuMat img_r_1_gpu(img_r_1);\n    cv::cuda::GpuMat status0_gpu(status0);\n    cv::cuda::GpuMat status1_gpu(status1);\n    cv::cuda::GpuMat status2_gpu(status2);\n    cv::cuda::GpuMat status3_gpu(status3);\n    cv::cuda::GpuMat points_l_0_gpu(points_l_0);\n    cv::cuda::GpuMat points_r_0_gpu(points_r_0);\n    cv::cuda::GpuMat points_l_1_gpu(points_l_1);\n    cv::cuda::GpuMat points_r_1_gpu(points_r_1);\n    cv::cuda::GpuMat points_l_0_ret_gpu(points_l_0_return);\n\n    d_pyrLK_sparse->calc(img_l_0_gpu, img_r_0_gpu, points_l_0_gpu, points_r_0_gpu, status0_gpu);\n    d_pyrLK_sparse->calc(img_r_0_gpu, img_r_1_gpu, points_r_0_gpu, points_r_1_gpu, status1_gpu);\n    d_pyrLK_sparse->calc(img_r_1_gpu, img_l_1_gpu, points_r_1_gpu, points_l_1_gpu, status2_gpu);\n    d_pyrLK_sparse->calc(img_l_1_gpu, img_l_0_gpu, points_l_1_gpu, points_l_0_ret_gpu, status3_gpu);\n\n    download(status0_gpu, status0);\n    download(status1_gpu, status1);\n    download(status2_gpu, status2);\n    download(status3_gpu, status3);\n    download(points_l_0_gpu, points_l_0);\n    download(points_l_1_gpu, points_l_1);\n    download(points_r_0_gpu, points_r_0);\n    download(points_r_1_gpu, points_r_1);\n    download(points_l_0_ret_gpu, points_l_0_return);\n\n    clock_t toc_gpu = clock();\n    std::cerr << \"calcOpticalFlowPyrLK(CUDA)  time: \" << float(toc_gpu - tic_gpu)/CLOCKS_PER_SEC*1000 << \"ms\" << std::endl;\n\n    deleteUnmatchFeaturesCircle(points_l_0, points_r_0, points_r_1, points_l_1, points_l_0_return,\n                        status0, status1, status2, status3, current_features.ages);\n}\n#endif\n\nvoid bucketingFeatures(cv::Mat& image, FeatureSet& current_features, int bucket_size, int features_per_bucket)\n{\n    // This function buckets features\n    // image: only use for getting dimension of the image\n    // bucket_size: bucket size in pixel is bucket_size*bucket_size\n    // features_per_bucket: number of selected features per bucket\n    int image_height = image.rows;\n    int image_width = image.cols;\n    int buckets_nums_height = image_height/bucket_size;\n    int buckets_nums_width = image_width/bucket_size;\n    int buckets_number = buckets_nums_height * buckets_nums_width;\n\n    std::vector<Bucket> Buckets;\n\n    // initialize all the buckets\n    for (int buckets_idx_height = 0; buckets_idx_height <= buckets_nums_height; buckets_idx_height++)\n    {\n      for (int buckets_idx_width = 0; buckets_idx_width <= buckets_nums_width; buckets_idx_width++)\n      {\n        Buckets.push_back(Bucket(features_per_bucket));\n      }\n    }\n\n    // bucket all current features into buckets by their location\n    int buckets_nums_height_idx, buckets_nums_width_idx, buckets_idx;\n    for (int i = 0; i < current_features.points.size(); ++i)\n    {\n        buckets_nums_height_idx = current_features.points[i].y/bucket_size;\n        buckets_nums_width_idx = current_features.points[i].x/bucket_size;\n        buckets_idx = buckets_nums_height_idx*buckets_nums_width + buckets_nums_width_idx;\n        Buckets[buckets_idx].add_feature(current_features.points[i], current_features.ages[i]);\n    }\n\n    // get features back from buckets\n    current_features.clear();\n    for (int buckets_idx_height = 0; buckets_idx_height <= buckets_nums_height; buckets_idx_height++)\n    {\n        for (int buckets_idx_width = 0; buckets_idx_width <= buckets_nums_width; buckets_idx_width++)\n        {\n            buckets_idx = buckets_idx_height*buckets_nums_width + buckets_idx_width;\n            Buckets[buckets_idx].get_features(current_features);\n        }\n    }\n\n}\n\nvoid appendNewFeatures(cv::Mat& image, FeatureSet& current_features)\n{\n    std::vector<cv::Point2f>  points_new;\n    featureDetectionFast(image, points_new);\n    current_features.points.insert(current_features.points.end(), points_new.begin(), points_new.end());\n    std::vector<int>  ages_new(points_new.size(), 0);\n    current_features.ages.insert(current_features.ages.end(), ages_new.begin(), ages_new.end());\n}"
        }
    ]
}