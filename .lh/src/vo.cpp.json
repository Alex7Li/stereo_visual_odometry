{
    "sourceFile": "src/vo.cpp",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 203,
            "patches": [
                {
                    "date": 1647548849040,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1647548896261,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n  * @authors \tBen Kolligs, Alex Li\n  * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n  *\n  ****************************************************************/\n-#include \"../include/vo.h\"\n+#include \"vo.h\"\n \n namespace visual_odometry {\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n"
                },
                {
                    "date": 1647548908612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n  * @authors \tBen Kolligs, Alex Li\n  * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n  *\n  ****************************************************************/\n-#include \"vo.h\"\n+#include \"../include/vo.h\"\n \n namespace visual_odometry {\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n"
                },
                {
                    "date": 1647548983747,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -14,9 +14,9 @@\n  *\n  ****************************************************************/\n #include \"../include/vo.h\"\n \n-namespace visual_odometry {\n+using namespace visual_odometry;\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n   leftCameraProjection_ = leftCameraProjection;\n   rightCameraProjection_ = rightCameraProjection;\n@@ -346,5 +346,4 @@\n \n     // Update current tracked points.\n     currentVOFeatures.points = pointsLeftT1;\n   }\n-} // namespace visual_odometry\n"
                },
                {
                    "date": 1647549048660,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,8 +13,9 @@\n  * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n  *\n  ****************************************************************/\n #include \"../include/vo.h\"\n+#include \"feature_set.cpp\"\n \n using namespace visual_odometry;\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n"
                },
                {
                    "date": 1647549414607,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,9 +13,8 @@\n  * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n  *\n  ****************************************************************/\n #include \"../include/vo.h\"\n-#include \"feature_set.cpp\"\n \n using namespace visual_odometry;\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n"
                },
                {
                    "date": 1647549587268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,10 +141,11 @@\n       }\n     }\n   }\n \n-  std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, const cv::Mat img_2,\n-                        const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n+  std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1,\n+                        const cv::Mat img_2, const cv::Mat img_3,\n+                        std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n                         std::vector<cv::Point2f> & points_0_return) {\n"
                },
                {
                    "date": 1647549615838,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,15 +141,15 @@\n       }\n     }\n   }\n \n-  std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1,\n+std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                         const cv::Mat img_2, const cv::Mat img_3,\n                         std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n-                        std::vector<cv::Point2f> & points_0_return) {\n+                        std::vector<cv::Point2f> & points_0_return);\n     std::vector<float> err;\n \n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n"
                },
                {
                    "date": 1647549645034,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n                         std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n                         std::vector<cv::Point2f> & points_3,\n-                        std::vector<cv::Point2f> & points_0_return);\n+                        std::vector<cv::Point2f> & points_0_return) {\n     std::vector<float> err;\n \n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n"
                },
                {
                    "date": 1647549982440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -111,13 +111,13 @@\n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/feature.cpp\n   // --------------------------------\n \n-  void deleteFeaturesWithFailureStatus(\n-      std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n-      std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n-      std::vector<cv::Point2f> & points4, FeatureSet& current_features,\n-      const std::vector<bool> & status_all) {\n+void deleteFeaturesWithFailureStatus(\n+    std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n+    std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n+    std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n+    const std::vector<bool> &status_all);\n     // getting rid of points for which the KLT tracking failed or those who have\n     // gone outside the frame\n     int indexCorrection = 0;\n     for (int i = 0; i < status_all.size(); i++) {\n"
                },
                {
                    "date": 1647550030950,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,12 +116,12 @@\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n     const std::vector<bool> &status_all);\n-    // getting rid of points for which the KLT tracking failed or those who have\n-    // gone outside the frame\n-    int indexCorrection = 0;\n-    for (int i = 0; i < status_all.size(); i++) {\n+  // getting rid of points for which the KLT tracking failed or those who have\n+  // gone outside the frame\n+  int indexCorrection = 0;\n+  for (int i = 0; i < status_all.size(); i++) {\n       cv::Point2f pt0 = points0.at(i - indexCorrection);\n       cv::Point2f pt1 = points1.at(i - indexCorrection);\n       cv::Point2f pt2 = points2.at(i - indexCorrection);\n       cv::Point2f pt3 = points3.at(i - indexCorrection);\n"
                },
                {
                    "date": 1647550036752,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,9 +115,9 @@\n void deleteFeaturesWithFailureStatus(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n-    const std::vector<bool> &status_all);\n+    const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n   for (int i = 0; i < status_all.size(); i++) {\n"
                },
                {
                    "date": 1647550099074,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -134,10 +134,10 @@\n         points2.erase(points2.begin() + (i - indexCorrection));\n         points3.erase(points3.begin() + (i - indexCorrection));\n         points4.erase(points4.begin() + (i - indexCorrection));\n \n-        current_features.ages.erase(current_features.ages.begin() + (i - indexCorrection));\n-        current_features.strengths.erase(current_features.strengths.begin() + (i - indexCorrection));\n+        currentFeatures.ages.erase(currentFeatures.ages.begin() + (i - indexCorrection));\n+        currentFeatures.strengths.erase(currentFeatures.strengths.begin() + (i - indexCorrection));\n         indexCorrection++;\n       }\n     }\n   }\n"
                },
                {
                    "date": 1647550253615,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -314,9 +314,9 @@\n \n     pointsLeftT0 = currentVOFeatures.points;\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-    std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n+    std::vector<uchar> matchingStatus = visual_odometry::circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n"
                },
                {
                    "date": 1647550379510,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n       }\n     }\n   }\n \n-std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n+std::vector<uchar> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                         const cv::Mat img_2, const cv::Mat img_3,\n                         std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n@@ -314,9 +314,9 @@\n \n     pointsLeftT0 = currentVOFeatures.points;\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-    std::vector<uchar> matchingStatus = visual_odometry::circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n+    std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n"
                },
                {
                    "date": 1647550402576,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -232,9 +232,9 @@\n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/visualOdometry.cpp\n   // --------------------------------\n \n-  std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n+  std::vector<bool> visual_odometry::findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n                        const std::vector<cv::Point2f> & points_2,\n                        const int threshold) {\n     std::vector<bool> status;\n     int offset;\n"
                },
                {
                    "date": 1647550449415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -292,9 +292,9 @@\n \n     cv::Rodrigues(rvec, rotation);\n   }\n \n-  void matchingFeatures(\n+  void visual_odometry::matchingFeatures(\n       const cv::Mat &imageLeft_t0, const cv::Mat &imageRight_t0,\n       const cv::Mat &imageLeft_t1, const cv::Mat &imageRight_t1,\n       FeatureSet &currentVOFeatures, std::vector<cv::Point2f> &pointsLeftT0,\n       std::vector<cv::Point2f> &pointsRightT0,\n"
                },
                {
                    "date": 1647550463410,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -260,9 +260,9 @@\n         index++;\n       }\n     }\n   }\n-  void cameraToWorld(\n+  void visual_odometry::cameraToWorld(\n       const cv::Mat & cameraProjection,\n       const std::vector<cv::Point2f> & cameraPoints, const cv::Mat & worldPoints,\n       cv::Mat & rotation, cv::Mat & translation) {\n     // Calculate frame to frame transformation\n"
                },
                {
                    "date": 1647550473865,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -249,9 +249,9 @@\n     }\n     return status;\n   }\n \n-  void removeInvalidPoints(std::vector<cv::Point2f> & points,\n+  void visual_odometry::removeInvalidPoints(std::vector<cv::Point2f> & points,\n                            const std::vector<bool> &status) {\n     int index = 0;\n     for (int i = 0; i < status.size(); i++) {\n       if (status[i] == false) {\n"
                },
                {
                    "date": 1647550487576,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,9 +209,9 @@\n \n   // Calculates rotation matrix to euler angles\n   // The result is the same as MATLAB except the order\n   // of the euler angles ( x and z are swapped ).\n-  cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat & R) {\n+  cv::Vec3f visual_odometry::rotationMatrixToEulerAngles(const cv::Mat & R) {\n     float sy = sqrt(R.at<double>(0, 0) * R.at<double>(0, 0) +\n                     R.at<double>(1, 0) * R.at<double>(1, 0));\n \n     bool singular = sy < 1e-6;\n"
                },
                {
                    "date": 1647550493641,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -180,9 +180,9 @@\n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n   // --------------------------------\n \n-  void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+  void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                                const cv::Mat &translation_stereo) {\n     cv::Mat rigid_body_transformation;\n \n     cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n"
                },
                {
                    "date": 1647550503700,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -111,9 +111,9 @@\n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/feature.cpp\n   // --------------------------------\n \n-void deleteFeaturesWithFailureStatus(\n+void visual_odometry::deleteFeaturesWithFailureStatus(\n     std::vector<cv::Point2f> &points0, std::vector<cv::Point2f> &points1,\n     std::vector<cv::Point2f> &points2, std::vector<cv::Point2f> &points3,\n     std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n     const std::vector<bool> &status_all) {\n"
                },
                {
                    "date": 1647631351735,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,8 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n+    cout << xyz;\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647631376877,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    cout << xyz;\n+    printf(\"x %f y %f z %f\", xyz[0], xyz[1], xyz[2]);\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647631402090,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    printf(\"x %f y %f z %f\", xyz[0], xyz[1], xyz[2]);\n+    printf(\"x %f y %f z %f\", xyz(0), xyz(1), xyz(2));\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647631432105,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    printf(\"x %f y %f z %f\", xyz(0), xyz(1), xyz(2));\n+    printf(\"x %f y %f z %f\", xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647640837710,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,8 +39,9 @@\n \n     std::vector<cv::Point2f> pointsLeftT0, pointsRightT0, pointsLeftT1,\n         pointsRightT1;\n     \n+    std::cout << \"matching\" << std::endl;\n     matchingFeatures(imageLeftT0_, imageRightT0_, imageLeftT1_, imageRightT1_,\n                      currentVOFeatures, pointsLeftT0, pointsRightT0,\n                      pointsLeftT1, pointsRightT1);\n \n"
                },
                {
                    "date": 1647640861694,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,8 +54,9 @@\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n       return;\n     }\n+    std::cout << \"triang\" << std::endl;\n \n     // ---------------------\n     // Triangulate 3D Points\n     // ---------------------\n@@ -63,14 +64,16 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n \n+    std::cout << \"track\" << std::endl;\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n+    std::cout << \"integrate\" << std::endl;\n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n"
                },
                {
                    "date": 1647640932360,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -345,9 +345,9 @@\n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n \n-    for (int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n+    for (unsigned int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n       currentVOFeatures.ages[i] += 1;\n     }\n \n     // Update current tracked points.\n"
                },
                {
                    "date": 1647640956946,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -257,9 +257,9 @@\n \n   void visual_odometry::removeInvalidPoints(std::vector<cv::Point2f> & points,\n                            const std::vector<bool> &status) {\n     int index = 0;\n-    for (int i = 0; i < status.size(); i++) {\n+    for (unsigned int i = 0; i < status.size(); i++) {\n       if (status[i] == false) {\n         points.erase(points.begin() + index);\n       } else {\n         index++;\n"
                },
                {
                    "date": 1647640979065,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -326,9 +326,9 @@\n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     \n     // Only keep points that were matched correctly and are in the image bounds.\n-    for(int i = 0; i < status.size(); i++) {\n+    for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n               (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n               (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n"
                },
                {
                    "date": 1647640999050,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,13 +125,8 @@\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n   for (int i = 0; i < status_all.size(); i++) {\n-      cv::Point2f pt0 = points0.at(i - indexCorrection);\n-      cv::Point2f pt1 = points1.at(i - indexCorrection);\n-      cv::Point2f pt2 = points2.at(i - indexCorrection);\n-      cv::Point2f pt3 = points3.at(i - indexCorrection);\n-      cv::Point2f pt4 = points4.at(i - indexCorrection);\n       // no need to check bounds for pt4 since it's equal to pt0 at\n       // all valid locations\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647641038166,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,10 +125,8 @@\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n   for (int i = 0; i < status_all.size(); i++) {\n-      // no need to check bounds for pt4 since it's equal to pt0 at\n-      // all valid locations\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n         points2.erase(points2.begin() + (i - indexCorrection));\n@@ -332,8 +330,10 @@\n               (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n               (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n               (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n               ) {\n+      // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT at\n+      // all valid locations\n           status[i] = false;\n       }\n     }\n \n"
                },
                {
                    "date": 1647641049183,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -329,11 +329,11 @@\n               (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n               (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n               (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n               (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+              // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n+              // all valid locations\n               ) {\n-      // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT at\n-      // all valid locations\n           status[i] = false;\n       }\n     }\n \n"
                },
                {
                    "date": 1647641075614,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -167,9 +167,9 @@\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n     std::vector<uchar> status_all;\n-    for(int i = 0; i < status3.size(); i++) {\n+    for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n     return status_all;\n   }\n"
                },
                {
                    "date": 1647641112265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -300,8 +300,9 @@\n       std::vector<cv::Point2f> &pointsRightT1) {\n     \n     std::vector<cv::Point2f> pointsLeftReturn_t0; // feature points to check\n                                                   // circular matching validation\n+    std::cout << \"a\" << std::endl;\n     if(currentVOFeatures.size() < 4000) {\n         // update feature set with detected features from the image.\n         currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n     }\n"
                },
                {
                    "date": 1647641124782,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -305,8 +305,9 @@\n     if(currentVOFeatures.size() < 4000) {\n         // update feature set with detected features from the image.\n         currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n     }\n+    std::cout << \"b\" << std::endl;\n \n     // --------------------------------------------------------\n     // Feature tracking using KLT tracker, bucketing and circular matching.\n     // --------------------------------------------------------\n@@ -315,11 +316,13 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n+    std::cout << \"c\" << std::endl;\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n+    std::cout << \"d\" << std::endl;\n     \n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n"
                },
                {
                    "date": 1647641177955,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -124,9 +124,9 @@\n     const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n-  for (int i = 0; i < status_all.size(); i++) {\n+  for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n         points2.erase(points2.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647641186716,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -235,9 +235,9 @@\n                        const std::vector<cv::Point2f> & points_2,\n                        const int threshold) {\n     std::vector<bool> status;\n     int offset;\n-    for (int i = 0; i < points_1.size(); i++) {\n+    for (unsigned int i = 0; i < points_1.size(); i++) {\n       offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n                         std::abs(points_1[i].y - points_2[i].y));\n       if (offset > threshold) {\n         status.push_back(false);\n"
                },
                {
                    "date": 1647643009453,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -300,14 +300,12 @@\n       std::vector<cv::Point2f> &pointsRightT1) {\n     \n     std::vector<cv::Point2f> pointsLeftReturn_t0; // feature points to check\n                                                   // circular matching validation\n-    std::cout << \"a\" << std::endl;\n     if(currentVOFeatures.size() < 4000) {\n         // update feature set with detected features from the image.\n         currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n     }\n-    std::cout << \"b\" << std::endl;\n \n     // --------------------------------------------------------\n     // Feature tracking using KLT tracker, bucketing and circular matching.\n     // --------------------------------------------------------\n"
                },
                {
                    "date": 1647643107029,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -39,9 +39,8 @@\n \n     std::vector<cv::Point2f> pointsLeftT0, pointsRightT0, pointsLeftT1,\n         pointsRightT1;\n     \n-    std::cout << \"matching\" << std::endl;\n     matchingFeatures(imageLeftT0_, imageRightT0_, imageLeftT1_, imageRightT1_,\n                      currentVOFeatures, pointsLeftT0, pointsRightT0,\n                      pointsLeftT1, pointsRightT1);\n \n@@ -54,9 +53,8 @@\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n       return;\n     }\n-    std::cout << \"triang\" << std::endl;\n \n     // ---------------------\n     // Triangulate 3D Points\n     // ---------------------\n@@ -64,16 +62,14 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n \n-    std::cout << \"track\" << std::endl;\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n-    std::cout << \"integrate\" << std::endl;\n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n@@ -314,13 +310,11 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    std::cout << \"c\" << std::endl;\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    std::cout << \"d\" << std::endl;\n     \n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n"
                },
                {
                    "date": 1647643775440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,8 +155,9 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n+    cout << \"ah\";\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647643815293,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,10 +155,11 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    cout << \"ah\";\n+    std::cout << img_0.width << \" \" << im_1.width << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n"
                },
                {
                    "date": 1647643826669,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,9 +155,9 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    std::cout << img_0.width << \" \" << im_1.width << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n+    std::cout << img_0.width << \" \" << img_1.width << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647643837335,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,9 +155,9 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    std::cout << img_0.width << \" \" << img_1.width << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n+    std::cout << img_0.height << \" \" << img_1.height << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647643856585,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,9 +155,9 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    std::cout << img_0.height << \" \" << img_1.height << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n+    std::cout << img_0.rows << \" \" << img_1.rows << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647644400066,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,9 +155,10 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    std::cout << img_0.rows << \" \" << img_1.rows << \" \" << points_0.size() << \" \" << points_1.size() << std::endl;\n+    std::cout << img_0.rows << \" \" << img_0.rows << \" \" << points_0.size() << std::endl;\n+    std::cout << img_1.rows << \" \" << img_1.rows << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647647360659,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -158,15 +158,15 @@\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     std::cout << img_0.rows << \" \" << img_0.rows << \" \" << points_0.size() << std::endl;\n     std::cout << img_1.rows << \" \" << img_1.rows << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cout << \"ah\" << std::endl;\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n+    std::cout << \"ok\" << std::endl;\n     std::vector<uchar> status_all;\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1647647390815,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,9 +164,8 @@\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n-    std::cout << \"ok\" << std::endl;\n     std::vector<uchar> status_all;\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1647647403248,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -312,11 +312,13 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n+    std::cout << \"ok\" << std::endl;\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n+    std::cout << \"ok\" << std::endl;\n     \n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n@@ -333,16 +335,19 @@\n               ) {\n           status[i] = false;\n       }\n     }\n+    std::cout << \"ok\" << std::endl;\n \n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n+    std::cout << \"ok\" << std::endl;\n \n     for (unsigned int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n       currentVOFeatures.ages[i] += 1;\n     }\n \n+    std::cout << \"ok\" << std::endl;\n     // Update current tracked points.\n     currentVOFeatures.points = pointsLeftT1;\n   }\n"
                },
                {
                    "date": 1647647443039,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,12 +164,14 @@\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n+    std::cout << \"ok\" << std::endl;\n     std::vector<uchar> status_all;\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n+    std::cout << \"ok\" << std::endl;\n     return status_all;\n   }\n \n \n@@ -335,9 +337,9 @@\n               ) {\n           status[i] = false;\n       }\n     }\n-    std::cout << \"ok\" << std::endl;\n+    std::cout << \"kok\" << std::endl;\n \n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n"
                },
                {
                    "date": 1647647451465,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,19 +159,22 @@\n     std::cout << img_0.rows << \" \" << img_0.rows << \" \" << points_0.size() << std::endl;\n     std::cout << img_1.rows << \" \" << img_1.rows << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    std::cout << \"lok\" << std::endl;\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    std::cout << \"lok\" << std::endl;\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    std::cout << \"lok\" << std::endl;\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n-    std::cout << \"ok\" << std::endl;\n+    std::cout << \"lok\" << std::endl;\n     std::vector<uchar> status_all;\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n-    std::cout << \"ok\" << std::endl;\n+    std::cout << \"wok\" << std::endl;\n     return status_all;\n   }\n \n \n"
                },
                {
                    "date": 1647647466765,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,17 +159,13 @@\n     std::cout << img_0.rows << \" \" << img_0.rows << \" \" << points_0.size() << std::endl;\n     std::cout << img_1.rows << \" \" << img_1.rows << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cout << \"lok\" << std::endl;\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cout << \"lok\" << std::endl;\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cout << \"lok\" << std::endl;\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n-    std::cout << \"lok\" << std::endl;\n     std::vector<uchar> status_all;\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1647647477387,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,9 +164,9 @@\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n-    std::vector<uchar> status_all;\n+    std::vector<uchar> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n     std::cout << \"wok\" << std::endl;\n"
                },
                {
                    "date": 1647647495334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,8 +164,9 @@\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n+    assert(status0.size() == status1.size())\n     std::vector<uchar> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1647647508099,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,9 +164,11 @@\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n-    assert(status0.size() == status1.size())\n+    assert(status0.size() == status1.size());\n+    assert(status1.size() == status2.size());\n+    assert(status2.size() == status3.size());\n     std::vector<uchar> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1647647520410,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -171,9 +171,8 @@\n     std::vector<uchar> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n-    std::cout << \"wok\" << std::endl;\n     return status_all;\n   }\n \n \n"
                },
                {
                    "date": 1647647566471,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -315,13 +315,11 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    std::cout << \"ok\" << std::endl;\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    std::cout << \"ok\" << std::endl;\n     \n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n"
                },
                {
                    "date": 1647647619321,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,8 +120,9 @@\n     const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n+  cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647647631924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,9 +120,10 @@\n     const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n-  cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n+  std::cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n+  std::cout << status_all.size();\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647647638253,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -121,9 +121,9 @@\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   int indexCorrection = 0;\n   std::cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n-  std::cout << status_all.size();\n+  std::cout << status_all.size() << std::endl;\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647647680255,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -135,8 +135,9 @@\n         currentFeatures.strengths.erase(currentFeatures.strengths.begin() + (i - indexCorrection));\n         indexCorrection++;\n       }\n     }\n+    std::cout << \"free\" << std::endl;\n   }\n \n std::vector<uchar> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                         const cv::Mat img_2, const cv::Mat img_3,\n"
                },
                {
                    "date": 1647647687566,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -119,9 +119,9 @@\n     std::vector<cv::Point2f> &points4, FeatureSet &currentFeatures,\n     const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n-  int indexCorrection = 0;\n+  unsigned int indexCorrection = 0;\n   std::cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n   std::cout << status_all.size() << std::endl;\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n"
                },
                {
                    "date": 1647647717182,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -122,8 +122,10 @@\n   // gone outside the frame\n   unsigned int indexCorrection = 0;\n   std::cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n   std::cout << status_all.size() << std::endl;\n+  std::cout << currentFeatures.ages.size() << std::endl;\n+  std::cout << currentFeatures.strengths.size() << std::endl;\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n"
                },
                {
                    "date": 1647648099641,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,12 +120,8 @@\n     const std::vector<bool> &status_all) {\n   // getting rid of points for which the KLT tracking failed or those who have\n   // gone outside the frame\n   unsigned int indexCorrection = 0;\n-  std::cout << points0.size() << points1.size() << points2.size() << points3.size() << std::endl;\n-  std::cout << status_all.size() << std::endl;\n-  std::cout << currentFeatures.ages.size() << std::endl;\n-  std::cout << currentFeatures.strengths.size() << std::endl;\n   for (unsigned int i = 0; i < status_all.size(); i++) {\n       if ((status_all.at(i) == 0)) {\n         points0.erase(points0.begin() + (i - indexCorrection));\n         points1.erase(points1.begin() + (i - indexCorrection));\n@@ -137,9 +133,8 @@\n         currentFeatures.strengths.erase(currentFeatures.strengths.begin() + (i - indexCorrection));\n         indexCorrection++;\n       }\n     }\n-    std::cout << \"free\" << std::endl;\n   }\n \n std::vector<uchar> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                         const cv::Mat img_2, const cv::Mat img_3,\n"
                },
                {
                    "date": 1647648136059,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -336,19 +336,16 @@\n               ) {\n           status[i] = false;\n       }\n     }\n-    std::cout << \"kok\" << std::endl;\n \n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n-    std::cout << \"ok\" << std::endl;\n \n     for (unsigned int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n       currentVOFeatures.ages[i] += 1;\n     }\n \n-    std::cout << \"ok\" << std::endl;\n     // Update current tracked points.\n     currentVOFeatures.points = pointsLeftT1;\n   }\n"
                },
                {
                    "date": 1647648161904,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,10 +155,8 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n \n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    std::cout << img_0.rows << \" \" << img_0.rows << \" \" << points_0.size() << std::endl;\n-    std::cout << img_1.rows << \" \" << img_1.rows << \" \" << points_1.size() << std::endl;\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647648223867,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    printf(\"x %f y %f z %f\", xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n+    cout << \"x\" xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647657030382,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    cout << \"x\" xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n+    std::cout << \"x\" << xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647657685593,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    std::cout << \"x\" << xyz.at<float>(0), xyz.at<float>(1), xyz.at<float>(2));\n+    std::cout << \"x\" << xyz.at<float>(0) << \" y \" << xyz.at<float>(1) << \" z \" <<  xyz.at<float>(2);\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647657730188,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n  * @authors \tBen Kolligs, Alex Li\n  * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n  *\n  ****************************************************************/\n-#include \"../include/vo.h\"\n+#include \"vo.h\"\n \n using namespace visual_odometry;\n VisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                                const cv::Mat rightCameraProjection) {\n@@ -79,9 +79,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    std::cout << \"x\" << xyz.at<float>(0) << \" y \" << xyz.at<float>(1) << \" z \" <<  xyz.at<float>(2);\n+    std::cout << \"x\" << xyz.at<float>(0) << \" y \" << xyz.at<float>(1) << \" z \" << xyz.at<float>(2);\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1647657834181,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,9 +46,9 @@\n \n     // Set new images as old images.\n     imageLeftT0_ = imageLeftT1_;\n     imageRightT0_ = imageRightT1_;\n-\n+    dbg(currentVOFeatures.size());\n     if (currentVOFeatures.size() < 5) {\n       // There are not enough features to fully determine\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n"
                },
                {
                    "date": 1647658896701,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -316,9 +316,9 @@\n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    \n+    raise(SIGTRAP);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1647658912460,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -316,9 +316,9 @@\n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    raise(SIGTRAP);\n+    std::raise(SIGTRAP);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1647658928598,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -316,9 +316,8 @@\n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    std::raise(SIGTRAP);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1647659656987,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -303,8 +303,9 @@\n     if(currentVOFeatures.size() < 4000) {\n         // update feature set with detected features from the image.\n         currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n     }\n+    dbg(currentVOFeatures.size())\n \n     // --------------------------------------------------------\n     // Feature tracking using KLT tracker, bucketing and circular matching.\n     // --------------------------------------------------------\n"
                },
                {
                    "date": 1647659675938,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -314,8 +314,9 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n+    dbg(matchingStatus)\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     // Only keep points that were matched correctly and are in the image bounds.\n"
                },
                {
                    "date": 1647659686356,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -303,9 +303,8 @@\n     if(currentVOFeatures.size() < 4000) {\n         // update feature set with detected features from the image.\n         currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n     }\n-    dbg(currentVOFeatures.size())\n \n     // --------------------------------------------------------\n     // Feature tracking using KLT tracker, bucketing and circular matching.\n     // --------------------------------------------------------\n@@ -314,12 +313,13 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    dbg(matchingStatus)\n+    dbg(matchingStatus);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n+    dbg(status);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1647659861019,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -313,13 +313,13 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    dbg(matchingStatus);\n+    dbga(matchingStatus);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    dbg(status);\n+    dbga(status);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n       if(!matchingStatus[i] ||\n           (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1647659935813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -313,9 +313,9 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    dbga(matchingStatus);\n+    // dbga(matchingStatus);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     dbga(status);\n@@ -335,8 +335,9 @@\n               ) {\n           status[i] = false;\n       }\n     }\n+    dbga(status);\n \n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n"
                },
                {
                    "date": 1647660012659,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -320,17 +320,17 @@\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     dbga(status);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n-      if(!matchingStatus[i] ||\n-          (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-              (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n-              (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-              (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n-              (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-              (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n-              (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-              (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+      if(!matchingStatus[i]// ||\n+          // (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n+          //     (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+          //     (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n+          //     (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+          //     (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n+          //     (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+          //     (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n+          //     (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n               // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n               // all valid locations\n               ) {\n           status[i] = false;\n"
                },
                {
                    "date": 1647660194070,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -320,24 +320,23 @@\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     dbga(status);\n     // Only keep points that were matched correctly and are in the image bounds.\n     for(unsigned int i = 0; i < status.size(); i++) {\n-      if(!matchingStatus[i]// ||\n-          // (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-          //     (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n-          //     (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-          //     (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n-          //     (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-          //     (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n-          //     (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-          //     (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+      if(!matchingStatus[i] ||\n+          (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n+              (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+              (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n+              (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+              (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n+              (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+              (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n+              (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n               // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n               // all valid locations\n               ) {\n           status[i] = false;\n       }\n     }\n-    dbga(status);\n \n     deleteFeaturesWithFailureStatus(\n         pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n         currentVOFeatures, status);\n"
                },
                {
                    "date": 1647660225466,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -135,9 +135,9 @@\n       }\n     }\n   }\n \n-std::vector<uchar> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n+std::vector<bool> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n                         const cv::Mat img_2, const cv::Mat img_3,\n                         std::vector<cv::Point2f> & points_0,\n                         std::vector<cv::Point2f> & points_1,\n                         std::vector<cv::Point2f> & points_2,\n"
                },
                {
                    "date": 1647660231860,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -311,9 +311,9 @@\n \n     pointsLeftT0 = currentVOFeatures.points;\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-    std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n+    std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n     // dbga(matchingStatus);\n \n     // Check if circled back points are in range of original points.\n"
                },
                {
                    "date": 1647660239460,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -165,9 +165,9 @@\n     }\n     assert(status0.size() == status1.size());\n     assert(status1.size() == status2.size());\n     assert(status2.size() == status3.size());\n-    std::vector<uchar> status_all(status0.size());\n+    std::vector<bool> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n     return status_all;\n"
                },
                {
                    "date": 1647660281233,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -313,9 +313,9 @@\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n     std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    // dbga(matchingStatus);\n+    dbga(matchingStatus);\n \n     // Check if circled back points are in range of original points.\n     std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n     dbga(status);\n"
                },
                {
                    "date": 1647660704916,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,10 @@\n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n-\n+    cv::OutputArrayOfArrays pyramid0;\n+    cv::buildOpticalFlowPyramid(img_0, pyramid0)\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660744217,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,9 +154,9 @@\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::OutputArrayOfArrays pyramid0;\n-    cv::buildOpticalFlowPyramid(img_0, pyramid0)\n+    cv::buildOpticalFlowPyramid(img_0, pyramid0, 3, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660757354,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,9 +154,9 @@\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::OutputArrayOfArrays pyramid0;\n-    cv::buildOpticalFlowPyramid(img_0, pyramid0, 3, 3);\n+    cv::buildOpticalFlowPyramid(img_0, pyramid0, 21, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660822809,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,9 +154,9 @@\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::OutputArrayOfArrays pyramid0;\n-    cv::buildOpticalFlowPyramid(img_0, pyramid0, 21, 3);\n+    cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660850291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n-    cv::OutputArrayOfArrays pyramid0;\n+    cv::OutputArray pyramid0;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660863313,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n-    cv::OutputArray pyramid0;\n+    cv::OutputArrayOfArrays pyramid0 = nullptr;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660901293,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n-    cv::OutputArrayOfArrays pyramid0 = nullptr;\n+    cv::Mat pyramid0;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660909328,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -154,8 +154,9 @@\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::Mat pyramid0;\n+    cv::Mat pyramid1;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660915056,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -156,8 +156,9 @@\n     std::vector<uchar> status3;\n     cv::Mat pyramid0;\n     cv::Mat pyramid1;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n+    cv::buildOpticalFlowPyramid(img_0, pyramid1, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1647660922318,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -156,9 +156,9 @@\n     std::vector<uchar> status3;\n     cv::Mat pyramid0;\n     cv::Mat pyramid1;\n     cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n-    cv::buildOpticalFlowPyramid(img_0, pyramid1, winSize, 3);\n+    cv::buildOpticalFlowPyramid(img_1, pyramid1, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n"
                },
                {
                    "date": 1648059437693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -135,14 +135,14 @@\n       }\n     }\n   }\n \n-std::vector<bool> visual_odometry::circularMatching(const cv::Mat img_0, const cv::Mat img_1, \n-                        const cv::Mat img_2, const cv::Mat img_3,\n-                        std::vector<cv::Point2f> & points_0,\n-                        std::vector<cv::Point2f> & points_1,\n-                        std::vector<cv::Point2f> & points_2,\n-                        std::vector<cv::Point2f> & points_3,\n+std::vector<bool> visual_odometry::circularMatching(const cv::Mat imgLeft_t0, const cv::Mat imgRight_t0, \n+                        const cv::Mat imgLeft_t1, const cv::Mat imgRight_t1,\n+                        std::vector<cv::Point2f> & pointsLeft_t0,\n+                        std::vector<cv::Point2f> & pointsRight_t0,\n+                        std::vector<cv::Point2f> & pointsLeft_t1,\n+                        std::vector<cv::Point2f> & pointsRight_t1,\n                         std::vector<cv::Point2f> & points_0_return) {\n     std::vector<float> err;\n \n     cv::Size winSize =\n@@ -155,16 +155,16 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::Mat pyramid0;\n     cv::Mat pyramid1;\n-    cv::buildOpticalFlowPyramid(img_0, pyramid0, winSize, 3);\n-    cv::buildOpticalFlowPyramid(img_1, pyramid1, winSize, 3);\n+    cv::buildOpticalFlowPyramid(imgLeft_t0, pyramid0, winSize, 3);\n+    cv::buildOpticalFlowPyramid(imgRight_t0, pyramid1, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n-    calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n+    calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\\n\";\n     }\n     assert(status0.size() == status1.size());\n     assert(status1.size() == status2.size());\n"
                },
                {
                    "date": 1648059553436,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -158,14 +158,17 @@\n     cv::Mat pyramid1;\n     cv::buildOpticalFlowPyramid(imgLeft_t0, pyramid0, winSize, 3);\n     cv::buildOpticalFlowPyramid(imgRight_t0, pyramid1, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n+    \n+    std::cerr << \"Enter\" << std::endl;\n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    std::cerr << \"Exit\" << std::endl;\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n-      std::cerr << \"Size of returned points was not correct!!\\n\";\n+      std::cerr << \"Size of returned points was not correct!! << std::endl;\n     }\n     assert(status0.size() == status1.size());\n     assert(status1.size() == status2.size());\n     assert(status2.size() == status3.size());\n"
                },
                {
                    "date": 1648059560380,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -166,9 +166,9 @@\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     std::cerr << \"Exit\" << std::endl;\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n-      std::cerr << \"Size of returned points was not correct!! << std::endl;\n+      std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n     assert(status1.size() == status2.size());\n     assert(status2.size() == status3.size());\n"
                },
                {
                    "date": 1648059623482,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,12 +38,13 @@\n     imageRightT1_ = imageRight;\n \n     std::vector<cv::Point2f> pointsLeftT0, pointsRightT0, pointsLeftT1,\n         pointsRightT1;\n-    \n+    std::cout << \"AAAAA\" << std::endl;\n     matchingFeatures(imageLeftT0_, imageRightT0_, imageLeftT1_, imageRightT1_,\n                      currentVOFeatures, pointsLeftT0, pointsRightT0,\n                      pointsLeftT1, pointsRightT1);\n+    std::cout << \"BBBBB\" << std::endl;\n \n     // Set new images as old images.\n     imageLeftT0_ = imageLeftT1_;\n     imageRightT0_ = imageRightT1_;\n"
                },
                {
                    "date": 1648059669085,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,14 +160,14 @@\n     cv::buildOpticalFlowPyramid(imgLeft_t0, pyramid0, winSize, 3);\n     cv::buildOpticalFlowPyramid(imgRight_t0, pyramid1, winSize, 3);\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     \n-    std::cerr << \"Enter\" << std::endl;\n+    std::cout << \"Enter\" << std::endl;\n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cerr << \"Exit\" << std::endl;\n+    std::cout << \"Exit\" << std::endl;\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n"
                },
                {
                    "date": 1648060550281,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,14 +143,16 @@\n                         std::vector<cv::Point2f> & pointsRight_t0,\n                         std::vector<cv::Point2f> & pointsLeft_t1,\n                         std::vector<cv::Point2f> & pointsRight_t1,\n                         std::vector<cv::Point2f> & points_0_return) {\n+    std::cout << \"A\" << std::endl;\n     std::vector<float> err;\n \n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n     cv::TermCriteria termcrit = cv::TermCriteria(\n         cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 30, 0.01);\n+    std::cout << \"B\" << std::endl;\n \n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n"
                },
                {
                    "date": 1648060570810,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -320,8 +320,9 @@\n \n     pointsLeftT0 = currentVOFeatures.points;\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n+    std::cout << \"C\" << std::endl;\n     std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n     dbga(matchingStatus);\n \n"
                },
                {
                    "date": 1648060575927,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -320,9 +320,8 @@\n \n     pointsLeftT0 = currentVOFeatures.points;\n     if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-    std::cout << \"C\" << std::endl;\n     std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                      pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n     dbga(matchingStatus);\n \n"
                },
                {
                    "date": 1648060591276,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,9 +143,8 @@\n                         std::vector<cv::Point2f> & pointsRight_t0,\n                         std::vector<cv::Point2f> & pointsLeft_t1,\n                         std::vector<cv::Point2f> & pointsRight_t1,\n                         std::vector<cv::Point2f> & points_0_return) {\n-    std::cout << \"A\" << std::endl;\n     std::vector<float> err;\n \n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n@@ -158,18 +157,18 @@\n     std::vector<uchar> status2;\n     std::vector<uchar> status3;\n     cv::Mat pyramid0;\n     cv::Mat pyramid1;\n-    cv::buildOpticalFlowPyramid(imgLeft_t0, pyramid0, winSize, 3);\n-    cv::buildOpticalFlowPyramid(imgRight_t0, pyramid1, winSize, 3);\n+    // std::cout << \"A\" << std::endl;\n+    // cv::buildOpticalFlowPyramid(imgLeft_t0, pyramid0, winSize, 3);\n+    // cv::buildOpticalFlowPyramid(imgRight_t0, pyramid1, winSize, 3);\n+    // std::cout << \"A\" << std::endl;\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     \n-    std::cout << \"Enter\" << std::endl;\n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    std::cout << \"Exit\" << std::endl;\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n"
                },
                {
                    "date": 1648060647868,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,9 +149,8 @@\n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n     cv::TermCriteria termcrit = cv::TermCriteria(\n         cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 30, 0.01);\n-    std::cout << \"B\" << std::endl;\n \n     std::vector<uchar> status0;\n     std::vector<uchar> status1;\n     std::vector<uchar> status2;\n"
                },
                {
                    "date": 1648060678133,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,11 +163,15 @@\n     // std::cout << \"A\" << std::endl;\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     \n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    dbga(status0);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    dbga(status1);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    dbga(status2);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n+    dbga(status3);\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n"
                },
                {
                    "date": 1648060892386,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -170,8 +170,9 @@\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     dbga(status2);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     dbga(status3);\n+    dbga(err);\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n"
                },
                {
                    "date": 1648062354121,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,16 +163,11 @@\n     // std::cout << \"A\" << std::endl;\n     // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n     \n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    dbga(status0);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    dbga(status1);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    dbga(status2);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    dbga(status3);\n-    dbga(err);\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n     assert(status0.size() == status1.size());\n"
                },
                {
                    "date": 1648063284051,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -38,13 +38,11 @@\n     imageRightT1_ = imageRight;\n \n     std::vector<cv::Point2f> pointsLeftT0, pointsRightT0, pointsLeftT1,\n         pointsRightT1;\n-    std::cout << \"AAAAA\" << std::endl;\n     matchingFeatures(imageLeftT0_, imageRightT0_, imageLeftT1_, imageRightT1_,\n                      currentVOFeatures, pointsLeftT0, pointsRightT0,\n                      pointsLeftT1, pointsRightT1);\n-    std::cout << \"BBBBB\" << std::endl;\n \n     // Set new images as old images.\n     imageLeftT0_ = imageLeftT1_;\n     imageRightT0_ = imageRightT1_;\n"
                },
                {
                    "date": 1648063363507,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -175,181 +175,181 @@\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n     return status_all;\n-  }\n+}\n \n \n-  // --------------------------------\n-  // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n-  // --------------------------------\n+// --------------------------------\n+// https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n+// --------------------------------\n \n-  void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n-                               const cv::Mat &translation_stereo) {\n-    cv::Mat rigid_body_transformation;\n+void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+                              const cv::Mat &translation_stereo) {\n+  cv::Mat rigid_body_transformation;\n \n-    cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n+  cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n \n-    cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n-    cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n+  cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n+  cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n \n-    const double scale = sqrt((translation_stereo.at<double>(0)) *\n-                            (translation_stereo.at<double>(0)) +\n-                        (translation_stereo.at<double>(1)) *\n-                            (translation_stereo.at<double>(1)) +\n-                        (translation_stereo.at<double>(2)) *\n-                            (translation_stereo.at<double>(2)));\n+  const double scale = sqrt((translation_stereo.at<double>(0)) *\n+                          (translation_stereo.at<double>(0)) +\n+                      (translation_stereo.at<double>(1)) *\n+                          (translation_stereo.at<double>(1)) +\n+                      (translation_stereo.at<double>(2)) *\n+                          (translation_stereo.at<double>(2)));\n \n-    rigid_body_transformation = rigid_body_transformation.inv();\n-    if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n-    {\n-      frame_pose = frame_pose * rigid_body_transformation;\n-    } else {\n-      std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n-                << std::endl;\n-    }\n+  rigid_body_transformation = rigid_body_transformation.inv();\n+  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n+  {\n+    frame_pose = frame_pose * rigid_body_transformation;\n+  } else {\n+    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n+              << std::endl;\n   }\n+}\n \n-  // Calculates rotation matrix to euler angles\n-  // The result is the same as MATLAB except the order\n-  // of the euler angles ( x and z are swapped ).\n-  cv::Vec3f visual_odometry::rotationMatrixToEulerAngles(const cv::Mat & R) {\n-    float sy = sqrt(R.at<double>(0, 0) * R.at<double>(0, 0) +\n-                    R.at<double>(1, 0) * R.at<double>(1, 0));\n+// Calculates rotation matrix to euler angles\n+// The result is the same as MATLAB except the order\n+// of the euler angles ( x and z are swapped ).\n+cv::Vec3f visual_odometry::rotationMatrixToEulerAngles(const cv::Mat & R) {\n+  float sy = sqrt(R.at<double>(0, 0) * R.at<double>(0, 0) +\n+                  R.at<double>(1, 0) * R.at<double>(1, 0));\n \n-    bool singular = sy < 1e-6;\n+  bool singular = sy < 1e-6;\n \n-    float x, y, z;\n-    if (!singular) {\n-      x = atan2(R.at<double>(2, 1), R.at<double>(2, 2));\n-      y = atan2(-R.at<double>(2, 0), sy);\n-      z = atan2(R.at<double>(1, 0), R.at<double>(0, 0));\n-    } else {\n-      x = atan2(-R.at<double>(1, 2), R.at<double>(1, 1));\n-      y = atan2(-R.at<double>(2, 0), sy);\n-      z = 0;\n-    }\n-    return cv::Vec3f(x, y, z);\n+  float x, y, z;\n+  if (!singular) {\n+    x = atan2(R.at<double>(2, 1), R.at<double>(2, 2));\n+    y = atan2(-R.at<double>(2, 0), sy);\n+    z = atan2(R.at<double>(1, 0), R.at<double>(0, 0));\n+  } else {\n+    x = atan2(-R.at<double>(1, 2), R.at<double>(1, 1));\n+    y = atan2(-R.at<double>(2, 0), sy);\n+    z = 0;\n   }\n+  return cv::Vec3f(x, y, z);\n+}\n \n-  // --------------------------------\n-  // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/visualOdometry.cpp\n-  // --------------------------------\n+// --------------------------------\n+// https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/visualOdometry.cpp\n+// --------------------------------\n \n-  std::vector<bool> visual_odometry::findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n-                       const std::vector<cv::Point2f> & points_2,\n-                       const int threshold) {\n-    std::vector<bool> status;\n-    int offset;\n-    for (unsigned int i = 0; i < points_1.size(); i++) {\n-      offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n-                        std::abs(points_1[i].y - points_2[i].y));\n-      if (offset > threshold) {\n-        status.push_back(false);\n-      } else {\n-        status.push_back(true);\n-      }\n+std::vector<bool> visual_odometry::findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n+                      const std::vector<cv::Point2f> & points_2,\n+                      const int threshold) {\n+  std::vector<bool> status;\n+  int offset;\n+  for (unsigned int i = 0; i < points_1.size(); i++) {\n+    offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n+                      std::abs(points_1[i].y - points_2[i].y));\n+    if (offset > threshold) {\n+      status.push_back(false);\n+    } else {\n+      status.push_back(true);\n     }\n-    return status;\n   }\n+  return status;\n+}\n \n-  void visual_odometry::removeInvalidPoints(std::vector<cv::Point2f> & points,\n-                           const std::vector<bool> &status) {\n-    int index = 0;\n-    for (unsigned int i = 0; i < status.size(); i++) {\n-      if (status[i] == false) {\n-        points.erase(points.begin() + index);\n-      } else {\n-        index++;\n-      }\n+void visual_odometry::removeInvalidPoints(std::vector<cv::Point2f> & points,\n+                          const std::vector<bool> &status) {\n+  int index = 0;\n+  for (unsigned int i = 0; i < status.size(); i++) {\n+    if (status[i] == false) {\n+      points.erase(points.begin() + index);\n+    } else {\n+      index++;\n     }\n   }\n-  void visual_odometry::cameraToWorld(\n-      const cv::Mat & cameraProjection,\n-      const std::vector<cv::Point2f> & cameraPoints, const cv::Mat & worldPoints,\n-      cv::Mat & rotation, cv::Mat & translation) {\n-    // Calculate frame to frame transformation\n-    cv::Mat distCoeffs = cv::Mat::zeros(4, 1, CV_64FC1);\n-    cv::Mat rvec = cv::Mat::zeros(3, 1, CV_64FC1);\n-    cv::Mat intrinsic_matrix =\n-        (cv::Mat_<float>(3, 3) << cameraProjection.at<float>(0, 0),\n-         cameraProjection.at<float>(0, 1),\n-         cameraProjection.at<float>(0, 2),\n-         cameraProjection.at<float>(1, 0),\n-         cameraProjection.at<float>(1, 1),\n-         cameraProjection.at<float>(1, 2),\n-         cameraProjection.at<float>(1, 1),\n-         cameraProjection.at<float>(1, 2),\n-         cameraProjection.at<float>(1, 3));\n+}\n+void visual_odometry::cameraToWorld(\n+    const cv::Mat & cameraProjection,\n+    const std::vector<cv::Point2f> & cameraPoints, const cv::Mat & worldPoints,\n+    cv::Mat & rotation, cv::Mat & translation) {\n+  // Calculate frame to frame transformation\n+  cv::Mat distCoeffs = cv::Mat::zeros(4, 1, CV_64FC1);\n+  cv::Mat rvec = cv::Mat::zeros(3, 1, CV_64FC1);\n+  cv::Mat intrinsic_matrix =\n+      (cv::Mat_<float>(3, 3) << cameraProjection.at<float>(0, 0),\n+        cameraProjection.at<float>(0, 1),\n+        cameraProjection.at<float>(0, 2),\n+        cameraProjection.at<float>(1, 0),\n+        cameraProjection.at<float>(1, 1),\n+        cameraProjection.at<float>(1, 2),\n+        cameraProjection.at<float>(1, 1),\n+        cameraProjection.at<float>(1, 2),\n+        cameraProjection.at<float>(1, 3));\n \n-    int iterationsCount = 500; // number of Ransac iterations.\n-    float reprojectionError = .5; // maximum allowed distance to consider it an inlier.\n-    float confidence = 0.999; // RANSAC successful confidence.\n-    bool useExtrinsicGuess = true;\n-    int flags = cv::SOLVEPNP_ITERATIVE;\n+  int iterationsCount = 500; // number of Ransac iterations.\n+  float reprojectionError = .5; // maximum allowed distance to consider it an inlier.\n+  float confidence = 0.999; // RANSAC successful confidence.\n+  bool useExtrinsicGuess = true;\n+  int flags = cv::SOLVEPNP_ITERATIVE;\n \n-    cv::Mat inliers;\n-    cv::solvePnPRansac(worldPoints, cameraPoints, intrinsic_matrix, distCoeffs,\n-                       rvec, translation, useExtrinsicGuess, iterationsCount,\n-                       reprojectionError, confidence, inliers, flags);\n+  cv::Mat inliers;\n+  cv::solvePnPRansac(worldPoints, cameraPoints, intrinsic_matrix, distCoeffs,\n+                      rvec, translation, useExtrinsicGuess, iterationsCount,\n+                      reprojectionError, confidence, inliers, flags);\n \n-    cv::Rodrigues(rvec, rotation);\n+  cv::Rodrigues(rvec, rotation);\n+}\n+\n+void visual_odometry::matchingFeatures(\n+    const cv::Mat &imageLeft_t0, const cv::Mat &imageRight_t0,\n+    const cv::Mat &imageLeft_t1, const cv::Mat &imageRight_t1,\n+    FeatureSet &currentVOFeatures, std::vector<cv::Point2f> &pointsLeftT0,\n+    std::vector<cv::Point2f> &pointsRightT0,\n+    std::vector<cv::Point2f> &pointsLeftT1,\n+    std::vector<cv::Point2f> &pointsRightT1) {\n+  \n+  std::vector<cv::Point2f> pointsLeftReturn_t0; // feature points to check\n+                                                // circular matching validation\n+  if(currentVOFeatures.size() < 4000) {\n+      // update feature set with detected features from the image.\n+      currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n   }\n \n-  void visual_odometry::matchingFeatures(\n-      const cv::Mat &imageLeft_t0, const cv::Mat &imageRight_t0,\n-      const cv::Mat &imageLeft_t1, const cv::Mat &imageRight_t1,\n-      FeatureSet &currentVOFeatures, std::vector<cv::Point2f> &pointsLeftT0,\n-      std::vector<cv::Point2f> &pointsRightT0,\n-      std::vector<cv::Point2f> &pointsLeftT1,\n-      std::vector<cv::Point2f> &pointsRightT1) {\n-    \n-    std::vector<cv::Point2f> pointsLeftReturn_t0; // feature points to check\n-                                                  // circular matching validation\n-    if(currentVOFeatures.size() < 4000) {\n-        // update feature set with detected features from the image.\n-        currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n-    }\n+  // --------------------------------------------------------\n+  // Feature tracking using KLT tracker, bucketing and circular matching.\n+  // --------------------------------------------------------\n \n-    // --------------------------------------------------------\n-    // Feature tracking using KLT tracker, bucketing and circular matching.\n-    // --------------------------------------------------------\n+  pointsLeftT0 = currentVOFeatures.points;\n+  if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-    pointsLeftT0 = currentVOFeatures.points;\n-    if (currentVOFeatures.points.size() == 0) return; // early exit\n+  std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n+                    pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n+  dbga(matchingStatus);\n \n-    std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n-                     pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-    dbga(matchingStatus);\n-\n-    // Check if circled back points are in range of original points.\n-    std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n-    dbga(status);\n-    // Only keep points that were matched correctly and are in the image bounds.\n-    for(unsigned int i = 0; i < status.size(); i++) {\n-      if(!matchingStatus[i] ||\n-          (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-              (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n-              (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-              (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n-              (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-              (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n-              (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-              (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n-              // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n-              // all valid locations\n-              ) {\n-          status[i] = false;\n-      }\n+  // Check if circled back points are in range of original points.\n+  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n+  dbga(status);\n+  // Only keep points that were matched correctly and are in the image bounds.\n+  for(unsigned int i = 0; i < status.size(); i++) {\n+    if(!matchingStatus[i] ||\n+        (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n+            (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+            (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n+            (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+            (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n+            (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+            (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n+            (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+            // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n+            // all valid locations\n+            ) {\n+        status[i] = false;\n     }\n+  }\n \n-    deleteFeaturesWithFailureStatus(\n-        pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n-        currentVOFeatures, status);\n+  deleteFeaturesWithFailureStatus(\n+      pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n+      currentVOFeatures, status);\n \n-    for (unsigned int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n-      currentVOFeatures.ages[i] += 1;\n-    }\n+  for (unsigned int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n+    currentVOFeatures.ages[i] += 1;\n+  }\n \n-    // Update current tracked points.\n-    currentVOFeatures.points = pointsLeftT1;\n-  }\n+  // Update current tracked points.\n+  currentVOFeatures.points = pointsLeftT1;\n+}\n"
                },
                {
                    "date": 1648071637462,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -251,19 +251,8 @@\n   }\n   return status;\n }\n \n-void visual_odometry::removeInvalidPoints(std::vector<cv::Point2f> & points,\n-                          const std::vector<bool> &status) {\n-  int index = 0;\n-  for (unsigned int i = 0; i < status.size(); i++) {\n-    if (status[i] == false) {\n-      points.erase(points.begin() + index);\n-    } else {\n-      index++;\n-    }\n-  }\n-}\n void visual_odometry::cameraToWorld(\n     const cv::Mat & cameraProjection,\n     const std::vector<cv::Point2f> & cameraPoints, const cv::Mat & worldPoints,\n     cv::Mat & rotation, cv::Mat & translation) {\n"
                },
                {
                    "date": 1648071800250,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -236,9 +236,9 @@\n // --------------------------------\n \n std::vector<bool> visual_odometry::findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n                       const std::vector<cv::Point2f> & points_2,\n-                      const int threshold) {\n+                      const float threshold) {\n   std::vector<bool> status;\n   int offset;\n   for (unsigned int i = 0; i < points_1.size(); i++) {\n     offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n"
                },
                {
                    "date": 1648071815132,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -238,9 +238,9 @@\n std::vector<bool> visual_odometry::findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n                       const std::vector<cv::Point2f> & points_2,\n                       const float threshold) {\n   std::vector<bool> status;\n-  int offset;\n+  float offset;\n   for (unsigned int i = 0; i < points_1.size(); i++) {\n     offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n                       std::abs(points_1[i].y - points_2[i].y));\n     if (offset > threshold) {\n"
                },
                {
                    "date": 1648071823210,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -310,9 +310,9 @@\n                     pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n   dbga(matchingStatus);\n \n   // Check if circled back points are in range of original points.\n-  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n+  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0.5);\n   dbga(status);\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n"
                },
                {
                    "date": 1648072341575,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -203,8 +203,9 @@\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n+    dbg(scale);\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n   }\n }\n"
                },
                {
                    "date": 1648072421776,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,13 +199,13 @@\n                       (translation_stereo.at<double>(2)) *\n                           (translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n+  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n-    dbg(scale);\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n   }\n }\n"
                },
                {
                    "date": 1648072563397,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,9 @@\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    std::cout << \"x\" << xyz.at<float>(0) << \" y \" << xyz.at<float>(1) << \" z \" << xyz.at<float>(2);\n+    std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n"
                },
                {
                    "date": 1648072597138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -308,13 +308,11 @@\n   if (currentVOFeatures.points.size() == 0) return; // early exit\n \n   std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                     pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n-  dbga(matchingStatus);\n \n   // Check if circled back points are in range of original points.\n   std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0.5);\n-  dbga(status);\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1648072681367,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,9 +199,8 @@\n                       (translation_stereo.at<double>(2)) *\n                           (translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n"
                },
                {
                    "date": 1648072700803,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,8 +199,9 @@\n                       (translation_stereo.at<double>(2)) *\n                           (translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n+  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n"
                },
                {
                    "date": 1648072839767,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -181,12 +181,21 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-\n+bool isRotationMatrix(cv::Mat &R)\n+{\n+    cv::Mat Rt;\n+    transpose(R, Rt);\n+    cv::Mat shouldBeIdentity = Rt * R;\n+    cv::Mat I = cv::Mat::eye(3,3, shouldBeIdentity.type());\n+     \n+    return  norm(I, shouldBeIdentity) < 1e-6;\n+}\n void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                               const cv::Mat &translation_stereo) {\n   cv::Mat rigid_body_transformation;\n+  assert(isRotationMatrix(rotation));\n \n   cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n \n   cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n"
                },
                {
                    "date": 1648072850862,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -181,9 +181,9 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-bool isRotationMatrix(cv::Mat &R)\n+bool isRotationMatrix(const cv::Mat &R)\n {\n     cv::Mat Rt;\n     transpose(R, Rt);\n     cv::Mat shouldBeIdentity = Rt * R;\n"
                },
                {
                    "date": 1648072974451,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -200,14 +200,14 @@\n \n   cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n   cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n \n-  const double scale = sqrt((translation_stereo.at<double>(0)) *\n-                          (translation_stereo.at<double>(0)) +\n-                      (translation_stereo.at<double>(1)) *\n-                          (translation_stereo.at<double>(1)) +\n-                      (translation_stereo.at<double>(2)) *\n-                          (translation_stereo.at<double>(2)));\n+  const double scale = sqrt((translation_stereo.at<double>(0) *\n+                          translation_stereo.at<double>(0)) +\n+                      (translation_stereo.at<double>(1) *\n+                          translation_stereo.at<double>(1)) +\n+                      (translation_stereo.at<double>(2) *\n+                          translation_stereo.at<double>(2));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n"
                },
                {
                    "date": 1648072980114,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,9 +205,9 @@\n                           translation_stereo.at<double>(0)) +\n                       (translation_stereo.at<double>(1) *\n                           translation_stereo.at<double>(1)) +\n                       (translation_stereo.at<double>(2) *\n-                          translation_stereo.at<double>(2));\n+                          translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n"
                },
                {
                    "date": 1648072992471,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -200,14 +200,12 @@\n \n   cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n   cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n \n-  const double scale = sqrt((translation_stereo.at<double>(0) *\n-                          translation_stereo.at<double>(0)) +\n-                      (translation_stereo.at<double>(1) *\n-                          translation_stereo.at<double>(1)) +\n-                      (translation_stereo.at<double>(2) *\n-                          translation_stereo.at<double>(2)));\n+  const double scale = sqrt(\n+    (translation_stereo.at<double>(0) * translation_stereo.at<double>(0)) +\n+    (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n+    (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n"
                },
                {
                    "date": 1648074293875,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,10 +77,10 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n+    std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n-    std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n \n     // publish\n     // if (true) {\n     //     static tf::TransformBroadcaster br;\n@@ -206,8 +206,10 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n+  cv::Mat xyz = frame_pose.col(3).clone();\n+  std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n"
                },
                {
                    "date": 1648074405886,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -206,10 +206,10 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  cv::Mat xyz = frame_pose.col(3).clone();\n-  std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n+  cv::Mat xyz = frame_pose.col(3);\n+  std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n"
                },
                {
                    "date": 1648074413700,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    std::cout << \"x:\" << xyz.at<float>(0) << \" y:\" << xyz.at<float>(1) << \" z:\" << xyz.at<float>(2) << std::endl;\n+    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n"
                },
                {
                    "date": 1648074488445,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -206,14 +206,16 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  cv::Mat xyz = frame_pose.col(3);\n-  std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n+    cv::Mat xyz = frame_pose.col(3);\n+    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     frame_pose = frame_pose * rigid_body_transformation;\n+    frame_pose.col(3);\n+    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n   } else {\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n   }\n"
                },
                {
                    "date": 1648074495206,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -212,9 +212,9 @@\n   {\n     cv::Mat xyz = frame_pose.col(3);\n     std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     frame_pose = frame_pose * rigid_body_transformation;\n-    frame_pose.col(3);\n+    xyz = frame_pose.col(3);\n     std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n   } else {\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n"
                },
                {
                    "date": 1648074561077,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,8 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n@@ -209,9 +208,9 @@\n   rigid_body_transformation = rigid_body_transformation.inv();\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n-    cv::Mat xyz = frame_pose.col(3);\n+    cv::Mat xyz = rigid_body_transformation.col(3);\n     std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     frame_pose = frame_pose * rigid_body_transformation;\n     xyz = frame_pose.col(3);\n     std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n"
                },
                {
                    "date": 1648074582544,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -209,12 +209,9 @@\n   dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     cv::Mat xyz = rigid_body_transformation.col(3);\n-    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n     frame_pose = frame_pose * rigid_body_transformation;\n-    xyz = frame_pose.col(3);\n-    std::cout << \"x:\" << xyz.at<double>(0) << \" y:\" << xyz.at<double>(1) << \" z:\" << xyz.at<double>(2) << std::endl;\n   } else {\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n   }\n"
                },
                {
                    "date": 1648074590539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,9 +205,8 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     cv::Mat xyz = rigid_body_transformation.col(3);\n     frame_pose = frame_pose * rigid_body_transformation;\n"
                },
                {
                    "date": 1648074607294,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -205,11 +205,11 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n+  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n-    cv::Mat xyz = rigid_body_transformation.col(3);\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n               << std::endl;\n"
                },
                {
                    "date": 1648074629813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,8 +77,9 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n+    cout << xyz<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n@@ -205,9 +206,8 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  dbg(scale);\n   if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n"
                },
                {
                    "date": 1648074658734,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    cout << xyz<double>(0);\n+    std::cout << xyz<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n"
                },
                {
                    "date": 1648074676341,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    std::cout << xyz<double>(0);\n+    std::cout << xyz.at()<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n"
                },
                {
                    "date": 1648148684866,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n         abs(rotation_euler[2]) < 0.1) {\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    std::cout << xyz.at()<double>(0);\n+    std::cout << xyz.at<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n@@ -129,8 +129,9 @@\n         points4.erase(points4.begin() + (i - indexCorrection));\n \n         currentFeatures.ages.erase(currentFeatures.ages.begin() + (i - indexCorrection));\n         currentFeatures.strengths.erase(currentFeatures.strengths.begin() + (i - indexCorrection));\n+        currentFeatures.points.erase(currentFeatures.points.begin() + (i - indexCorrection));\n         indexCorrection++;\n       }\n     }\n   }\n"
                },
                {
                    "date": 1648149371248,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -168,11 +168,8 @@\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n       std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n     }\n-    assert(status0.size() == status1.size());\n-    assert(status1.size() == status2.size());\n-    assert(status2.size() == status3.size());\n     std::vector<bool> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1648149379277,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -165,11 +165,8 @@\n     calcOpticalFlowPyrLK(imgLeft_t0, imgRight_t0, pointsLeft_t0, pointsRight_t0, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t0, imgRight_t1, pointsRight_t0, pointsRight_t1, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgRight_t1, imgLeft_t1, pointsRight_t1, pointsLeft_t1, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n     calcOpticalFlowPyrLK(imgLeft_t1, imgLeft_t0, pointsLeft_t1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n-    if (status3.size() != status0.size() or pointsLeft_t0.size() != points_0_return.size()) {\n-      std::cerr << \"Size of returned points was not correct!!\" << std::endl;\n-    }\n     std::vector<bool> status_all(status0.size());\n     for(unsigned int i = 0; i < status3.size(); i++) {\n       status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n     }\n"
                },
                {
                    "date": 1648149432539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -176,21 +176,11 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-bool isRotationMatrix(const cv::Mat &R)\n-{\n-    cv::Mat Rt;\n-    transpose(R, Rt);\n-    cv::Mat shouldBeIdentity = Rt * R;\n-    cv::Mat I = cv::Mat::eye(3,3, shouldBeIdentity.type());\n-     \n-    return  norm(I, shouldBeIdentity) < 1e-6;\n-}\n void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                               const cv::Mat &translation_stereo) {\n   cv::Mat rigid_body_transformation;\n-  assert(isRotationMatrix(rotation));\n \n   cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n \n   cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n"
                },
                {
                    "date": 1648149566668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n   rightCameraProjection_ = rightCameraProjection;\n }\n \n VisualOdometry::~VisualOdometry() {}\n-void VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n+std::pair<cv:Mat, cv:Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n"
                },
                {
                    "date": 1648149578440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n   rightCameraProjection_ = rightCameraProjection;\n }\n \n VisualOdometry::~VisualOdometry() {}\n-std::pair<cv:Mat, cv:Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n+std::pair<cv::Mat, cv::Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n"
                },
                {
                    "date": 1648149956865,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,8 +74,9 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n+          dbgstr(\"Likely error, rotation was huge.\");\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     std::cout << xyz.at<double>(0);\n"
                },
                {
                    "date": 1648149963060,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-          dbgstr(\"Likely error, rotation was huge.\");\n+      dbgstr(\"Likely error, rotation was huge.\");\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     std::cout << xyz.at<double>(0);\n"
                },
                {
                    "date": 1648149974493,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,10 +74,11 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n+      integrateOdometryStereo(frame_pose, rotation, translation);\n+    } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n-      integrateOdometryStereo(frame_pose, rotation, translation);\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     std::cout << xyz.at<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n"
                },
                {
                    "date": 1648150028727,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,32 +178,9 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n-                              const cv::Mat &translation_stereo) {\n-  cv::Mat rigid_body_transformation;\n \n-  cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n-\n-  cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n-  cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n-\n-  const double scale = sqrt(\n-    (translation_stereo.at<double>(0) * translation_stereo.at<double>(0)) +\n-    (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n-    (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n-\n-  rigid_body_transformation = rigid_body_transformation.inv();\n-  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n-  {\n-    frame_pose = frame_pose * rigid_body_transformation;\n-  } else {\n-    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n-              << std::endl;\n-  }\n-}\n-\n // Calculates rotation matrix to euler angles\n // The result is the same as MATLAB except the order\n // of the euler angles ( x and z are swapped ).\n cv::Vec3f visual_odometry::rotationMatrixToEulerAngles(const cv::Mat & R) {\n"
                },
                {
                    "date": 1648150071851,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -178,9 +178,32 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n+void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+                              const cv::Mat &translation_stereo) {\n+  cv::Mat rigid_body_transformation;\n \n+  cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n+\n+  cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n+  cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n+\n+  const double scale = sqrt(\n+    (translation_stereo.at<double>(0) * translation_stereo.at<double>(0)) +\n+    (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n+    (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n+\n+  rigid_body_transformation = rigid_body_transformation.inv();\n+  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n+  {\n+    frame_pose = frame_pose * rigid_body_transformation;\n+  } else {\n+    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n+              << std::endl;\n+  }\n+}\n+\n // Calculates rotation matrix to euler angles\n // The result is the same as MATLAB except the order\n // of the euler angles ( x and z are swapped ).\n cv::Vec3f visual_odometry::rotationMatrixToEulerAngles(const cv::Mat & R) {\n"
                },
                {
                    "date": 1648150146073,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -333,4 +333,28 @@\n \n   // Update current tracked points.\n   currentVOFeatures.points = pointsLeftT1;\n }\n+\n+void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+                              const cv::Mat &translation_stereo) {\n+  cv::Mat rigid_body_transformation;\n+\n+  cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n+\n+  cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n+  cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n+\n+  const double scale = sqrt(\n+    (translation_stereo.at<double>(0) * translation_stereo.at<double>(0)) +\n+    (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n+    (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n+\n+  rigid_body_transformation = rigid_body_transformation.inv();\n+  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n+  {\n+    frame_pose = frame_pose * rigid_body_transformation;\n+  } else {\n+    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n+              << std::endl;\n+  }\n+}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1648150204029,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,10 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n+    cv::Mat rot_1_timstep = rotation.clone();\n+    cv::Mat trans_1_timestep = translation.clone();\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648150214913,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,16 +64,16 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n-    cv::Mat rot_1_timstep = rotation.clone();\n-    cv::Mat trans_1_timestep = translation.clone();\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n+    cv::Mat rot_1_timstep = rotation.clone();\n+    cv::Mat trans_1_timestep = translation.clone();\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n"
                },
                {
                    "date": 1648150655334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -81,9 +81,8 @@\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n-    std::cout << xyz.at<double>(0);\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n     // if (true) {\n"
                },
                {
                    "date": 1648150681887,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,8 +24,10 @@\n \n VisualOdometry::~VisualOdometry() {}\n std::pair<cv::Mat, cv::Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n+    cv::Mat this_frame_rotation = cv::Mat::eye(3, 3, CV_64F);\n+    cv::Mat this_frame_translation = cv::Mat::zeros(3, 1, CV_64F);\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n       imageLeftT0_ = imageLeft;\n"
                },
                {
                    "date": 1648150689717,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,9 @@\n     if (!frame_id) {\n       imageLeftT0_ = imageLeft;\n       imageRightT0_ = imageRight;\n       frame_id++;\n-      return;\n+      return this_frame_translation, this_frame_rotation;\n     }\n \n     imageLeftT1_ = imageLeft;\n     imageRightT1_ = imageRight;\n"
                },
                {
                    "date": 1648150712868,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,9 @@\n     if (!frame_id) {\n       imageLeftT0_ = imageLeft;\n       imageRightT0_ = imageRight;\n       frame_id++;\n-      return this_frame_translation, this_frame_rotation;\n+      return make_pair(this_frame_translation, this_frame_rotation);\n     }\n \n     imageLeftT1_ = imageLeft;\n     imageRightT1_ = imageRight;\n"
                },
                {
                    "date": 1648150718026,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,9 @@\n     if (!frame_id) {\n       imageLeftT0_ = imageLeft;\n       imageRightT0_ = imageRight;\n       frame_id++;\n-      return make_pair(this_frame_translation, this_frame_rotation);\n+      return std::make_pair(this_frame_translation, this_frame_rotation);\n     }\n \n     imageLeftT1_ = imageLeft;\n     imageRightT1_ = imageRight;\n"
                },
                {
                    "date": 1648150731884,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,10 +72,10 @@\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n-    cv::Mat rot_1_timstep = rotation.clone();\n-    cv::Mat trans_1_timestep = translation.clone();\n+    this_frame_rotation = rotation.clone();\n+    this_frame_translation = translation.clone();\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n"
                },
                {
                    "date": 1648150744380,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,9 +52,9 @@\n     if (currentVOFeatures.size() < 5) {\n       // There are not enough features to fully determine\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n-      return;\n+      return std::make_pair(this_frame_translation, this_frame_rotation);\n     }\n \n     // ---------------------\n     // Triangulate 3D Points\n@@ -110,8 +110,9 @@\n     //         tf::StampedTransform(transform, ros::Time::now(), \"map\",\n     //         \"odom\"));\n     // }\n     frame_id++;\n+    return std::make_pair(this_frame_translation, this_frame_rotation);\n   }\n \n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/feature.cpp\n"
                },
                {
                    "date": 1648150764964,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,14 +72,14 @@\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n-    this_frame_rotation = rotation.clone();\n-    this_frame_translation = translation.clone();\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n+      this_frame_rotation = rotation.clone();\n+      this_frame_translation = translation.clone();\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n"
                },
                {
                    "date": 1648150988716,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -148,8 +148,12 @@\n                         std::vector<cv::Point2f> & pointsRight_t0,\n                         std::vector<cv::Point2f> & pointsLeft_t1,\n                         std::vector<cv::Point2f> & pointsRight_t1,\n                         std::vector<cv::Point2f> & points_0_return) {\n+    if(pointsLeft_t0.size() == 0){\n+      std::vector<bool> status_all; \n+      return status_all;\n+    }\n     std::vector<float> err;\n \n     cv::Size winSize =\n         cv::Size(20, 20); // Lucas-Kanade optical flow window size\n"
                },
                {
                    "date": 1648151175727,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,8 +25,9 @@\n VisualOdometry::~VisualOdometry() {}\n std::pair<cv::Mat, cv::Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n     cv::Mat this_frame_rotation = cv::Mat::eye(3, 3, CV_64F);\n+    dbg(this_frame_rotation.at<double>(1,1));\n     cv::Mat this_frame_translation = cv::Mat::zeros(3, 1, CV_64F);\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n"
                },
                {
                    "date": 1648151205843,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,8 @@\n VisualOdometry::~VisualOdometry() {}\n std::pair<cv::Mat, cv::Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n     cv::Mat this_frame_rotation = cv::Mat::eye(3, 3, CV_64F);\n-    dbg(this_frame_rotation.at<double>(1,1));\n     cv::Mat this_frame_translation = cv::Mat::zeros(3, 1, CV_64F);\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n"
                },
                {
                    "date": 1648151662698,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -186,9 +186,9 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                               const cv::Mat &translation_stereo) {\n   cv::Mat rigid_body_transformation;\n \n   cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n"
                },
                {
                    "date": 1648151730885,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,9 @@\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     cameraToWorld(leftCameraProjection_,\n-        pointsLeftT1, world_points_T0, rotation, translation);\n+        pointsLeftT1, world_points_T0, this_frame_rotation, this_frame_translation);\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n@@ -186,9 +186,9 @@\n \n // --------------------------------\n // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n // --------------------------------\n-void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n+void visual_odometry::integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                               const cv::Mat &translation_stereo) {\n   cv::Mat rigid_body_transformation;\n \n   cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n"
                },
                {
                    "date": 1648151753103,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,10 +76,10 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      this_frame_rotation = rotation.clone();\n-      this_frame_translation = translation.clone();\n+      total_rotation = rotation.clone();\n+      total_translation = translation.clone();\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n"
                },
                {
                    "date": 1648151764473,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,10 +76,10 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      total_rotation = rotation.clone();\n-      total_translation = translation.clone();\n+      cv::Mat total_rotation = rotation.clone();\n+      cv::Mat total_translation = translation.clone();\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n"
                },
                {
                    "date": 1648151775904,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,10 +76,10 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      cv::Mat total_rotation = rotation.clone();\n-      cv::Mat total_translation = translation.clone();\n+      cv::Mat total_rotation = this_frame_rotation.clone();\n+      cv::Mat total_translation = this_frame_translation.clone();\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n"
                },
                {
                    "date": 1648151811082,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,10 +76,8 @@\n     cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      cv::Mat total_rotation = this_frame_rotation.clone();\n-      cv::Mat total_translation = this_frame_translation.clone();\n       integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n@@ -341,28 +339,4 @@\n \n   // Update current tracked points.\n   currentVOFeatures.points = pointsLeftT1;\n }\n-\n-void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n-                              const cv::Mat &translation_stereo) {\n-  cv::Mat rigid_body_transformation;\n-\n-  cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n-\n-  cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n-  cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n-\n-  const double scale = sqrt(\n-    (translation_stereo.at<double>(0) * translation_stereo.at<double>(0)) +\n-    (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n-    (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n-\n-  rigid_body_transformation = rigid_body_transformation.inv();\n-  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n-  {\n-    frame_pose = frame_pose * rigid_body_transformation;\n-  } else {\n-    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n-              << std::endl;\n-  }\n-}\n\\ No newline at end of file\n"
                },
                {
                    "date": 1648151823164,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,13 +72,13 @@\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n-    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n+    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(this_frame_rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      integrateOdometryStereo(frame_pose, rotation, translation);\n+      integrateOdometryStereo(frame_pose, this_frame_rotation, this_frame_translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n"
                },
                {
                    "date": 1648152051740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,17 +24,17 @@\n \n VisualOdometry::~VisualOdometry() {}\n std::pair<cv::Mat, cv::Mat> VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                       const cv::Mat &imageRight) {\n-    cv::Mat this_frame_rotation = cv::Mat::eye(3, 3, CV_64F);\n-    cv::Mat this_frame_translation = cv::Mat::zeros(3, 1, CV_64F);\n+    cv::Mat rotation = cv::Mat::eye(3, 3, CV_64F);\n+    cv::Mat translation = cv::Mat::zeros(3, 1, CV_64F);\n     // Wait until we have at least two time steps of data\n     // to begin predicting the change in pose.\n     if (!frame_id) {\n       imageLeftT0_ = imageLeft;\n       imageRightT0_ = imageRight;\n       frame_id++;\n-      return std::make_pair(this_frame_translation, this_frame_rotation);\n+      return std::make_pair(translation, rotation);\n     }\n \n     imageLeftT1_ = imageLeft;\n     imageRightT1_ = imageRight;\n@@ -52,9 +52,9 @@\n     if (currentVOFeatures.size() < 5) {\n       // There are not enough features to fully determine\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n-      return std::make_pair(this_frame_translation, this_frame_rotation);\n+      return std::make_pair(translation, rotation);\n     }\n \n     // ---------------------\n     // Triangulate 3D Points\n@@ -67,18 +67,18 @@\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     cameraToWorld(leftCameraProjection_,\n-        pointsLeftT1, world_points_T0, this_frame_rotation, this_frame_translation);\n+        pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n-    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(this_frame_rotation);\n+    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n     if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n         abs(rotation_euler[2]) < 0.1) {\n-      integrateOdometryStereo(frame_pose, this_frame_rotation, this_frame_translation);\n+      integrateOdometryStereo(frame_pose, rotation, translation);\n     } else {\n       dbgstr(\"Likely error, rotation was huge.\");\n     }\n     cv::Mat xyz = frame_pose.col(3).clone();\n@@ -108,9 +108,9 @@\n     //         tf::StampedTransform(transform, ros::Time::now(), \"map\",\n     //         \"odom\"));\n     // }\n     frame_id++;\n-    return std::make_pair(this_frame_translation, this_frame_rotation);\n+    return std::make_pair(translation, rotation);\n   }\n \n   // --------------------------------\n   // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/feature.cpp\n"
                },
                {
                    "date": 1648152712304,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,8 +66,9 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n+    cout << world_points_T0.shape;\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648152722084,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n-    cout << world_points_T0.shape;\n+    dbg(world_points_T0.shape);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648152856063,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,10 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n-    dbg(world_points_T0.shape);\n+    dbg(world_points_T0.rows);\n+    dbg(world_points_T0.cols);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648152962981,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,8 +68,9 @@\n     // Tracking transfomation\n     // ---------------------\n     dbg(world_points_T0.rows);\n     dbg(world_points_T0.cols);\n+    dbg(world_points_T0.cn);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648153005791,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     // Tracking transfomation\n     // ---------------------\n     dbg(world_points_T0.rows);\n     dbg(world_points_T0.cols);\n-    dbg(world_points_T0.cn);\n+    dbg(world_points_T0.size);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648153025798,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,10 +66,8 @@\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n-    dbg(world_points_T0.rows);\n-    dbg(world_points_T0.cols);\n     dbg(world_points_T0.size);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n"
                },
                {
                    "date": 1648153052845,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,14 +61,15 @@\n     // ---------------------\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n+    dbg(world_homogenous_points_T0.size);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n+    dbg(world_points_T0.size);\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n-    dbg(world_points_T0.size);\n     cameraToWorld(leftCameraProjection_,\n         pointsLeftT1, world_points_T0, rotation, translation);\n \n     // ------------------------------------------------\n"
                },
                {
                    "date": 1648153228292,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     dbg(world_homogenous_points_T0.size);\n-    cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n+    cv::convertPointsFromHomogeneous(world_homogenous_points_T0., world_points_T0);\n     dbg(world_points_T0.size);\n \n     // ---------------------\n     // Tracking transfomation\n"
                },
                {
                    "date": 1648153254493,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,9 @@\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     dbg(world_homogenous_points_T0.size);\n-    cv::convertPointsFromHomogeneous(world_homogenous_points_T0., world_points_T0);\n+    cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n \n     // ---------------------\n     // Tracking transfomation\n"
                },
                {
                    "date": 1648153337440,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,9 @@\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     dbg(world_homogenous_points_T0.size);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n+    dbg(world_points_T0[0].size);\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648153348009,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,12 +61,11 @@\n     // ---------------------\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n-    dbg(world_homogenous_points_T0.size);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n-    dbg(world_points_T0[0].size);\n+    dbg(world_points_T0.at<float>[0].size);\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648153377161,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n-    dbg(world_points_T0.at<float>[0].size);\n+    dbg(world_points_T0.at<float>(0));\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648153467889,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n-    dbg(world_points_T0.at<float>(0));\n+    dbg(world_points_T0.at<float>(0)); // use float not double\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648153473632,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n-    dbg(world_points_T0.at<float>(0)); // use float not double\n+    dbg(world_points_T0.at<float>(0));\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648153569916,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,8 +63,9 @@\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n     dbg(world_points_T0.size);\n+    dbg(world_points_T0.channels());\n     dbg(world_points_T0.at<float>(0));\n \n     // ---------------------\n     // Tracking transfomation\n"
                },
                {
                    "date": 1648527320889,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,9 +47,9 @@\n \n     // Set new images as old images.\n     imageLeftT0_ = imageLeftT1_;\n     imageRightT0_ = imageRightT1_;\n-    dbg(currentVOFeatures.size());\n+    // dbg(currentVOFeatures.size());\n     if (currentVOFeatures.size() < 5) {\n       // There are not enough features to fully determine\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n@@ -62,11 +62,11 @@\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n-    dbg(world_points_T0.size);\n-    dbg(world_points_T0.channels());\n-    dbg(world_points_T0.at<float>(0));\n+    // dbg(world_points_T0.size);\n+    // dbg(world_points_T0.channels());\n+    // dbg(world_points_T0.at<float>(0));\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n"
                },
                {
                    "date": 1648528223383,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,11 +62,8 @@\n     cv::Mat world_points_T0, world_homogenous_points_T0;\n     cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                           pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n     cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n-    // dbg(world_points_T0.size);\n-    // dbg(world_points_T0.channels());\n-    // dbg(world_points_T0.at<float>(0));\n \n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n@@ -202,9 +199,9 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n+  if ( scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n     std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n"
                },
                {
                    "date": 1648528249230,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,14 +199,14 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  if ( scale < 10) // WHY DO WE NEED THIS\n+  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n-    std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n-              << std::endl;\n+    // std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n+    //           << std::endl;\n   }\n }\n \n // Calculates rotation matrix to euler angles\n"
                },
                {
                    "date": 1648581339464,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,16 +72,16 @@\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n-    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n+    // cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n     // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n-    if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n-        abs(rotation_euler[2]) < 0.1) {\n-      integrateOdometryStereo(frame_pose, rotation, translation);\n-    } else {\n-      dbgstr(\"Likely error, rotation was huge.\");\n-    }\n+    // if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n+    //     abs(rotation_euler[2]) < 0.1) {\n+    //   integrateOdometryStereo(frame_pose, rotation, translation);\n+    // } else {\n+    //   dbgstr(\"Likely error, rotation was huge.\");\n+    // }\n     cv::Mat xyz = frame_pose.col(3).clone();\n     cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n \n     // publish\n"
                },
                {
                    "date": 1648582656292,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -305,10 +305,10 @@\n \n   pointsLeftT0 = currentVOFeatures.points;\n   if (currentVOFeatures.points.size() == 0) return; // early exit\n \n-  std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n-                    pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n+  std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageLeft_t1, imageRight_t1, \n+                    pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0);\n \n   // Check if circled back points are in range of original points.\n   std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0.5);\n   // Only keep points that were matched correctly and are in the image bounds.\n"
                },
                {
                    "date": 1648584366700,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -309,9 +309,9 @@\n   std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageLeft_t1, imageRight_t1, \n                     pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0);\n \n   // Check if circled back points are in range of original points.\n-  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0.5);\n+  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 1.5);\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1648584571624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -309,9 +309,9 @@\n   std::vector<bool> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageLeft_t1, imageRight_t1, \n                     pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0);\n \n   // Check if circled back points are in range of original points.\n-  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 1.5);\n+  std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 1.999);\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n"
                },
                {
                    "date": 1648584586756,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -314,15 +314,15 @@\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-            (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+            // (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n             (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-            (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+            // (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n             (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-            (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+            // (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n             (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-            (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+            // (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n             // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n             // all valid locations\n             ) {\n         status[i] = false;\n"
                },
                {
                    "date": 1648584593393,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -314,15 +314,15 @@\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-            // (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+            (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n             (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-            // (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+            (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n             (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-            // (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+            (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n             (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-            // (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+            (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n             // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n             // all valid locations\n             ) {\n         status[i] = false;\n"
                },
                {
                    "date": 1648584917136,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,9 +199,9 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n+  if (scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n     // std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n"
                },
                {
                    "date": 1648584964021,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -199,9 +199,9 @@\n     (translation_stereo.at<double>(1) * translation_stereo.at<double>(1)) +\n     (translation_stereo.at<double>(2) * translation_stereo.at<double>(2)));\n \n   rigid_body_transformation = rigid_body_transformation.inv();\n-  if (scale < 10) // WHY DO WE NEED THIS\n+  if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n   {\n     frame_pose = frame_pose * rigid_body_transformation;\n   } else {\n     // std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n"
                },
                {
                    "date": 1648587614973,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -314,15 +314,15 @@\n   // Only keep points that were matched correctly and are in the image bounds.\n   for(unsigned int i = 0; i < status.size(); i++) {\n     if(!matchingStatus[i] ||\n         (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n-            (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n+            (pointsLeftT0[i].y >= imageLeft_t0.rows) || (pointsLeftT0[i].x >= imageLeft_t0.cols) ||\n             (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n-            (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n+            (pointsLeftT1[i].y >= imageLeft_t1.rows) || (pointsLeftT1[i].x >= imageLeft_t1.cols) ||\n             (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n-            (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n+            (pointsRightT0[i].y >= imageRight_t0.rows) || (pointsRightT0[i].x >= imageRight_t0.cols) ||\n             (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n-            (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n+            (pointsRightT1[i].y >= imageRight_t1.rows) || (pointsRightT1[i].x >= imageRight_t1.cols)\n             // no need to check bounds for pointsLeftReturn_t0 since it's equal to pointsLeftT0 at\n             // all valid locations\n             ) {\n         status[i] = false;\n"
                },
                {
                    "date": 1648587626417,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,9 +47,9 @@\n \n     // Set new images as old images.\n     imageLeftT0_ = imageLeftT1_;\n     imageRightT0_ = imageRightT1_;\n-    // dbg(currentVOFeatures.size());\n+    dbg(currentVOFeatures.size());\n     if (currentVOFeatures.size() < 5) {\n       // There are not enough features to fully determine\n       // equations for pose estimation, so presume nothing and exit.\n       frame_id++;\n"
                },
                {
                    "date": 1648587760696,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -297,8 +297,11 @@\n   if(currentVOFeatures.size() < 4000) {\n       // update feature set with detected features from the image.\n       currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n   }\n+  if(currentVOFeatures.size() < 50) {\n+      currentVOFeatures.appendGridOfFeatures(imageLeft_t0);\n+  }\n \n   // --------------------------------------------------------\n   // Feature tracking using KLT tracker, bucketing and circular matching.\n   // --------------------------------------------------------\n"
                },
                {
                    "date": 1648587777256,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -297,9 +297,10 @@\n   if(currentVOFeatures.size() < 4000) {\n       // update feature set with detected features from the image.\n       currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n   }\n-  if(currentVOFeatures.size() < 50) {\n+  if(currentVOFeatures.size() < 100) {\n+      // Just append a bunch of random features\n       currentVOFeatures.appendGridOfFeatures(imageLeft_t0);\n   }\n \n   // --------------------------------------------------------\n"
                },
                {
                    "date": 1648587833656,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -300,8 +300,9 @@\n   }\n   if(currentVOFeatures.size() < 100) {\n       // Just append a bunch of random features\n       currentVOFeatures.appendGridOfFeatures(imageLeft_t0);\n+      dbg(currentVOFeatures.size());\n   }\n \n   // --------------------------------------------------------\n   // Feature tracking using KLT tracker, bucketing and circular matching.\n"
                },
                {
                    "date": 1648587971223,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -300,9 +300,8 @@\n   }\n   if(currentVOFeatures.size() < 100) {\n       // Just append a bunch of random features\n       currentVOFeatures.appendGridOfFeatures(imageLeft_t0);\n-      dbg(currentVOFeatures.size());\n   }\n \n   // --------------------------------------------------------\n   // Feature tracking using KLT tracker, bucketing and circular matching.\n"
                },
                {
                    "date": 1648603754138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,7 +132,7 @@\n                         rvec, translation, false, 200, 0.5, 20, &inliers);\n     #endif\n \n     cv::Rodrigues(rvec, rotation);\n-    debug(\"[vo]: inliers size after PnP: \" + std::to_string(inliers.size().height) + \" out of \" + std::to_string(pointsLeft_t1.size()));\n+    // debug(\"[vo]: inliers size after PnP: \" + std::to_string(inliers.size().height) + \" out of \" + std::to_string(pointsLeft_t1.size()));\n     return inliers.size().height;\n }\n"
                }
            ],
            "date": 1647548849040,
            "name": "Commit-0",
            "content": "/****************************************************************\n *\n * @file \t\tvo.cpp\n *\n * @brief \t\tThe Visual Odometry class being used for\n translation. The math can be found in Haidar Jamal's Thesis:\n *https://www.ri.cmu.edu/publications/localization-for-lunar-micro-rovers/\n *\n * @version \t1.0\n * @date \t\t02/09/2022\n *\n * @authors \tBen Kolligs, Alex Li\n * @author \t\tCarnegie Mellon University, Planetary Robotics Lab\n *\n ****************************************************************/\n#include \"../include/vo.h\"\n\nnamespace visual_odometry {\nVisualOdometry::VisualOdometry(const cv::Mat leftCameraProjection,\n                               const cv::Mat rightCameraProjection) {\n  leftCameraProjection_ = leftCameraProjection;\n  rightCameraProjection_ = rightCameraProjection;\n}\n\nVisualOdometry::~VisualOdometry() {}\nvoid VisualOdometry::stereo_callback(const cv::Mat &imageLeft,\n                                      const cv::Mat &imageRight) {\n    // Wait until we have at least two time steps of data\n    // to begin predicting the change in pose.\n    if (!frame_id) {\n      imageLeftT0_ = imageLeft;\n      imageRightT0_ = imageRight;\n      frame_id++;\n      return;\n    }\n\n    imageLeftT1_ = imageLeft;\n    imageRightT1_ = imageRight;\n\n    std::vector<cv::Point2f> pointsLeftT0, pointsRightT0, pointsLeftT1,\n        pointsRightT1;\n    \n    matchingFeatures(imageLeftT0_, imageRightT0_, imageLeftT1_, imageRightT1_,\n                     currentVOFeatures, pointsLeftT0, pointsRightT0,\n                     pointsLeftT1, pointsRightT1);\n\n    // Set new images as old images.\n    imageLeftT0_ = imageLeftT1_;\n    imageRightT0_ = imageRightT1_;\n\n    if (currentVOFeatures.size() < 5) {\n      // There are not enough features to fully determine\n      // equations for pose estimation, so presume nothing and exit.\n      frame_id++;\n      return;\n    }\n\n    // ---------------------\n    // Triangulate 3D Points\n    // ---------------------\n    cv::Mat world_points_T0, world_homogenous_points_T0;\n    cv::triangulatePoints(leftCameraProjection_, rightCameraProjection_,\n                          pointsLeftT0, pointsRightT0, world_homogenous_points_T0);\n    cv::convertPointsFromHomogeneous(world_homogenous_points_T0.t(), world_points_T0);\n\n    // ---------------------\n    // Tracking transfomation\n    // ---------------------\n    cameraToWorld(leftCameraProjection_,\n        pointsLeftT1, world_points_T0, rotation, translation);\n\n    // ------------------------------------------------\n    // Integrating\n    // ------------------------------------------------\n    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n    // Don't perform an update if the output is unusually large, indicates a error elsewhere.\n    if (abs(rotation_euler[1]) < 0.1 && abs(rotation_euler[0]) < 0.1 &&\n        abs(rotation_euler[2]) < 0.1) {\n      integrateOdometryStereo(frame_pose, rotation, translation);\n    }\n    cv::Mat xyz = frame_pose.col(3).clone();\n    cv::Mat R = frame_pose(cv::Rect(0, 0, 3, 3));\n\n    // publish\n    // if (true) {\n    //     static tf::TransformBroadcaster br;\n\n    //     tf::Transform transform;\n    //     transform.setOrigin(tf::Vector3(xyz.at<double>(0), xyz.at<double>(1),\n    //                                     xyz.at<double>(2)));\n    //     tf::Quaternion q;\n    //     tf::Matrix3x3 R_tf(\n    //         R.at<double>(0, 0), R.at<double>(0, 1), R.at<double>(0, 2),\n    //         R.at<double>(1, 0), R.at<double>(1, 1), R.at<double>(1, 2),\n    //         R.at<double>(2, 0), R.at<double>(2, 1), R.at<double>(2, 2));\n    //     R_tf.getRotation(q);\n    //     transform.setRotation(q);\n    //     br.sendTransform(tf::StampedTransform(transform, ros::Time::now(),\n    //                                           \"odom\", \"camera\"));\n\n    //     transform.setOrigin(tf::Vector3(0.0, 0.0, 0.0));\n    //     tf::Quaternion q2(0.5, -0.5, 0.5, -0.5);\n    //     transform.setRotation(q2);\n    //     br.sendTransform(\n    //         tf::StampedTransform(transform, ros::Time::now(), \"map\",\n    //         \"odom\"));\n    // }\n    frame_id++;\n  }\n\n  // --------------------------------\n  // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/feature.cpp\n  // --------------------------------\n\n  void deleteFeaturesWithFailureStatus(\n      std::vector<cv::Point2f> & points0, std::vector<cv::Point2f> & points1,\n      std::vector<cv::Point2f> & points2, std::vector<cv::Point2f> & points3,\n      std::vector<cv::Point2f> & points4, FeatureSet& current_features,\n      const std::vector<bool> & status_all) {\n    // getting rid of points for which the KLT tracking failed or those who have\n    // gone outside the frame\n    int indexCorrection = 0;\n    for (int i = 0; i < status_all.size(); i++) {\n      cv::Point2f pt0 = points0.at(i - indexCorrection);\n      cv::Point2f pt1 = points1.at(i - indexCorrection);\n      cv::Point2f pt2 = points2.at(i - indexCorrection);\n      cv::Point2f pt3 = points3.at(i - indexCorrection);\n      cv::Point2f pt4 = points4.at(i - indexCorrection);\n      // no need to check bounds for pt4 since it's equal to pt0 at\n      // all valid locations\n      if ((status_all.at(i) == 0)) {\n        points0.erase(points0.begin() + (i - indexCorrection));\n        points1.erase(points1.begin() + (i - indexCorrection));\n        points2.erase(points2.begin() + (i - indexCorrection));\n        points3.erase(points3.begin() + (i - indexCorrection));\n        points4.erase(points4.begin() + (i - indexCorrection));\n\n        current_features.ages.erase(current_features.ages.begin() + (i - indexCorrection));\n        current_features.strengths.erase(current_features.strengths.begin() + (i - indexCorrection));\n        indexCorrection++;\n      }\n    }\n  }\n\n  std::vector<uchar> circularMatching(const cv::Mat img_0, const cv::Mat img_1, const cv::Mat img_2,\n                        const cv::Mat img_3, std::vector<cv::Point2f> & points_0,\n                        std::vector<cv::Point2f> & points_1,\n                        std::vector<cv::Point2f> & points_2,\n                        std::vector<cv::Point2f> & points_3,\n                        std::vector<cv::Point2f> & points_0_return) {\n    std::vector<float> err;\n\n    cv::Size winSize =\n        cv::Size(20, 20); // Lucas-Kanade optical flow window size\n    cv::TermCriteria termcrit = cv::TermCriteria(\n        cv::TermCriteria::COUNT + cv::TermCriteria::EPS, 30, 0.01);\n\n    std::vector<uchar> status0;\n    std::vector<uchar> status1;\n    std::vector<uchar> status2;\n    std::vector<uchar> status3;\n\n    // Sparse iterative version of the Lucas-Kanade optical flow in pyramids.\n    calcOpticalFlowPyrLK(img_0, img_1, points_0, points_1, status0, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n    calcOpticalFlowPyrLK(img_1, img_2, points_1, points_2, status1, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n    calcOpticalFlowPyrLK(img_2, img_3, points_2, points_3, status2, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n    calcOpticalFlowPyrLK(img_3, img_0, points_1, points_0_return, status3, err, winSize, 3, termcrit, cv::OPTFLOW_LK_GET_MIN_EIGENVALS, 0.01);\n    if (status3.size() != status0.size() or points_0.size() != points_0_return.size()) {\n      std::cerr << \"Size of returned points was not correct!!\\n\";\n    }\n    std::vector<uchar> status_all;\n    for(int i = 0; i < status3.size(); i++) {\n      status_all[i] = status0[i] | status1[i] | status2[i] | status3[i];\n    }\n    return status_all;\n  }\n\n\n  // --------------------------------\n  // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/utils.cpp\n  // --------------------------------\n\n  void integrateOdometryStereo(cv::Mat &frame_pose, const cv::Mat &rotation,\n                               const cv::Mat &translation_stereo) {\n    cv::Mat rigid_body_transformation;\n\n    cv::Mat addup = (cv::Mat_<double>(1, 4) << 0, 0, 0, 1);\n\n    cv::hconcat(rotation, translation_stereo, rigid_body_transformation);\n    cv::vconcat(rigid_body_transformation, addup, rigid_body_transformation);\n\n    const double scale = sqrt((translation_stereo.at<double>(0)) *\n                            (translation_stereo.at<double>(0)) +\n                        (translation_stereo.at<double>(1)) *\n                            (translation_stereo.at<double>(1)) +\n                        (translation_stereo.at<double>(2)) *\n                            (translation_stereo.at<double>(2)));\n\n    rigid_body_transformation = rigid_body_transformation.inv();\n    if (scale > 0.001 && scale < 10) // WHY DO WE NEED THIS\n    {\n      frame_pose = frame_pose * rigid_body_transformation;\n    } else {\n      std::cout << \"[WARNING] scale below 0.1, or incorrect translation\"\n                << std::endl;\n    }\n  }\n\n  // Calculates rotation matrix to euler angles\n  // The result is the same as MATLAB except the order\n  // of the euler angles ( x and z are swapped ).\n  cv::Vec3f rotationMatrixToEulerAngles(const cv::Mat & R) {\n    float sy = sqrt(R.at<double>(0, 0) * R.at<double>(0, 0) +\n                    R.at<double>(1, 0) * R.at<double>(1, 0));\n\n    bool singular = sy < 1e-6;\n\n    float x, y, z;\n    if (!singular) {\n      x = atan2(R.at<double>(2, 1), R.at<double>(2, 2));\n      y = atan2(-R.at<double>(2, 0), sy);\n      z = atan2(R.at<double>(1, 0), R.at<double>(0, 0));\n    } else {\n      x = atan2(-R.at<double>(1, 2), R.at<double>(1, 1));\n      y = atan2(-R.at<double>(2, 0), sy);\n      z = 0;\n    }\n    return cv::Vec3f(x, y, z);\n  }\n\n  // --------------------------------\n  // https://github.com/hjamal3/stereo_visual_odometry/blob/main/src/visualOdometry.cpp\n  // --------------------------------\n\n  std::vector<bool> findUnmovedPoints(const std::vector<cv::Point2f> & points_1,\n                       const std::vector<cv::Point2f> & points_2,\n                       const int threshold) {\n    std::vector<bool> status;\n    int offset;\n    for (int i = 0; i < points_1.size(); i++) {\n      offset = std::max(std::abs(points_1[i].x - points_2[i].x),\n                        std::abs(points_1[i].y - points_2[i].y));\n      if (offset > threshold) {\n        status.push_back(false);\n      } else {\n        status.push_back(true);\n      }\n    }\n    return status;\n  }\n\n  void removeInvalidPoints(std::vector<cv::Point2f> & points,\n                           const std::vector<bool> &status) {\n    int index = 0;\n    for (int i = 0; i < status.size(); i++) {\n      if (status[i] == false) {\n        points.erase(points.begin() + index);\n      } else {\n        index++;\n      }\n    }\n  }\n  void cameraToWorld(\n      const cv::Mat & cameraProjection,\n      const std::vector<cv::Point2f> & cameraPoints, const cv::Mat & worldPoints,\n      cv::Mat & rotation, cv::Mat & translation) {\n    // Calculate frame to frame transformation\n    cv::Mat distCoeffs = cv::Mat::zeros(4, 1, CV_64FC1);\n    cv::Mat rvec = cv::Mat::zeros(3, 1, CV_64FC1);\n    cv::Mat intrinsic_matrix =\n        (cv::Mat_<float>(3, 3) << cameraProjection.at<float>(0, 0),\n         cameraProjection.at<float>(0, 1),\n         cameraProjection.at<float>(0, 2),\n         cameraProjection.at<float>(1, 0),\n         cameraProjection.at<float>(1, 1),\n         cameraProjection.at<float>(1, 2),\n         cameraProjection.at<float>(1, 1),\n         cameraProjection.at<float>(1, 2),\n         cameraProjection.at<float>(1, 3));\n\n    int iterationsCount = 500; // number of Ransac iterations.\n    float reprojectionError = .5; // maximum allowed distance to consider it an inlier.\n    float confidence = 0.999; // RANSAC successful confidence.\n    bool useExtrinsicGuess = true;\n    int flags = cv::SOLVEPNP_ITERATIVE;\n\n    cv::Mat inliers;\n    cv::solvePnPRansac(worldPoints, cameraPoints, intrinsic_matrix, distCoeffs,\n                       rvec, translation, useExtrinsicGuess, iterationsCount,\n                       reprojectionError, confidence, inliers, flags);\n\n    cv::Rodrigues(rvec, rotation);\n  }\n\n  void matchingFeatures(\n      const cv::Mat &imageLeft_t0, const cv::Mat &imageRight_t0,\n      const cv::Mat &imageLeft_t1, const cv::Mat &imageRight_t1,\n      FeatureSet &currentVOFeatures, std::vector<cv::Point2f> &pointsLeftT0,\n      std::vector<cv::Point2f> &pointsRightT0,\n      std::vector<cv::Point2f> &pointsLeftT1,\n      std::vector<cv::Point2f> &pointsRightT1) {\n    \n    std::vector<cv::Point2f> pointsLeftReturn_t0; // feature points to check\n                                                  // circular matching validation\n    if(currentVOFeatures.size() < 4000) {\n        // update feature set with detected features from the image.\n        currentVOFeatures.appendFeaturesFromImage(imageLeft_t0);\n    }\n\n    // --------------------------------------------------------\n    // Feature tracking using KLT tracker, bucketing and circular matching.\n    // --------------------------------------------------------\n\n    pointsLeftT0 = currentVOFeatures.points;\n    if (currentVOFeatures.points.size() == 0) return; // early exit\n\n    std::vector<uchar> matchingStatus = circularMatching(imageLeft_t0, imageRight_t0, imageRight_t1, imageLeft_t1, \n                     pointsLeftT0, pointsRightT0, pointsRightT1, pointsLeftT1, pointsLeftReturn_t0);\n\n    // Check if circled back points are in range of original points.\n    std::vector<bool> status = findUnmovedPoints(pointsLeftT0, pointsLeftReturn_t0, 0);\n    \n    // Only keep points that were matched correctly and are in the image bounds.\n    for(int i = 0; i < status.size(); i++) {\n      if(!matchingStatus[i] ||\n          (pointsLeftT0[i].x < 0) || (pointsLeftT0[i].y < 0) ||\n              (pointsLeftT0[i].x >= imageLeft_t0.rows) || (pointsLeftT0[i].y >= imageLeft_t0.cols) ||\n              (pointsLeftT1[i].x < 0) || (pointsLeftT1[i].y < 0) ||\n              (pointsLeftT1[i].x >= imageLeft_t1.rows) || (pointsLeftT1[i].y >= imageLeft_t1.cols) ||\n              (pointsRightT0[i].x < 0) || (pointsRightT0[i].y < 0) ||\n              (pointsRightT0[i].x >= imageRight_t0.rows) || (pointsRightT0[i].y >= imageRight_t0.cols) ||\n              (pointsRightT1[i].x < 0) || (pointsRightT1[i].y < 0) ||\n              (pointsRightT1[i].x >= imageRight_t1.rows) || (pointsRightT1[i].y >= imageRight_t1.cols)\n              ) {\n          status[i] = false;\n      }\n    }\n\n    deleteFeaturesWithFailureStatus(\n        pointsLeftT0, pointsRightT0, pointsLeftT1, pointsRightT1, pointsLeftReturn_t0,\n        currentVOFeatures, status);\n\n    for (int i = 0; i < currentVOFeatures.ages.size(); ++i) {\n      currentVOFeatures.ages[i] += 1;\n    }\n\n    // Update current tracked points.\n    currentVOFeatures.points = pointsLeftT1;\n  }\n} // namespace visual_odometry\n"
        }
    ]
}