{
    "sourceFile": "src/stereo_vo.cpp",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 20,
            "patches": [
                {
                    "date": 1644160456403,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1644160473230,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,9 +144,9 @@\n     {\n         std::cerr << \"no calib yaml\" << std::endl;\n         throw;\n     }\n-    // Get default projection parameters from file storage\n+    // Get default projection matrix parameters from file storage\n     cv::FileStorage fs(filename, cv::FileStorage::READ);\n     if(!(fs.isOpened()))\n     {\n         std::cerr << \"cv failed to load yaml\" << std::endl;\n@@ -162,9 +162,9 @@\n     cv::Mat projMatrl = (cv::Mat_<float>(3, 4) << fx, 0., cx, 0., 0., fy, cy, 0., 0,  0., 1., 0.);\n     cv::Mat projMatrr = (cv::Mat_<float>(3, 4) << fx, 0., cx, bf, 0., fy, cy, 0., 0,  0., 1., 0.);\n \n     // initialize VO object\n-    StereoVO stereo_vo(projMatrl,projMatrr);\n+    StereoVO stereo_vo(projMatrl, projMatrr);\n \n     // using message_filters to get stereo callback on one topic\n     message_filters::Subscriber<sensor_msgs::Image> image1_sub(n, \"left/image_rect\", 1);\n     message_filters::Subscriber<sensor_msgs::Image> image2_sub(n, \"right/image_rect\", 1);\n"
                },
                {
                    "date": 1644160774608,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -174,8 +174,8 @@\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n     sync.registerCallback(boost::bind(&StereoVO::stereo_callback, &stereo_vo, _1, _2));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n-    \n+  \n     ros::spin();\n     return 0;\n }\n"
                },
                {
                    "date": 1645289760307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -36,10 +36,8 @@\n }\n \n void StereoVO::run()\n {\n-    std::cout << std::endl << \"frame id \" << frame_id << std::endl;\n-\n     t_a = clock();\n     t_1 = clock();\n     std::vector<cv::Point2f> pointsLeft_t0, pointsRight_t0, pointsLeft_t1, pointsRight_t1;  \n     matchingFeatures( imageLeft_t0, imageRight_t0,\n"
                },
                {
                    "date": 1645395173769,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     // PnP: computes rotation and translation between pair of images\n-    trackingFrame2Frame(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n+    worldToCamera(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n"
                },
                {
                    "date": 1645395227148,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     // ---------------------\n     // Tracking transfomation\n     // ---------------------\n     // PnP: computes rotation and translation between pair of images\n-    worldToCamera(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n+    cameraToWorld(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n \n     // ------------------------------------------------\n     // Integrating\n     // ------------------------------------------------\n"
                },
                {
                    "date": 1645648013799,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n \n     // display visualize feature tracks\n     displayTracking(imageLeft_t1, pointsLeft_t0, pointsLeft_t1);\n \n-    if (currentVOFeatures.size() < 5 ) //TODO should this be AND?\n+    if (currentVOFeatures.size() < 5) //TODO should this be AND?\n     {\n         std::cout << \"not enough features matched for pose estimation\" << std::endl;\n         frame_id++;\n         return;  \n"
                },
                {
                    "date": 1645648022678,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n \n     // display visualize feature tracks\n     displayTracking(imageLeft_t1, pointsLeft_t0, pointsLeft_t1);\n \n-    if (currentVOFeatures.size() < 5) //TODO should this be AND?\n+    if (currentVOFeatures.size() < 5)\n     {\n         std::cout << \"not enough features matched for pose estimation\" << std::endl;\n         frame_id++;\n         return;  \n"
                },
                {
                    "date": 1645648345634,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,8 @@\n #include \"stereo_visual_odometry/stereo_vo.h\"\n #include <stdexcept>\n \n+namespace visual_odometry {\n StereoVO::StereoVO(cv::Mat projMatrl_, cv::Mat projMatrr_)\n {\n     projMatrl = projMatrl_;\n     projMatrr = projMatrr_;\n@@ -160,9 +161,9 @@\n     cv::Mat projMatrl = (cv::Mat_<float>(3, 4) << fx, 0., cx, 0., 0., fy, cy, 0., 0,  0., 1., 0.);\n     cv::Mat projMatrr = (cv::Mat_<float>(3, 4) << fx, 0., cx, bf, 0., fy, cy, 0., 0,  0., 1., 0.);\n \n     // initialize VO object\n-    StereoVO stereo_vo(projMatrl, projMatrr);\n+    VisualOdometry stereo_vo(projMatrl, projMatrr);\n \n     // using message_filters to get stereo callback on one topic\n     message_filters::Subscriber<sensor_msgs::Image> image1_sub(n, \"left/image_rect\", 1);\n     message_filters::Subscriber<sensor_msgs::Image> image2_sub(n, \"right/image_rect\", 1);\n@@ -176,4 +177,6 @@\n   \n     ros::spin();\n     return 0;\n }\n+\n+} // namespace visual_odometry\n\\ No newline at end of file\n"
                },
                {
                    "date": 1645648400537,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,9 +7,9 @@\n     projMatrl = projMatrl_;\n     projMatrr = projMatrr_;\n }\n \n-cv::Mat StereoVO::rosImage2CvMat(sensor_msgs::ImageConstPtr img) {\n+cv::Mat rosImage2CvMat(sensor_msgs::ImageConstPtr img) {\n     cv_bridge::CvImagePtr cv_ptr;\n     try {\n             cv_ptr = cv_bridge::toCvCopy(img, sensor_msgs::image_encodings::MONO8);\n     } catch (cv_bridge::Exception &e) {\n"
                },
                {
                    "date": 1645648409050,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,14 +1,8 @@\n #include \"stereo_visual_odometry/stereo_vo.h\"\n #include <stdexcept>\n \n namespace visual_odometry {\n-StereoVO::StereoVO(cv::Mat projMatrl_, cv::Mat projMatrr_)\n-{\n-    projMatrl = projMatrl_;\n-    projMatrr = projMatrr_;\n-}\n-\n cv::Mat rosImage2CvMat(sensor_msgs::ImageConstPtr img) {\n     cv_bridge::CvImagePtr cv_ptr;\n     try {\n             cv_ptr = cv_bridge::toCvCopy(img, sensor_msgs::image_encodings::MONO8);\n"
                },
                {
                    "date": 1645648437596,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,9 @@\n #include \"stereo_visual_odometry/stereo_vo.h\"\n #include <stdexcept>\n \n namespace visual_odometry {\n+\n cv::Mat rosImage2CvMat(sensor_msgs::ImageConstPtr img) {\n     cv_bridge::CvImagePtr cv_ptr;\n     try {\n             cv_ptr = cv_bridge::toCvCopy(img, sensor_msgs::image_encodings::MONO8);\n@@ -29,100 +30,8 @@\n     // run the pipeline\n     run();\n }\n \n-void StereoVO::run()\n-{\n-    t_a = clock();\n-    t_1 = clock();\n-    std::vector<cv::Point2f> pointsLeft_t0, pointsRight_t0, pointsLeft_t1, pointsRight_t1;  \n-    matchingFeatures( imageLeft_t0, imageRight_t0,\n-                      imageLeft_t1, imageRight_t1, \n-                      currentVOFeatures,\n-                      pointsLeft_t0, \n-                      pointsRight_t0, \n-                      pointsLeft_t1, \n-                      pointsRight_t1);  \n-    t_2 = clock();\n-\n-    // set new images as old images\n-    imageLeft_t0 = imageLeft_t1;\n-    imageRight_t0 = imageRight_t1;\n-\n-    // display visualize feature tracks\n-    displayTracking(imageLeft_t1, pointsLeft_t0, pointsLeft_t1);\n-\n-    if (currentVOFeatures.size() < 5)\n-    {\n-        std::cout << \"not enough features matched for pose estimation\" << std::endl;\n-        frame_id++;\n-        return;  \n-    }\n-\n-    // ---------------------\n-    // Triangulate 3D Points\n-    // ---------------------\n-    cv::Mat points3D_t0, points4D_t0;\n-    cv::triangulatePoints( projMatrl,  projMatrr,  pointsLeft_t0,  pointsRight_t0,  points4D_t0);\n-    cv::convertPointsFromHomogeneous(points4D_t0.t(), points3D_t0);\n-\n-    // ---------------------\n-    // Tracking transfomation\n-    // ---------------------\n-    // PnP: computes rotation and translation between pair of images\n-    cameraToWorld(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n-\n-    // ------------------------------------------------\n-    // Integrating\n-    // ------------------------------------------------\n-    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n-    if(abs(rotation_euler[1])<0.1 && abs(rotation_euler[0])<0.1 && abs(rotation_euler[2])<0.1)\n-    {\n-        integrateOdometryStereo(frame_id, frame_pose, rotation, translation);\n-\n-    } else {\n-\n-        std::cout << \"Too large rotation\"  << std::endl;\n-    }\n-    t_b = clock();\n-    float frame_time = 1000*(double)(t_b-t_a)/CLOCKS_PER_SEC;\n-    float fps = 1000/frame_time;\n-    //cout << \"[Info] frame times (ms): \" << frame_time << endl;\n-    //cout << \"[Info] FPS: \" << fps << endl;\n-    cv::Mat xyz = frame_pose.col(3).clone();\n-    cv::Mat R = frame_pose(cv::Rect(0,0,3,3));\n-\n-    // benchmark times\n-    if (false)\n-    {\n-        float time_matching_features = 1000*(double)(t_2-t_1)/CLOCKS_PER_SEC;\n-        std::cout << \"time to match features \" << time_matching_features << std::endl;\n-        std::cout << \"time total \" << float(t_b - t_a)/CLOCKS_PER_SEC*1000 << std::endl;\n-    }\n-\n-    // publish\n-    if (true)\n-    {\n-        std::cout << xyz << std::endl;\n-        static tf::TransformBroadcaster br;\n-\n-        tf::Transform transform;\n-        transform.setOrigin( tf::Vector3(xyz.at<double>(0), xyz.at<double>(1), xyz.at<double>(2)) );\n-        tf::Quaternion q;\n-        tf::Matrix3x3 R_tf(R.at<double>(0,0),R.at<double>(0,1),R.at<double>(0,2),R.at<double>(1,0),\n-            R.at<double>(1,1),R.at<double>(1,2),R.at<double>(2,0),R.at<double>(2,1),R.at<double>(2,2));\n-        R_tf.getRotation(q);\n-        transform.setRotation(q);\n-        br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), \"odom\", \"camera\"));\n-\n-        transform.setOrigin(tf::Vector3(0.0, 0.0,0.0));\n-        tf::Quaternion q2(0.5,-0.5,0.5,-0.5);\n-        transform.setRotation(q2);\n-        br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), \"map\", \"odom\"));\n-    }\n-    frame_id++;\n-}\n-\n // Entry point\n int main(int argc, char **argv)\n {\n \n"
                },
                {
                    "date": 1645648722673,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n     typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n-    sync.registerCallback(boost::bind(&StereoVO::stereo_callback, &stereo_vo, _1, _2));\n+    sync.registerCallback(boost::bind(&StereoVO::stereo_callback_ImageConstPtr, &stereo_vo, _1, _2));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n   \n     ros::spin();\n"
                },
                {
                    "date": 1645648739336,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,26 +12,8 @@\n     }\n     return cv_ptr->image;\n }\n \n-void StereoVO::stereo_callback(const sensor_msgs::ImageConstPtr& image_left, const sensor_msgs::ImageConstPtr& image_right)\n-{\n-\n-    if (!frame_id)\n-    {\n-        imageLeft_t0 = rosImage2CvMat(image_left);\n-        imageRight_t0 = rosImage2CvMat(image_right);\n-        frame_id++;\n-        return;\n-    }\n-\n-    imageLeft_t1 = rosImage2CvMat(image_left);\n-    imageRight_t1 = rosImage2CvMat(image_right);\n-\n-    // run the pipeline\n-    run();\n-}\n-\n // Entry point\n int main(int argc, char **argv)\n {\n \n"
                },
                {
                    "date": 1645649021530,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,10 @@\n     typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n-    sync.registerCallback(boost::bind(&StereoVO::stereo_callback_ImageConstPtr, &stereo_vo, _1, _2));\n+    sync.registerCallback(boost::bind(&StereoVO::stereo_callback_ImageConstPtr, &stereo_vo, \n+        boost::bind(rosImage2CvMat(_1)), boost::bind(rosImage2CvMat(_2))));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n   \n     ros::spin();\n"
                },
                {
                    "date": 1645649048136,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,9 +55,9 @@\n     typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n-    sync.registerCallback(boost::bind(&StereoVO::stereo_callback_ImageConstPtr, &stereo_vo, \n+    sync.registerCallback(boost::bind(&VisualOdometry::stereo_callback_, &stereo_vo, \n         boost::bind(rosImage2CvMat(_1)), boost::bind(rosImage2CvMat(_2))));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n   \n"
                },
                {
                    "date": 1645649059516,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,6 +63,5 @@\n   \n     ros::spin();\n     return 0;\n }\n-\n-} // namespace visual_odometry\n\\ No newline at end of file\n+} // namespace visual_odometry\n"
                },
                {
                    "date": 1645649102048,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n     sync.registerCallback(boost::bind(&VisualOdometry::stereo_callback_, &stereo_vo, \n-        boost::bind(rosImage2CvMat(_1)), boost::bind(rosImage2CvMat(_2))));\n+        boost::bind(rosImage2CvMat, _1), boost::bind(rosImage2CvMat, _2)));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n   \n     ros::spin();\n"
                },
                {
                    "date": 1645649263950,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,8 +55,10 @@\n     typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n+    // Register stereo_callback to the synchronizer. When the synchronizer sends a pair of images\n+    // _1 and _2, we convert them into matricies and run visual odometry.\n     sync.registerCallback(boost::bind(&VisualOdometry::stereo_callback_, &stereo_vo, \n         boost::bind(rosImage2CvMat, _1), boost::bind(rosImage2CvMat, _2)));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n"
                },
                {
                    "date": 1645649271001,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,10 +55,10 @@\n     typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n \n     // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n     message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n-    // Register stereo_callback to the synchronizer. When the synchronizer sends a pair of images\n-    // _1 and _2, we convert them into matricies and run visual odometry.\n+    // Register stereo_callback to the synchronizer. When the synchronizer sends a pair of stereo\n+    // images _1 and _2, we convert them into matricies and run visual odometry.\n     sync.registerCallback(boost::bind(&VisualOdometry::stereo_callback_, &stereo_vo, \n         boost::bind(rosImage2CvMat, _1), boost::bind(rosImage2CvMat, _2)));\n \n     std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n"
                },
                {
                    "date": 1645649313195,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,5 @@\n-#include \"stereo_visual_odometry/stereo_vo.h\"\n+#include \"stereo_visual_odometry/vo.h\"\n #include <stdexcept>\n \n namespace visual_odometry {\n \n"
                }
            ],
            "date": 1644160456403,
            "name": "Commit-0",
            "content": "#include \"stereo_visual_odometry/stereo_vo.h\"\n#include <stdexcept>\n\nStereoVO::StereoVO(cv::Mat projMatrl_, cv::Mat projMatrr_)\n{\n    projMatrl = projMatrl_;\n    projMatrr = projMatrr_;\n}\n\ncv::Mat StereoVO::rosImage2CvMat(sensor_msgs::ImageConstPtr img) {\n    cv_bridge::CvImagePtr cv_ptr;\n    try {\n            cv_ptr = cv_bridge::toCvCopy(img, sensor_msgs::image_encodings::MONO8);\n    } catch (cv_bridge::Exception &e) {\n            return cv::Mat();\n    }\n    return cv_ptr->image;\n}\n\nvoid StereoVO::stereo_callback(const sensor_msgs::ImageConstPtr& image_left, const sensor_msgs::ImageConstPtr& image_right)\n{\n\n    if (!frame_id)\n    {\n        imageLeft_t0 = rosImage2CvMat(image_left);\n        imageRight_t0 = rosImage2CvMat(image_right);\n        frame_id++;\n        return;\n    }\n\n    imageLeft_t1 = rosImage2CvMat(image_left);\n    imageRight_t1 = rosImage2CvMat(image_right);\n\n    // run the pipeline\n    run();\n}\n\nvoid StereoVO::run()\n{\n    std::cout << std::endl << \"frame id \" << frame_id << std::endl;\n\n    t_a = clock();\n    t_1 = clock();\n    std::vector<cv::Point2f> pointsLeft_t0, pointsRight_t0, pointsLeft_t1, pointsRight_t1;  \n    matchingFeatures( imageLeft_t0, imageRight_t0,\n                      imageLeft_t1, imageRight_t1, \n                      currentVOFeatures,\n                      pointsLeft_t0, \n                      pointsRight_t0, \n                      pointsLeft_t1, \n                      pointsRight_t1);  \n    t_2 = clock();\n\n    // set new images as old images\n    imageLeft_t0 = imageLeft_t1;\n    imageRight_t0 = imageRight_t1;\n\n    // display visualize feature tracks\n    displayTracking(imageLeft_t1, pointsLeft_t0, pointsLeft_t1);\n\n    if (currentVOFeatures.size() < 5 ) //TODO should this be AND?\n    {\n        std::cout << \"not enough features matched for pose estimation\" << std::endl;\n        frame_id++;\n        return;  \n    }\n\n    // ---------------------\n    // Triangulate 3D Points\n    // ---------------------\n    cv::Mat points3D_t0, points4D_t0;\n    cv::triangulatePoints( projMatrl,  projMatrr,  pointsLeft_t0,  pointsRight_t0,  points4D_t0);\n    cv::convertPointsFromHomogeneous(points4D_t0.t(), points3D_t0);\n\n    // ---------------------\n    // Tracking transfomation\n    // ---------------------\n    // PnP: computes rotation and translation between pair of images\n    trackingFrame2Frame(projMatrl, projMatrr, pointsLeft_t1, points3D_t0, rotation, translation, false);\n\n    // ------------------------------------------------\n    // Integrating\n    // ------------------------------------------------\n    cv::Vec3f rotation_euler = rotationMatrixToEulerAngles(rotation);\n    if(abs(rotation_euler[1])<0.1 && abs(rotation_euler[0])<0.1 && abs(rotation_euler[2])<0.1)\n    {\n        integrateOdometryStereo(frame_id, frame_pose, rotation, translation);\n\n    } else {\n\n        std::cout << \"Too large rotation\"  << std::endl;\n    }\n    t_b = clock();\n    float frame_time = 1000*(double)(t_b-t_a)/CLOCKS_PER_SEC;\n    float fps = 1000/frame_time;\n    //cout << \"[Info] frame times (ms): \" << frame_time << endl;\n    //cout << \"[Info] FPS: \" << fps << endl;\n    cv::Mat xyz = frame_pose.col(3).clone();\n    cv::Mat R = frame_pose(cv::Rect(0,0,3,3));\n\n    // benchmark times\n    if (false)\n    {\n        float time_matching_features = 1000*(double)(t_2-t_1)/CLOCKS_PER_SEC;\n        std::cout << \"time to match features \" << time_matching_features << std::endl;\n        std::cout << \"time total \" << float(t_b - t_a)/CLOCKS_PER_SEC*1000 << std::endl;\n    }\n\n    // publish\n    if (true)\n    {\n        std::cout << xyz << std::endl;\n        static tf::TransformBroadcaster br;\n\n        tf::Transform transform;\n        transform.setOrigin( tf::Vector3(xyz.at<double>(0), xyz.at<double>(1), xyz.at<double>(2)) );\n        tf::Quaternion q;\n        tf::Matrix3x3 R_tf(R.at<double>(0,0),R.at<double>(0,1),R.at<double>(0,2),R.at<double>(1,0),\n            R.at<double>(1,1),R.at<double>(1,2),R.at<double>(2,0),R.at<double>(2,1),R.at<double>(2,2));\n        R_tf.getRotation(q);\n        transform.setRotation(q);\n        br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), \"odom\", \"camera\"));\n\n        transform.setOrigin(tf::Vector3(0.0, 0.0,0.0));\n        tf::Quaternion q2(0.5,-0.5,0.5,-0.5);\n        transform.setRotation(q2);\n        br.sendTransform(tf::StampedTransform(transform, ros::Time::now(), \"map\", \"odom\"));\n    }\n    frame_id++;\n}\n\n// Entry point\nint main(int argc, char **argv)\n{\n\n    ros::init(argc, argv, \"stereo_vo_node\");\n\n    ros::NodeHandle n;\n\n    ros::Rate loop_rate(20);\n\n    std::string filename; //TODO correct the name\n    if (!(n.getParam(\"calib_yaml\",filename)))\n    {\n        std::cerr << \"no calib yaml\" << std::endl;\n        throw;\n    }\n    // Get default projection parameters from file storage\n    cv::FileStorage fs(filename, cv::FileStorage::READ);\n    if(!(fs.isOpened()))\n    {\n        std::cerr << \"cv failed to load yaml\" << std::endl;\n        throw;\n    }\n    float fx, fy, cx, cy, bf; // Projection matrix parameters\n    fs[\"fx\"] >> fx;\n    fs[\"fy\"] >> fy;\n    fs[\"cx\"] >> cx;\n    fs[\"cy\"] >> cy;\n    fs[\"bf\"] >> bf;\n\n    cv::Mat projMatrl = (cv::Mat_<float>(3, 4) << fx, 0., cx, 0., 0., fy, cy, 0., 0,  0., 1., 0.);\n    cv::Mat projMatrr = (cv::Mat_<float>(3, 4) << fx, 0., cx, bf, 0., fy, cy, 0., 0,  0., 1., 0.);\n\n    // initialize VO object\n    StereoVO stereo_vo(projMatrl,projMatrr);\n\n    // using message_filters to get stereo callback on one topic\n    message_filters::Subscriber<sensor_msgs::Image> image1_sub(n, \"left/image_rect\", 1);\n    message_filters::Subscriber<sensor_msgs::Image> image2_sub(n, \"right/image_rect\", 1);\n    typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, sensor_msgs::Image> MySyncPolicy;\n\n    // ApproximateTime takes a queue size as its constructor argument, hence MySyncPolicy(10)\n    message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), image1_sub, image2_sub);\n    sync.registerCallback(boost::bind(&StereoVO::stereo_callback, &stereo_vo, _1, _2));\n\n    std::cout << \"Stereo VO Node Initialized!\" << std::endl;\n    \n    ros::spin();\n    return 0;\n}\n"
        }
    ]
}